{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Dissonance VoIP Dissonance is a realtime Voice over IP (VoIP) system designed to be built directly into unity games Low latency/real-time voice communications. Efficient Opus encoding Multiple chat rooms Private message to individual players Voice Activation and Push To Talk Positional Audio Echo cancellation Getting Started Start with Project Setup this will guide you through importing Dissonance into your project and then present you with links to tutorials. If you're looking for documentation on a specific topic look in the sidebar. Intermediate Topics These tutorials are intended for after you understand how to use the basic core features of Dissonance, they will guide you on how to get the most out of voice communication for your game. Advanced Topics If you want to do something unusual with Dissonance the advanced tutorials are the place to start. However we can't cover everything so if what you want to achieve isn't covered try asking the community or reporting an issue .","title":"Home"},{"location":"index.html#dissonance-voip","text":"Dissonance is a realtime Voice over IP (VoIP) system designed to be built directly into unity games Low latency/real-time voice communications. Efficient Opus encoding Multiple chat rooms Private message to individual players Voice Activation and Push To Talk Positional Audio Echo cancellation","title":"Dissonance VoIP"},{"location":"index.html#getting-started","text":"Start with Project Setup this will guide you through importing Dissonance into your project and then present you with links to tutorials. If you're looking for documentation on a specific topic look in the sidebar.","title":"Getting Started"},{"location":"index.html#intermediate-topics","text":"These tutorials are intended for after you understand how to use the basic core features of Dissonance, they will guide you on how to get the most out of voice communication for your game.","title":"Intermediate Topics"},{"location":"index.html#advanced-topics","text":"If you want to do something unusual with Dissonance the advanced tutorials are the place to start. However we can't cover everything so if what you want to achieve isn't covered try asking the community or reporting an issue .","title":"Advanced Topics"},{"location":"Basics/Choosing-A-Network.html","text":"Network Integrations The core Dissonance package does not do any networking itself - instead it relies on integrations with other network systems to send and receive data. This gives you a lot of flexibility in choosing how you want voice data to be sent between computers. If none of the existing integrations are suitable for you you can even write a custom network integration. The easiest setup is simply to send voice data through whatever networking system you are already using. However this isn't required - for example if you have a game using TCP for it's networking (which is unsuitable for voice comms) you could keep the game over that network and establish a second session just for voice chat. See the Standalone Networking section for more details on this. Basic Integrations These integrations simply send data though a network session which you first setup - Dissonance starts itself when it detects that a network session has been started and stops itself when the network session is stopped. These are the simplest network integrations to use, if your application is already using one of these backends you just need to drop some components into the scene and you immediately have a functional Dissonance voice chat session. UNet HLAPI Mirror Networking Forge Remastered Photon Bolt Photon Unity Networking (Classic) Photon Unity networking (2) Dark Rift 2 Steamworks.NET P2P The Steamworks integration hosts a voice chat session using Steamworks.NET peer to peer networking, it requires all users to be logged into a Steam account . This can be a useful integration to use if your game already uses steamworks for game networking, or if your primary game networking is not suitable for voice. Before starting Dissonance you must first have established peer to peer connectivity between all peers using Steamworks.NET, refer to the Steamworks documentation for further details on this. This is separated from the others in this section because you will need to have done some scripting to setup the session and will need to inform Dissonance of certain networking events (e.g. start/stop/join/leave session). Standalone Networking These integrations host a voice chat session separately from any other networking system you may be using. These are slightly more complicated to setup but they have the advantage that voice data is not mixed with other application data. You may want to use these integrations if your application does not have any other networking, or if your application network usage is metered and you don't want to pay the costs of voice traffic. UNet LLAPI This integration hosts a voice chat session using the UNet low level networking API (LLAPI), to start a session you need to supply the port/IP address of the host computer to all clients. All voice packets are sent via the server. There is no NAT negotiation included in LLAPI so you may need to use a third party asset or host the server on a computer with no NAT. WebRTC Network This integration hosts a voice chat session using WebRTC Network , to start a session you need to supply a unique session ID string to all clients. This includes NAT negotiation and all packets are sent peer to peer to reduce the amount of bandwidth used by the server. There is a demo project using Dissonance and this integration to build a standalone peer to peer chat application. Custom Networking If none of these options work for you it's possible to write a custom network backend for Dissonance - any system which can send unreliable packets (e.g. UDP) can carry voice data. There is detailed documentation on exactly how to do this here .","title":"Network Integrations"},{"location":"Basics/Choosing-A-Network.html#network-integrations","text":"The core Dissonance package does not do any networking itself - instead it relies on integrations with other network systems to send and receive data. This gives you a lot of flexibility in choosing how you want voice data to be sent between computers. If none of the existing integrations are suitable for you you can even write a custom network integration. The easiest setup is simply to send voice data through whatever networking system you are already using. However this isn't required - for example if you have a game using TCP for it's networking (which is unsuitable for voice comms) you could keep the game over that network and establish a second session just for voice chat. See the Standalone Networking section for more details on this.","title":"Network Integrations"},{"location":"Basics/Choosing-A-Network.html#basic-integrations","text":"These integrations simply send data though a network session which you first setup - Dissonance starts itself when it detects that a network session has been started and stops itself when the network session is stopped. These are the simplest network integrations to use, if your application is already using one of these backends you just need to drop some components into the scene and you immediately have a functional Dissonance voice chat session. UNet HLAPI Mirror Networking Forge Remastered Photon Bolt Photon Unity Networking (Classic) Photon Unity networking (2) Dark Rift 2","title":"Basic Integrations"},{"location":"Basics/Choosing-A-Network.html#steamworksnet-p2p","text":"The Steamworks integration hosts a voice chat session using Steamworks.NET peer to peer networking, it requires all users to be logged into a Steam account . This can be a useful integration to use if your game already uses steamworks for game networking, or if your primary game networking is not suitable for voice. Before starting Dissonance you must first have established peer to peer connectivity between all peers using Steamworks.NET, refer to the Steamworks documentation for further details on this. This is separated from the others in this section because you will need to have done some scripting to setup the session and will need to inform Dissonance of certain networking events (e.g. start/stop/join/leave session).","title":"Steamworks.NET P2P"},{"location":"Basics/Choosing-A-Network.html#standalone-networking","text":"These integrations host a voice chat session separately from any other networking system you may be using. These are slightly more complicated to setup but they have the advantage that voice data is not mixed with other application data. You may want to use these integrations if your application does not have any other networking, or if your application network usage is metered and you don't want to pay the costs of voice traffic.","title":"Standalone Networking"},{"location":"Basics/Choosing-A-Network.html#unet-llapi","text":"This integration hosts a voice chat session using the UNet low level networking API (LLAPI), to start a session you need to supply the port/IP address of the host computer to all clients. All voice packets are sent via the server. There is no NAT negotiation included in LLAPI so you may need to use a third party asset or host the server on a computer with no NAT.","title":"UNet LLAPI"},{"location":"Basics/Choosing-A-Network.html#webrtc-network","text":"This integration hosts a voice chat session using WebRTC Network , to start a session you need to supply a unique session ID string to all clients. This includes NAT negotiation and all packets are sent peer to peer to reduce the amount of bandwidth used by the server. There is a demo project using Dissonance and this integration to build a standalone peer to peer chat application.","title":"WebRTC Network"},{"location":"Basics/Choosing-A-Network.html#custom-networking","text":"If none of these options work for you it's possible to write a custom network backend for Dissonance - any system which can send unreliable packets (e.g. UDP) can carry voice data. There is detailed documentation on exactly how to do this here .","title":"Custom Networking"},{"location":"Basics/Getting-Started.html","text":"Tutorial: Getting Started In this tutorial you will create a new project, import Dissonance and set up some settings required for Dissonance to work properly. 1. Import Dissonance Import the Dissonance asset into the project. Every time you import a new version of Dissonance a window will pop up offering to take you to the latest changelog, you can launch this window again by navigating to Windows > Dissonance > Welcome Screen . 2. Download Integrations On the welcome screen is a list of integrations available for Dissonance. You should install at least one network backend integration - read these docs for help on choosing which one to use. 3. Run In Background Since this is a multiplayer game you're going to need the game to continue running (and processing network packets) even when the game window does not have focus. To do this navigate to Edit -> Project Settings -> Player , the inspector pane will now change to show the player settings, check the box labeled \"Run In Background\". 4. Per Platform Specific Setup Some platforms have special setup requirements, make sure to read the documentation for the platforms you want to work with: Android & Oculus Go iOS Linux MacOS Magic Leap Windows (Desktop) Windows (UWP/Hololens) 4. Complete! That's all you need to get a project set up and ready for Dissonance. Next, follow the appropriate Quick Start tutorial for the network system you plan to use for your game: Quick Start - Forge Remastered Quick Start - Photon (PUN) Quick Start - Photon Bolt Quick Start - Unity Networking HLAPI Quick Start - Mirror Quick Start - Dissonance Self Contained Networking (LLAPI based) Quick Start - Dark\ud83d\uddf2Rift 2 Quick Start - WebRTC Network Quick Start - Steamworks.NET","title":"Getting Started"},{"location":"Basics/Getting-Started.html#tutorial-getting-started","text":"In this tutorial you will create a new project, import Dissonance and set up some settings required for Dissonance to work properly.","title":"Tutorial: Getting Started"},{"location":"Basics/Getting-Started.html#1-import-dissonance","text":"Import the Dissonance asset into the project. Every time you import a new version of Dissonance a window will pop up offering to take you to the latest changelog, you can launch this window again by navigating to Windows > Dissonance > Welcome Screen .","title":"1. Import Dissonance"},{"location":"Basics/Getting-Started.html#2-download-integrations","text":"On the welcome screen is a list of integrations available for Dissonance. You should install at least one network backend integration - read these docs for help on choosing which one to use.","title":"2. Download Integrations"},{"location":"Basics/Getting-Started.html#3-run-in-background","text":"Since this is a multiplayer game you're going to need the game to continue running (and processing network packets) even when the game window does not have focus. To do this navigate to Edit -> Project Settings -> Player , the inspector pane will now change to show the player settings, check the box labeled \"Run In Background\".","title":"3. Run In Background"},{"location":"Basics/Getting-Started.html#4-per-platform-specific-setup","text":"Some platforms have special setup requirements, make sure to read the documentation for the platforms you want to work with: Android & Oculus Go iOS Linux MacOS Magic Leap Windows (Desktop) Windows (UWP/Hololens)","title":"4. Per Platform Specific Setup"},{"location":"Basics/Getting-Started.html#4-complete","text":"That's all you need to get a project set up and ready for Dissonance. Next, follow the appropriate Quick Start tutorial for the network system you plan to use for your game: Quick Start - Forge Remastered Quick Start - Photon (PUN) Quick Start - Photon Bolt Quick Start - Unity Networking HLAPI Quick Start - Mirror Quick Start - Dissonance Self Contained Networking (LLAPI based) Quick Start - Dark\ud83d\uddf2Rift 2 Quick Start - WebRTC Network Quick Start - Steamworks.NET","title":"4. Complete!"},{"location":"Basics/Introduction-To-Chat-Rooms.html","text":"Who Hears Whom? By default when a player speaks no one one will hear them - before players can communicate you need to set up where to send voice to on the speaking end and where to receive voice from on the listening end. Where to send to is controlled by a \" Voice Broadcast Trigger \" component and where to receive from is controlled by a \" Voice Receipt Trigger \" component. Speech Intent The \"Voice Broadcast Trigger\" does not only control who sends to where it also controls when voice is transmitted to the given target. This is referred to as \"Activation\" and is divided into two further section: does the user want to speak and is the user allowed to speak. The \"Activation Mode\" setting on the \"Voice Broadcast Trigger\" determines how the user indicates if they want to speak, this can be set to: \"None\", \"Voice Activation\" and \"Push To Talk\" (see the Voice Broadcast Trigger reference documentation for further details). The \"Trigger Activation\" setting is the setting for if the user is allowed to speak, an associated trigger volume can enable and disable the broadcast as the player moves in and out of the volume. This can be used to create areas in the scene the player needs to stand inside to be heard (e.g. proximity chat). Sender Target The broadcast trigger component supports three types of target: Room, Player and Self. The setting for this highlighted in the image above. Room When the target of a broadcaster is set to \"Room\" then the local voice will be sent to the given room. Other players who have subscribed to the same room will hear what is said. If a player is both sending and receiving from the same room they will not hear themselves speaking. Player When the target of a broadcaster is set to \"Player\" the the local voice will be sent only to the player specified by the \"Recipient Player Name\" field. The receiving player will automatically receive this without setting up a \"Voice Receipt Trigger\". Self When the target of a bradocaster is set to \"Self\" the broadcaster will look for a \"Dissonance Player\" component attached to the same game object and will send the local voice to the player represented by that component. This is equivalent to the player mode. The receiving player will automatically receive this without setting up a \"Voice Receipt Trigger\". Receiver If the sending target is \"Player\" or \"Self\" then the receiving player automatically hears anything transmitted to them. However this is not the case for rooms, receiving players need to subscribe to rooms they wish to listen to, this is controlled by the \"Voice Receipt Trigger\". When the trigger component is activated voice will be received from the given room. Specific Setups This system of broadcasters and receivers is very flexible and allows for a variety of different setups. This documentation includes some specific examples but if you have a specific design in mind which is not covered here feel free to raise an issue or discuss it with the community.","title":"Basic Concepts"},{"location":"Basics/Introduction-To-Chat-Rooms.html#who-hears-whom","text":"By default when a player speaks no one one will hear them - before players can communicate you need to set up where to send voice to on the speaking end and where to receive voice from on the listening end. Where to send to is controlled by a \" Voice Broadcast Trigger \" component and where to receive from is controlled by a \" Voice Receipt Trigger \" component.","title":"Who Hears Whom?"},{"location":"Basics/Introduction-To-Chat-Rooms.html#speech-intent","text":"The \"Voice Broadcast Trigger\" does not only control who sends to where it also controls when voice is transmitted to the given target. This is referred to as \"Activation\" and is divided into two further section: does the user want to speak and is the user allowed to speak. The \"Activation Mode\" setting on the \"Voice Broadcast Trigger\" determines how the user indicates if they want to speak, this can be set to: \"None\", \"Voice Activation\" and \"Push To Talk\" (see the Voice Broadcast Trigger reference documentation for further details). The \"Trigger Activation\" setting is the setting for if the user is allowed to speak, an associated trigger volume can enable and disable the broadcast as the player moves in and out of the volume. This can be used to create areas in the scene the player needs to stand inside to be heard (e.g. proximity chat).","title":"Speech Intent"},{"location":"Basics/Introduction-To-Chat-Rooms.html#sender-target","text":"The broadcast trigger component supports three types of target: Room, Player and Self. The setting for this highlighted in the image above.","title":"Sender Target"},{"location":"Basics/Introduction-To-Chat-Rooms.html#room","text":"When the target of a broadcaster is set to \"Room\" then the local voice will be sent to the given room. Other players who have subscribed to the same room will hear what is said. If a player is both sending and receiving from the same room they will not hear themselves speaking.","title":"Room"},{"location":"Basics/Introduction-To-Chat-Rooms.html#player","text":"When the target of a broadcaster is set to \"Player\" the the local voice will be sent only to the player specified by the \"Recipient Player Name\" field. The receiving player will automatically receive this without setting up a \"Voice Receipt Trigger\".","title":"Player"},{"location":"Basics/Introduction-To-Chat-Rooms.html#self","text":"When the target of a bradocaster is set to \"Self\" the broadcaster will look for a \"Dissonance Player\" component attached to the same game object and will send the local voice to the player represented by that component. This is equivalent to the player mode. The receiving player will automatically receive this without setting up a \"Voice Receipt Trigger\".","title":"Self"},{"location":"Basics/Introduction-To-Chat-Rooms.html#receiver","text":"If the sending target is \"Player\" or \"Self\" then the receiving player automatically hears anything transmitted to them. However this is not the case for rooms, receiving players need to subscribe to rooms they wish to listen to, this is controlled by the \"Voice Receipt Trigger\". When the trigger component is activated voice will be received from the given room.","title":"Receiver"},{"location":"Basics/Introduction-To-Chat-Rooms.html#specific-setups","text":"This system of broadcasters and receivers is very flexible and allows for a variety of different setups. This documentation includes some specific examples but if you have a specific design in mind which is not covered here feel free to raise an issue or discuss it with the community.","title":"Specific Setups"},{"location":"Basics/Licensing.html","text":"Licensing Dissonances uses parts of the WebRTC project for audio preprocessing/postprocessing and the Opus codec for encoding/decoding audio. The distribution requirements for both of these projects are quite simple - you must include copies of the license in your project alongside Opus.dll and AudioPluginDissonance.dll : Opus License WebRTC License","title":"Licensing"},{"location":"Basics/Licensing.html#licensing","text":"Dissonances uses parts of the WebRTC project for audio preprocessing/postprocessing and the Opus codec for encoding/decoding audio. The distribution requirements for both of these projects are quite simple - you must include copies of the license in your project alongside Opus.dll and AudioPluginDissonance.dll : Opus License WebRTC License","title":"Licensing"},{"location":"Basics/Quick-Start-DR2.html","text":"Quick Start: Dissonance with Dark\ud83d\uddf2Rift 2 This Quick Start guide is for those of you integrating Dissonance into a game with Dark Rift 2 . This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/DarkRift2/Demo folder. Note that to use the demo scene you must install the server plugins (see section 1a). Step 1: Dissonance Comms Object Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This game object contains the main \"Dissonance Comms\" behavior, together with the Dark Rift networking script. To place the default Dissonance game object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/DarkRift2 folder into your scene. This should create a game object with two scripts attached: \"Dissonance Comms\" and \"Dark Rift 2 Comms Network\". Step 1a: Server Setup Dark Rift has a system of server side plugins to process packets, Dissonance includes two plugins. For the demo scene there is a DissonanceDemoPlugin.dll , this is a very basic plugin to synchronise the positions of characters in the demo scene. There is also the DissonanceServerPlugin.dll which runs the Dissonance server logic. The precompiled plugin DLL files are included in the package, simply drop them into the plugins folder on your dark rift server. If you need to modify the code of the plugins unzip the ServerProject.zip into Assets/Dissonance/Integrations/DarkRift2/.ServerProject , this will create two visual studio projects (one for each of the DLLs). The projects reference the Dissonance source files by relative path, so it's critical that you unzip into the correct location! Step 2: Add a Broadcast Trigger You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to your scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what situations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room. Step 3: Add a Receipt Trigger Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room. You're Done! Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"Dark Rift 2"},{"location":"Basics/Quick-Start-DR2.html#quick-start-dissonance-with-darkrift-2","text":"This Quick Start guide is for those of you integrating Dissonance into a game with Dark Rift 2 . This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/DarkRift2/Demo folder. Note that to use the demo scene you must install the server plugins (see section 1a).","title":"Quick Start: Dissonance with Dark\ud83d\uddf2Rift 2"},{"location":"Basics/Quick-Start-DR2.html#step-1-dissonance-comms-object","text":"Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This game object contains the main \"Dissonance Comms\" behavior, together with the Dark Rift networking script. To place the default Dissonance game object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/DarkRift2 folder into your scene. This should create a game object with two scripts attached: \"Dissonance Comms\" and \"Dark Rift 2 Comms Network\".","title":"Step 1: Dissonance Comms Object"},{"location":"Basics/Quick-Start-DR2.html#step-1a-server-setup","text":"Dark Rift has a system of server side plugins to process packets, Dissonance includes two plugins. For the demo scene there is a DissonanceDemoPlugin.dll , this is a very basic plugin to synchronise the positions of characters in the demo scene. There is also the DissonanceServerPlugin.dll which runs the Dissonance server logic. The precompiled plugin DLL files are included in the package, simply drop them into the plugins folder on your dark rift server. If you need to modify the code of the plugins unzip the ServerProject.zip into Assets/Dissonance/Integrations/DarkRift2/.ServerProject , this will create two visual studio projects (one for each of the DLLs). The projects reference the Dissonance source files by relative path, so it's critical that you unzip into the correct location!","title":"Step 1a: Server Setup"},{"location":"Basics/Quick-Start-DR2.html#step-2-add-a-broadcast-trigger","text":"You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to your scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what situations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.","title":"Step 2: Add a Broadcast Trigger"},{"location":"Basics/Quick-Start-DR2.html#step-3-add-a-receipt-trigger","text":"Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.","title":"Step 3: Add a Receipt Trigger"},{"location":"Basics/Quick-Start-DR2.html#youre-done","text":"Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"You're Done!"},{"location":"Basics/Quick-Start-Forge-Remastered.html","text":"Quick Start: Dissonance with Forge Networking Remastered This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/ForgeNetworkingRemastered/Demo folder. Please make sure to read the include readme file before trying the demo scene. Step 1: Dissonance Comms Object Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This game object contains the main \"Dissonance Comms\" behavior, together with the Forge networking script. To place the default Dissonance game object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/ForgeNetworkingRemastered folder into your scene. This should create a game object with two scripts attached: \"Dissonance Comms\" and \"Forge Remastered Comms Network\". Step 2: Add a Broadcast Trigger You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room. Step 3: Add a Receipt Trigger Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room. You're Done! Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"Forge Networking Remastered"},{"location":"Basics/Quick-Start-Forge-Remastered.html#quick-start-dissonance-with-forge-networking-remastered","text":"This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/ForgeNetworkingRemastered/Demo folder. Please make sure to read the include readme file before trying the demo scene.","title":"Quick Start: Dissonance with Forge Networking Remastered"},{"location":"Basics/Quick-Start-Forge-Remastered.html#step-1-dissonance-comms-object","text":"Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This game object contains the main \"Dissonance Comms\" behavior, together with the Forge networking script. To place the default Dissonance game object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/ForgeNetworkingRemastered folder into your scene. This should create a game object with two scripts attached: \"Dissonance Comms\" and \"Forge Remastered Comms Network\".","title":"Step 1: Dissonance Comms Object"},{"location":"Basics/Quick-Start-Forge-Remastered.html#step-2-add-a-broadcast-trigger","text":"You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.","title":"Step 2: Add a Broadcast Trigger"},{"location":"Basics/Quick-Start-Forge-Remastered.html#step-3-add-a-receipt-trigger","text":"Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.","title":"Step 3: Add a Receipt Trigger"},{"location":"Basics/Quick-Start-Forge-Remastered.html#youre-done","text":"Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"You're Done!"},{"location":"Basics/Quick-Start-Mirror.html","text":"Quick Start: Dissonance with Mirror Networking This Quick Start guide is for those of you integrating Dissonance into a game with the Mirror Networking . You must use a network backend which supports unreliable networking such as Ignorance . This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/MirrorIgnorance/Demo folder. Step 1: Dissonance Comms Object Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the Mirror networking script. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/MirrorIgnorance folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and MirrorIgnoranceCommsNetwork . Step 1a: Setup Network Manager In this configuration Dissonance sends it's network packets through Mirror - this means you need a Mirror session setup for Dissonance to use. To create a high level network session add a Network Manager to your scene, this is a Mirror component which will handle setting up your network. If you need a basic UI for test purposes also add a Network Manager HUD to your scene, this is another Mirror component which shows a simple UI for creating and joining sessions. Step 2: Add a Broadcast Trigger You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room. Step 3: Add a Receipt Trigger Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room. You're Done! Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"Mirror Networking"},{"location":"Basics/Quick-Start-Mirror.html#quick-start-dissonance-with-mirror-networking","text":"This Quick Start guide is for those of you integrating Dissonance into a game with the Mirror Networking . You must use a network backend which supports unreliable networking such as Ignorance . This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/MirrorIgnorance/Demo folder.","title":"Quick Start: Dissonance with Mirror Networking"},{"location":"Basics/Quick-Start-Mirror.html#step-1-dissonance-comms-object","text":"Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the Mirror networking script. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/MirrorIgnorance folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and MirrorIgnoranceCommsNetwork .","title":"Step 1: Dissonance Comms Object"},{"location":"Basics/Quick-Start-Mirror.html#step-1a-setup-network-manager","text":"In this configuration Dissonance sends it's network packets through Mirror - this means you need a Mirror session setup for Dissonance to use. To create a high level network session add a Network Manager to your scene, this is a Mirror component which will handle setting up your network. If you need a basic UI for test purposes also add a Network Manager HUD to your scene, this is another Mirror component which shows a simple UI for creating and joining sessions.","title":"Step 1a: Setup Network Manager"},{"location":"Basics/Quick-Start-Mirror.html#step-2-add-a-broadcast-trigger","text":"You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.","title":"Step 2: Add a Broadcast Trigger"},{"location":"Basics/Quick-Start-Mirror.html#step-3-add-a-receipt-trigger","text":"Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.","title":"Step 3: Add a Receipt Trigger"},{"location":"Basics/Quick-Start-Mirror.html#youre-done","text":"Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"You're Done!"},{"location":"Basics/Quick-Start-Photon-Bolt.html","text":"Quick Start: Dissonance with Photon BOLT This Quick Start guide is for those of you integrating Dissonance into a game with the Photon BOLT networking asset This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/PhotonBolt/Demo folder. Be sure to read the README in the demo folder, as the demo will not initially compile until you have configured BOLT. Step 1: Dissonance Comms Object Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the Photon networking script. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/PhotonBolt folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and Bolt Comms Network . The Photon BOLT integration will automatically route Dissonance traffic through an established BOLT session. Step 2: Add a Broadcast Trigger You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room. Step 3: Add a Receipt Trigger Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room. You're Done! Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other Note that setting up positional audio for bolt requires some extra steps, see this article for more detail: 3D Positional Audio For BOLT","title":"Photon BOLT"},{"location":"Basics/Quick-Start-Photon-Bolt.html#quick-start-dissonance-with-photon-bolt","text":"This Quick Start guide is for those of you integrating Dissonance into a game with the Photon BOLT networking asset This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/PhotonBolt/Demo folder. Be sure to read the README in the demo folder, as the demo will not initially compile until you have configured BOLT.","title":"Quick Start: Dissonance with Photon BOLT"},{"location":"Basics/Quick-Start-Photon-Bolt.html#step-1-dissonance-comms-object","text":"Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the Photon networking script. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/PhotonBolt folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and Bolt Comms Network . The Photon BOLT integration will automatically route Dissonance traffic through an established BOLT session.","title":"Step 1: Dissonance Comms Object"},{"location":"Basics/Quick-Start-Photon-Bolt.html#step-2-add-a-broadcast-trigger","text":"You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.","title":"Step 2: Add a Broadcast Trigger"},{"location":"Basics/Quick-Start-Photon-Bolt.html#step-3-add-a-receipt-trigger","text":"Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.","title":"Step 3: Add a Receipt Trigger"},{"location":"Basics/Quick-Start-Photon-Bolt.html#youre-done","text":"Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other Note that setting up positional audio for bolt requires some extra steps, see this article for more detail: 3D Positional Audio For BOLT","title":"You're Done!"},{"location":"Basics/Quick-Start-Photon.html","text":"Quick Start: Dissonance with Photon Unity Networking (PUN) This Quick Start guide is for those of you integrating Dissonance into a game with Photon Unity Networking . This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/Photon/Demo folder. Step 1: Dissonance Comms Object Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the Photon networking script. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/Photon folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and PhotonCommsNetwork . The Photon integration will automatically route Dissonance traffic through the Photon cloud network. Step 2: Add a Broadcast Trigger You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room. Step 3: Add a Receipt Trigger Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room. You're Done! Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"Photon Unity Networking"},{"location":"Basics/Quick-Start-Photon.html#quick-start-dissonance-with-photon-unity-networking-pun","text":"This Quick Start guide is for those of you integrating Dissonance into a game with Photon Unity Networking . This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/Photon/Demo folder.","title":"Quick Start: Dissonance with Photon Unity Networking (PUN)"},{"location":"Basics/Quick-Start-Photon.html#step-1-dissonance-comms-object","text":"Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the Photon networking script. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/Photon folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and PhotonCommsNetwork . The Photon integration will automatically route Dissonance traffic through the Photon cloud network.","title":"Step 1: Dissonance Comms Object"},{"location":"Basics/Quick-Start-Photon.html#step-2-add-a-broadcast-trigger","text":"You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.","title":"Step 2: Add a Broadcast Trigger"},{"location":"Basics/Quick-Start-Photon.html#step-3-add-a-receipt-trigger","text":"Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.","title":"Step 3: Add a Receipt Trigger"},{"location":"Basics/Quick-Start-Photon.html#youre-done","text":"Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"You're Done!"},{"location":"Basics/Quick-Start-PureP2P.html","text":"Quick Start: Dissonance with PureP2P WebRTC Network This Quick Start guide is for those of you integrating Dissonance into a game with the WebRTC Network asset. This integration requires Dissonance 6.2.5 or greater. This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Assets/Dissonance/Integrations/PureP2P/Demo folder. Step 1: Dissonance Comms Object Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the PureP2P networking script. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/PureP2P folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: Dissonance Comms and Pure P2P Comms Network . Step 1a: Setup Network Session Dissonance internally manages the WebRTC network session, automatically hosting a session and connecting to other peers as they join. From your script you simply need to call InitializeAsServer or InitializeAsClient on the PureP2PCommsNetwork component and supply the same session ID to both calls. If the peer leaves the session you will need to start a new server with a new session ID and connect all the clients again. Step 2: Add a Broadcast Trigger You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room. Step 3: Add a Receipt Trigger Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room. You're Done! Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"WebRTC Network (self contained)"},{"location":"Basics/Quick-Start-PureP2P.html#quick-start-dissonance-with-purep2p-webrtc-network","text":"This Quick Start guide is for those of you integrating Dissonance into a game with the WebRTC Network asset. This integration requires Dissonance 6.2.5 or greater. This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Assets/Dissonance/Integrations/PureP2P/Demo folder.","title":"Quick Start: Dissonance with PureP2P WebRTC Network"},{"location":"Basics/Quick-Start-PureP2P.html#step-1-dissonance-comms-object","text":"Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the PureP2P networking script. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/PureP2P folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: Dissonance Comms and Pure P2P Comms Network .","title":"Step 1: Dissonance Comms Object"},{"location":"Basics/Quick-Start-PureP2P.html#step-1a-setup-network-session","text":"Dissonance internally manages the WebRTC network session, automatically hosting a session and connecting to other peers as they join. From your script you simply need to call InitializeAsServer or InitializeAsClient on the PureP2PCommsNetwork component and supply the same session ID to both calls. If the peer leaves the session you will need to start a new server with a new session ID and connect all the clients again.","title":"Step 1a: Setup Network Session"},{"location":"Basics/Quick-Start-PureP2P.html#step-2-add-a-broadcast-trigger","text":"You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.","title":"Step 2: Add a Broadcast Trigger"},{"location":"Basics/Quick-Start-PureP2P.html#step-3-add-a-receipt-trigger","text":"Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.","title":"Step 3: Add a Receipt Trigger"},{"location":"Basics/Quick-Start-PureP2P.html#youre-done","text":"Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"You're Done!"},{"location":"Basics/Quick-Start-Steamworks.Net-P2P.html","text":"Quick Start: Dissonance with Steamworks.NET P2P This Quick Start guide is for those of you integrating Dissonance into a game with the Steamworks.NET P2P API This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/SteamworksP2P/Demo folder. Step 1: Dissonance Comms Object Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the Steamworks P2P networking script. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/SteamworksP2P folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and SteamworksP2PCommsNetwork . Step 1a: Setup Network Session Dissonance does not manage your steamworks session, instead it uses whatever session you have already setup. This gives you maximum control over how you want the network session to be configured. Refer to the Steamworks Networking Documentation for details on how to setup a session. You can see example code in the SteamworksDemoUi component in the Assets/Dissonance/Integrations/SteamworksP2P/Demo folder. Once you have a Steamworks session running you need to inform Dissonance about the state of the session when it changes. When you have a session running you need to start Dissonance, call one of InitializeAsDedicatedServer , InitializeAsServer or InitializeAsClient on the SteamworksP2PCommsNetwork component. The server is the central control point of the session, if it leaves the game you must stop Dissonance and pick a new server. When a player joins the session you must call the PeerConnected method. When a player leaves the session you must call the PeerDisconnected method. Step 2: Add a Broadcast Trigger You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room. Step 3: Add a Receipt Trigger Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room. You're Done! Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"Steamworks.NET P2P"},{"location":"Basics/Quick-Start-Steamworks.Net-P2P.html#quick-start-dissonance-with-steamworksnet-p2p","text":"This Quick Start guide is for those of you integrating Dissonance into a game with the Steamworks.NET P2P API This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/SteamworksP2P/Demo folder.","title":"Quick Start: Dissonance with Steamworks.NET P2P"},{"location":"Basics/Quick-Start-Steamworks.Net-P2P.html#step-1-dissonance-comms-object","text":"Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the Steamworks P2P networking script. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/SteamworksP2P folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and SteamworksP2PCommsNetwork .","title":"Step 1: Dissonance Comms Object"},{"location":"Basics/Quick-Start-Steamworks.Net-P2P.html#step-1a-setup-network-session","text":"Dissonance does not manage your steamworks session, instead it uses whatever session you have already setup. This gives you maximum control over how you want the network session to be configured. Refer to the Steamworks Networking Documentation for details on how to setup a session. You can see example code in the SteamworksDemoUi component in the Assets/Dissonance/Integrations/SteamworksP2P/Demo folder. Once you have a Steamworks session running you need to inform Dissonance about the state of the session when it changes. When you have a session running you need to start Dissonance, call one of InitializeAsDedicatedServer , InitializeAsServer or InitializeAsClient on the SteamworksP2PCommsNetwork component. The server is the central control point of the session, if it leaves the game you must stop Dissonance and pick a new server. When a player joins the session you must call the PeerConnected method. When a player leaves the session you must call the PeerDisconnected method.","title":"Step 1a: Setup Network Session"},{"location":"Basics/Quick-Start-Steamworks.Net-P2P.html#step-2-add-a-broadcast-trigger","text":"You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.","title":"Step 2: Add a Broadcast Trigger"},{"location":"Basics/Quick-Start-Steamworks.Net-P2P.html#step-3-add-a-receipt-trigger","text":"Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.","title":"Step 3: Add a Receipt Trigger"},{"location":"Basics/Quick-Start-Steamworks.Net-P2P.html#youre-done","text":"Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"You're Done!"},{"location":"Basics/Quick-Start-UNet-HLAPI.html","text":"Quick Start: Dissonance with UNet High Level API (HLAPI) This Quick Start guide is for those of you integrating Dissonance into a game with the Unity Networking High Level API . This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/UNet_HLAPI/Demo folder. Step 1: Dissonance Comms Object Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the UNet HLAPI networking script. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/UNet_HLAPI folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and HlapiCommsNetwork . Step 1a: Setup Network Manager In this configuration Dissonance sends it's network packets through the UNet High Level API - this means you need a high level network session setup for Dissonance to use. To create a high level network session add a Network Manager to your scene, this is a Unity component which will handle setting up your network. If you need a basic UI for test purposes also add a Network Manager HUD to your scene, this is another Unity component which shows a simple UI for creating and joining sessions. Dissonance needs two network channels to send it's data through. On the Network Manager component check the Advanced Configuration checkbox and add two new channels, configure one as Reliable Sequenced and the other as Unreliable . In the Dissonance Hlapi Comms Network inspector check the Reliable Channel and Unreliable Channel fields correspond to the channels numbers in the Network Manager . Step 2: Add a Broadcast Trigger You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room. Step 3: Add a Receipt Trigger Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room. You're Done! Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"Unity Networking HLAPI"},{"location":"Basics/Quick-Start-UNet-HLAPI.html#quick-start-dissonance-with-unet-high-level-api-hlapi","text":"This Quick Start guide is for those of you integrating Dissonance into a game with the Unity Networking High Level API . This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/UNet_HLAPI/Demo folder.","title":"Quick Start: Dissonance with UNet High Level API (HLAPI)"},{"location":"Basics/Quick-Start-UNet-HLAPI.html#step-1-dissonance-comms-object","text":"Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the UNet HLAPI networking script. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/UNet_HLAPI folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and HlapiCommsNetwork .","title":"Step 1: Dissonance Comms Object"},{"location":"Basics/Quick-Start-UNet-HLAPI.html#step-1a-setup-network-manager","text":"In this configuration Dissonance sends it's network packets through the UNet High Level API - this means you need a high level network session setup for Dissonance to use. To create a high level network session add a Network Manager to your scene, this is a Unity component which will handle setting up your network. If you need a basic UI for test purposes also add a Network Manager HUD to your scene, this is another Unity component which shows a simple UI for creating and joining sessions. Dissonance needs two network channels to send it's data through. On the Network Manager component check the Advanced Configuration checkbox and add two new channels, configure one as Reliable Sequenced and the other as Unreliable . In the Dissonance Hlapi Comms Network inspector check the Reliable Channel and Unreliable Channel fields correspond to the channels numbers in the Network Manager .","title":"Step 1a: Setup Network Manager"},{"location":"Basics/Quick-Start-UNet-HLAPI.html#step-2-add-a-broadcast-trigger","text":"You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.","title":"Step 2: Add a Broadcast Trigger"},{"location":"Basics/Quick-Start-UNet-HLAPI.html#step-3-add-a-receipt-trigger","text":"Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.","title":"Step 3: Add a Receipt Trigger"},{"location":"Basics/Quick-Start-UNet-HLAPI.html#youre-done","text":"Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"You're Done!"},{"location":"Basics/Quick-Start-UNet-LLAPI.html","text":"Quick Start: Dissonance with UNet Low Level API (LLAPI) This Quick Start guide is for those of you integrating Dissonance into a game without piggybacking onto your game's existing networking system. This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/UNet_LLAPI/Demo folder. Step 1: Dissonance Comms Object Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the UNet LLAPI networking script. For this quick start guide, we will also attach transmission and receipt trigger scripts to this object. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/UNet_LLAPI folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: Dissonance Comms and UNetCommsNetwork . Step 2: Configure the Network The UNetCommsNetwork script is responsible for transporting comms traffic for Dissonance across the network. Dissonance manages its own set of sockets for its own client/server network upon which comms data is routed. As the UNet LLAPI does not have any uniform concept of a game session, Dissonance does not automatically know anything about the peers in the game; it needs to be told to start the server on one of the clients, or to connect to the server's IP on the other clients. Starting the Server To start the server, grab a reference to the UNetCommsNetwork script on the Dissonance entity, and call InitializeAsServer . var dissonanceNetwork = GetComponent < UNetCommsNetwork >(); dissonanceNetwork . InitializeAsServer (); Connect to the Server To connect to the server as a client, grab a reference to the UNetCommsNetwork script on the Dissonance entity, and call InitializeAsClient . var dissonanceNetwork = GetComponent < UNetCommsNetwork >(); dissonanceNetwork . InitializeAsClient ( serverIpWithoutPort ); Configuring the port By default, the Dissonance server will listen on (and the client will try to connect to) port 5889 . To change this port, set the Port property on the UNetCommsNetwork before initializing the client or server. This will need to be done on both clients and the server. var dissonanceNetwork = GetComponent < UNetCommsNetwork >(); dissonanceNetwork . Port = 1234 ; dissonanceNetwork . InitializeAsServer (); Note Dissonance does not provide any NAT punch-through tooling. Your game will have to provide means to connect to servers hosted behind NAT. Step 3: Add a Broadcast Trigger You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room. Step 4: Add a Receipt Trigger Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, we will leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room. You're Done! Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"Unity Networking LLAPI (self contained)"},{"location":"Basics/Quick-Start-UNet-LLAPI.html#quick-start-dissonance-with-unet-low-level-api-llapi","text":"This Quick Start guide is for those of you integrating Dissonance into a game without piggybacking onto your game's existing networking system. This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room. Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project. A demo scene for this tutorial can be found in the Dissonance/Integrations/UNet_LLAPI/Demo folder.","title":"Quick Start: Dissonance with UNet Low Level API (LLAPI)"},{"location":"Basics/Quick-Start-UNet-LLAPI.html#step-1-dissonance-comms-object","text":"Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behavior, together with the UNet LLAPI networking script. For this quick start guide, we will also attach transmission and receipt trigger scripts to this object. To place the default Dissonance object into your scene, drag and drop the DissonanceSetup prefab from the Dissonance/Integrations/UNet_LLAPI folder into your scene. Once you have instantiated the DissonanceSetup prefab, you should have an object with two scripts attached: Dissonance Comms and UNetCommsNetwork .","title":"Step 1: Dissonance Comms Object"},{"location":"Basics/Quick-Start-UNet-LLAPI.html#step-2-configure-the-network","text":"The UNetCommsNetwork script is responsible for transporting comms traffic for Dissonance across the network. Dissonance manages its own set of sockets for its own client/server network upon which comms data is routed. As the UNet LLAPI does not have any uniform concept of a game session, Dissonance does not automatically know anything about the peers in the game; it needs to be told to start the server on one of the clients, or to connect to the server's IP on the other clients.","title":"Step 2: Configure the Network"},{"location":"Basics/Quick-Start-UNet-LLAPI.html#starting-the-server","text":"To start the server, grab a reference to the UNetCommsNetwork script on the Dissonance entity, and call InitializeAsServer . var dissonanceNetwork = GetComponent < UNetCommsNetwork >(); dissonanceNetwork . InitializeAsServer ();","title":"Starting the Server"},{"location":"Basics/Quick-Start-UNet-LLAPI.html#connect-to-the-server","text":"To connect to the server as a client, grab a reference to the UNetCommsNetwork script on the Dissonance entity, and call InitializeAsClient . var dissonanceNetwork = GetComponent < UNetCommsNetwork >(); dissonanceNetwork . InitializeAsClient ( serverIpWithoutPort );","title":"Connect to the Server"},{"location":"Basics/Quick-Start-UNet-LLAPI.html#configuring-the-port","text":"By default, the Dissonance server will listen on (and the client will try to connect to) port 5889 . To change this port, set the Port property on the UNetCommsNetwork before initializing the client or server. This will need to be done on both clients and the server. var dissonanceNetwork = GetComponent < UNetCommsNetwork >(); dissonanceNetwork . Port = 1234 ; dissonanceNetwork . InitializeAsServer (); Note Dissonance does not provide any NAT punch-through tooling. Your game will have to provide means to connect to servers hosted behind NAT.","title":"Configuring the port"},{"location":"Basics/Quick-Start-UNet-LLAPI.html#step-3-add-a-broadcast-trigger","text":"You now have a functional Dissonance comms system, but you are not yet transmitting anything. Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1. The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what sitations we should be transmitting and who to, but for this tutorial simply leave the settings at default. The default broadcast trigger configuration includes two settings of note: 1. Transmit on Voice Activation . This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.","title":"Step 3: Add a Broadcast Trigger"},{"location":"Basics/Quick-Start-UNet-LLAPI.html#step-4-add-a-receipt-trigger","text":"Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions. To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object. Again, we will leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.","title":"Step 4: Add a Receipt Trigger"},{"location":"Basics/Quick-Start-UNet-LLAPI.html#youre-done","text":"Congratulations, you have now added voice comms to your game! What to do next? Transmit on key press with Push-to-Talk Set up per-team chat channels Direct message another player Send text chat messages 3D Positional Audio 3D Area Chat Rooms Proximity Chat: Talk to players near each other","title":"You're Done!"},{"location":"Platforms/Android & Oculus Go.html","text":"Android (Including Oculus Go) On Android you must request permission to use the microphone, see the Unity documentation for this here . If you use Android 6.0 or greater and API level 23 or greater there is a runtime permissions system which Unity does not support. However there is some excellent documentation by Oculus on how to build a plugin to request permissions here . ARM64 Dissonance includes ARM64 binaries compatible with Android, these are only enabled in Unity 2018.1+ (Unity 2017.4 does not support ARM64).","title":"Android (Including Oculus Go)"},{"location":"Platforms/Android & Oculus Go.html#android-including-oculus-go","text":"On Android you must request permission to use the microphone, see the Unity documentation for this here . If you use Android 6.0 or greater and API level 23 or greater there is a runtime permissions system which Unity does not support. However there is some excellent documentation by Oculus on how to build a plugin to request permissions here .","title":"Android (Including Oculus Go)"},{"location":"Platforms/Android & Oculus Go.html#arm64","text":"Dissonance includes ARM64 binaries compatible with Android, these are only enabled in Unity 2018.1+ (Unity 2017.4 does not support ARM64).","title":"ARM64"},{"location":"Platforms/Linux.html","text":"Linux Running Dissonance on a Linux PC has no runtime dependencies.","title":"Linux"},{"location":"Platforms/Linux.html#linux","text":"Running Dissonance on a Linux PC has no runtime dependencies.","title":"Linux"},{"location":"Platforms/MacOS.html","text":"MacOS Running Dissonance on MacOS has no runtime dependencies.","title":"MacOS"},{"location":"Platforms/MacOS.html#macos","text":"Running Dissonance on MacOS has no runtime dependencies.","title":"MacOS"},{"location":"Platforms/Magic Leap.html","text":"Magic Leap Dissonance includes support for LuminOS on Magic leap devices. To enable this you must change the import settings of Assets\\Plugins\\Dissonance\\Plugins\\Magic Leap\\libAudioPluginDissonance.so and Assets\\Plugins\\Dissonance\\Plugins\\Android\\libs\\ARM64\\libopus.so to be included in Magic Leap builds. Acoustic Echo Cancellation (AEC) and Noise Suppression (NS) are built into the magic leap device. To prevent interference the Dissonance AEC and NS systems are disabled when deployed to a Magic Leap headset, any configuration settings in Dissonance for these two systems will be ignored.","title":"Magic Leap"},{"location":"Platforms/Magic Leap.html#magic-leap","text":"Dissonance includes support for LuminOS on Magic leap devices. To enable this you must change the import settings of Assets\\Plugins\\Dissonance\\Plugins\\Magic Leap\\libAudioPluginDissonance.so and Assets\\Plugins\\Dissonance\\Plugins\\Android\\libs\\ARM64\\libopus.so to be included in Magic Leap builds. Acoustic Echo Cancellation (AEC) and Noise Suppression (NS) are built into the magic leap device. To prevent interference the Dissonance AEC and NS systems are disabled when deployed to a Magic Leap headset, any configuration settings in Dissonance for these two systems will be ignored.","title":"Magic Leap"},{"location":"Platforms/Windows Desktop.html","text":"Windows (Desktop) To run Dissonance on a Windows PC requires Visual Studio 2015 v140 Redist . It's recommended that you package this with your application and install it as part of your install process.","title":"Windows (Desktop)"},{"location":"Platforms/Windows Desktop.html#windows-desktop","text":"To run Dissonance on a Windows PC requires Visual Studio 2015 v140 Redist . It's recommended that you package this with your application and install it as part of your install process.","title":"Windows (Desktop)"},{"location":"Platforms/Windows UWP & Hololens.html","text":"Windows (UWP/Hololens) To run Dissonance on a Windows PC within a UWP application requires Visual Studio 2017 v141 Redist . It's recommended that you package this with your application and install it as part of your install process.","title":"Windows (UWP/Hololens)"},{"location":"Platforms/Windows UWP & Hololens.html#windows-uwphololens","text":"To run Dissonance on a Windows PC within a UWP application requires Visual Studio 2017 v141 Redist . It's recommended that you package this with your application and install it as part of your install process.","title":"Windows (UWP/Hololens)"},{"location":"Platforms/iOS.html","text":"iOS Running Dissonance on iOS has no runtime dependencies. In the Player Settings for iOS there are four settings relevant to voice chat: Microphone Usage Description : You must enter the reason for accessing the microphone on the iOS device. Prepare iOS for Recording : You must enable this setting to enable low latency audio recording. Mute Other Audio Sources : You may enable this to ensure that background audio does not interfere with voice audio. Force iOS Speakers when Recording : You may enable this to force audio to the speakers even when headphones are plugged in. If this is not enabled all application audio will be played through the call speakers instead of the main speakers as soon as recording starts.","title":"iOS"},{"location":"Platforms/iOS.html#ios","text":"Running Dissonance on iOS has no runtime dependencies. In the Player Settings for iOS there are four settings relevant to voice chat: Microphone Usage Description : You must enter the reason for accessing the microphone on the iOS device. Prepare iOS for Recording : You must enable this setting to enable low latency audio recording. Mute Other Audio Sources : You may enable this to ensure that background audio does not interfere with voice audio. Force iOS Speakers when Recording : You may enable this to force audio to the speakers even when headphones are plugged in. If this is not enabled all application audio will be played through the call speakers instead of the main speakers as soon as recording starts.","title":"iOS"},{"location":"Reference/Audio/VoiceSettings.html","text":"Voice Settings Voice settings is a central place to control various audio settings Dissonance uses. Voice settings can be accessed through Window > Dissonance > Quality Settings . Persistence These settings are serialized into an asset file at Assets/Plugins/Dissonance/Resources/VoiceSettings.asset and are also saved into PlayerPrefs . PlayerPrefs override the values saved in the asset. Because the settings are saved into an asset the values you choose will be built into your game and will be the default values used by all players. Because settings are saved into PlayerPrefs you can expose the settings to end users in your UI and the values will be saved on a per user basis. Frame Size Tiny (10ms) LAN ONLY Small (20ms) Medium (40ms) Large (60ms) This setting determines how much voice data is sent in a single network packet. There is some overhead associated with each individual packet - using larger values will send less packets-per-second and thus reduce CPU load and network usage. However, larger packets introduce more latency (more delay between speaking and hearing). Latency is a very important aspect of perceived voice quality and lowering this will improve the flow of conversations. The Tiny option (10ms packets) is the lowest latency option. However due to the very high rate of packets (100/second) it is not suitable for use over the internet , only use it in a local area network when latency is very important (e.g. shared space VR). Audio Quality Low (~10KB/s) Medium (~17KB/s) High (~24KB/s) This setting determines the bitrate the encoder will target - higher values result in higher audio quality but slightly more CPU load and network usage. Forward Error Correction Forward error correction includes extra information in audio packets when network conditions are bad. When a packet is lost due to bad network conditions the audio decoder can use this extra information in other packets to reconstruct a lower quality version of the lost audio. This can almost completely conceal small amounts of packet loss at the cost of ~10% more data used when bad network conditions are detected. Noise Suppression This setting determines how much noise suppression will be applied to the microphone signal before transmission. Noise in this sense is any sound which is not speech such as computer fans or microphone hiss. Noise suppression will not remove echoes other other voices playing through your speakers. Noise suppression is not perfect and may sometimes distort speech, higher levels will remove more background noise but also risk more distortion of speech. However, the risk is fairly low - the distortion is quite minor and the noise suppressor is adaptive so it will only apply really high noise suppression when there is a lot of background noise. Acoustic Echo Cancellation These settings control the acoustic echo canceller, this observes sounds coming out of the speakers and then attempts to remove these sounds from the microphone signal after a short delay. It automatically calibrates the delay so expect a short period (10-40 seconds) where no echoes will be cancelled, if there is no sounds coming out of the speakers at all (or the microphone is not detecting those sounds) it will not be able to calibrate the delay. Refer to these docs for a tutorial on correctly setting up the acoustic echo canceller. Mobile Echo Cancellation This controls how much the echo canceller tries to cancel echo on mobile devices. Desktop Echo Cancellation This controls how much the echo canceller tries to cancel echo on desktop PCs. Audio Duck Attenuation This controls how much remote voices will be attenuated by (reduced in volume) when the local speaker is transmitting.","title":"Voice Settings"},{"location":"Reference/Audio/VoiceSettings.html#voice-settings","text":"Voice settings is a central place to control various audio settings Dissonance uses. Voice settings can be accessed through Window > Dissonance > Quality Settings .","title":"Voice Settings"},{"location":"Reference/Audio/VoiceSettings.html#persistence","text":"These settings are serialized into an asset file at Assets/Plugins/Dissonance/Resources/VoiceSettings.asset and are also saved into PlayerPrefs . PlayerPrefs override the values saved in the asset. Because the settings are saved into an asset the values you choose will be built into your game and will be the default values used by all players. Because settings are saved into PlayerPrefs you can expose the settings to end users in your UI and the values will be saved on a per user basis.","title":"Persistence"},{"location":"Reference/Audio/VoiceSettings.html#frame-size","text":"Tiny (10ms) LAN ONLY Small (20ms) Medium (40ms) Large (60ms) This setting determines how much voice data is sent in a single network packet. There is some overhead associated with each individual packet - using larger values will send less packets-per-second and thus reduce CPU load and network usage. However, larger packets introduce more latency (more delay between speaking and hearing). Latency is a very important aspect of perceived voice quality and lowering this will improve the flow of conversations. The Tiny option (10ms packets) is the lowest latency option. However due to the very high rate of packets (100/second) it is not suitable for use over the internet , only use it in a local area network when latency is very important (e.g. shared space VR).","title":"Frame Size"},{"location":"Reference/Audio/VoiceSettings.html#audio-quality","text":"Low (~10KB/s) Medium (~17KB/s) High (~24KB/s) This setting determines the bitrate the encoder will target - higher values result in higher audio quality but slightly more CPU load and network usage.","title":"Audio Quality"},{"location":"Reference/Audio/VoiceSettings.html#forward-error-correction","text":"Forward error correction includes extra information in audio packets when network conditions are bad. When a packet is lost due to bad network conditions the audio decoder can use this extra information in other packets to reconstruct a lower quality version of the lost audio. This can almost completely conceal small amounts of packet loss at the cost of ~10% more data used when bad network conditions are detected.","title":"Forward Error Correction"},{"location":"Reference/Audio/VoiceSettings.html#noise-suppression","text":"This setting determines how much noise suppression will be applied to the microphone signal before transmission. Noise in this sense is any sound which is not speech such as computer fans or microphone hiss. Noise suppression will not remove echoes other other voices playing through your speakers. Noise suppression is not perfect and may sometimes distort speech, higher levels will remove more background noise but also risk more distortion of speech. However, the risk is fairly low - the distortion is quite minor and the noise suppressor is adaptive so it will only apply really high noise suppression when there is a lot of background noise.","title":"Noise Suppression"},{"location":"Reference/Audio/VoiceSettings.html#acoustic-echo-cancellation","text":"These settings control the acoustic echo canceller, this observes sounds coming out of the speakers and then attempts to remove these sounds from the microphone signal after a short delay. It automatically calibrates the delay so expect a short period (10-40 seconds) where no echoes will be cancelled, if there is no sounds coming out of the speakers at all (or the microphone is not detecting those sounds) it will not be able to calibrate the delay. Refer to these docs for a tutorial on correctly setting up the acoustic echo canceller.","title":"Acoustic Echo Cancellation"},{"location":"Reference/Audio/VoiceSettings.html#mobile-echo-cancellation","text":"This controls how much the echo canceller tries to cancel echo on mobile devices.","title":"Mobile Echo Cancellation"},{"location":"Reference/Audio/VoiceSettings.html#desktop-echo-cancellation","text":"This controls how much the echo canceller tries to cancel echo on desktop PCs.","title":"Desktop Echo Cancellation"},{"location":"Reference/Audio/VoiceSettings.html#audio-duck-attenuation","text":"This controls how much remote voices will be attenuated by (reduced in volume) when the local speaker is transmitting.","title":"Audio Duck Attenuation"},{"location":"Reference/Components/Dissonance-Comms.html","text":"Dissonance Comms The Dissonance Comms component is the central place to configure Dissonance. There must be an active one within the scene for Dissonance to work. Playback Prefab This is a prefab for the audio playback system. For every remote player who is in the voice session Dissonance will instantiate this prefab, and use it to play the voice from that player. If left blank the default playback prefab included with Dissonance will be used. Read more about the playback prefab and how you can customise it here . Mute This will prevent the local player from sending any voice. Access Tokens This is the set of access tokens which the local player has. Voice Settings Clicking this button opens an inspector where audio settings relating to voice may be changed. Configure Rooms Clicking this button opens an inspector where rooms can be created or deleted. Diagnostic Settings Clicking this button opens an inspector where Dissonance diagnostic settings may be changed (e.g. log levels). Scripting Dissonance Comms is also the central place to access Dissonance from scripts. Readonly Properties IsNetworkInitialised : bool Indicates if the Dissonance network has been successfully initialised yet. Rooms : Rooms An object which exposes various properties and methods to do with rooms the local player is listening to. See further documentation here . PlayerChannels : PlayerChannels An object which exposes various properties and method to do with players the local player is speaking to. See further documentation here . RoomChannels : RoomChannels An object which exposes various properties and methods to do with room the local player is speaking to. See further documentation here . Text : TextChat An object which exposes various properties and methods to do with text chat. See further documentation here . Players : ReadOnlyCollection<VoicePlayerState> A list of VoicePlayerState objects, one for each remote player currently in the session. See further documentation on VoicePlayerState here . TopPrioritySpeaker : ChannelPriority The highest priority of all remote players currently speaking in the session. Tokens : IEnumerable<string> The set of tokens which the local player possesses. MicrophoneCapture : IMicrophoneCapture The microphone capture object which Dissonance is currently using. This may be null if Dissonance has not initialised yet or if the local instance is a dedicated server. Properties LocalPlayerName : String The name of the local player, this will be initialised to a unique ID per player when Dissonance starts. This may not be changed once Dissonance has started. PlayerPriority : ChannelPriority The priority of the local player, if a channel is opened with no priority set this priority will be used as a default. MicrophoneName : string Get or set the name of the microphone to use to capture voice. This may be changed at any time, if the microphone has already begun recording with a different name it will be reset to use the new name. PlaybackPrefab : VoicePlayback Get or set the playback prefab which Dissonance will use to play back remote voices. This may not be changed once Dissonance has started. IsMuted : bool Get or set if the local player is muted (i.e. prevented from sending any voice transmissions). IsDeafened : bool Get or set if the local player is deafened (i.e. prevented from hearing any remote voice transmissions). Events OnPlayerJoinedSession : event Action<VoicePlayerState> This event runs whenever a new player joins the Dissonance voice chat session. It is passed the object which represents the new player. OnPlayerLeftSession : event Action<VoicePlayerState> This event runs whenever a player leaves the Dissonance voice chat session. It is passed the object which represents the player. The object will never be touched by Dissonance again - if the player rejoins a new object will be created for them. OnPlayerStartedSpeaking : event Action<VoicePlayerState> This event runs whenever a remote player begins speaking in a channel which the local player can hear. OnPlayerStoppedSpeaking : event Action<VoicePlayerState> This event runs whenever a remote player stops speaking in all channels which the local player can hear. This may not indicate that the remote player has actually stopped talking completely, it is possible that the local player simply stopped listening. For example if you are listening to Room A and they are talking to Room A and Room B , then when you stop listening to Room A you will receive this event (even though they are still talking to Room B ) because they have stopped speaking from your point of view . OnPlayerEnteredRoom : event Action<VoicePlayerState, string> This event runs whenever a remote player begins listening to a new room. It is passed the object which represents the player and the name of the room. OnPlayerExitedRoom : event Action<VoicePlayerState, string> This event runs whenever a remote player stops listening to a room. It is passed the object which represents the player and the name of the room. LocalPlayerNameChanged : event Action<string> This event runs whenever the local player name is changed. Local player name may only be changed before the DissonanceComms component has been started. TokenAdded : event Action<string> An event which runs whenever a token is added to the local player. TokenRemoved : event Action<string> An event which runs whenever a token is removed from the local player. Methods FindPlayer(string name) : VoicePlayerState Attempt to find the player with the given Dissonance ID. Will return null if no such player can be found. SubcribeToVoiceActivation(IVoiceActivationListener) Subscribes the given listener object to the voice activation detector (VAD) for the local player. When VAD detects speech the VoiceActivationStart method will be called. When the VAD stops detecting speech the VoiceActivationStop method will be called. UnsubscribeFromVoiceActivation(IVoiceActivationListener) Unsubscribes a previously subscribed listener object from the VAD. SubcribeToRecordedAudio(IMicrophoneSubscriber) Subscribes the given listener object to the microphone recorded audio after it has been preprocessed. This will receive all audio recorded by the mic whether or not it is being sent over the network. Use DissonanceComms.RoomChannels.Count and DissonanceComms.PlayerChannels.Count to determine if the audio is being sent anywhere. UnsubscribeFromRecordedAudio(IMicrophoneSubscriber) Unsubscribes a previously subscribed listener object from the microphone audio stream. TrackPlayerPosition(IDissonancePlayer) Begins position tracking for the player represented by the given object. StopTracking(IDissonancePlayer) Stops position tracking for the player represented by the given object. AddToken(string) Adds a token to the local player. RemoveToken(string) : bool Removes a token from the local player and returns a bool indicating if that token was removed. This will return false if the player never had the token in the first place. ContainsToken(string) : bool Returns a boolean value indicating if the local player has the token with the given name. HasAnyToken(TokenSet) : bool Returns a boolean value indicating if the local player has any of the tokens in the given TokenSet.","title":"Dissonance Comms"},{"location":"Reference/Components/Dissonance-Comms.html#dissonance-comms","text":"The Dissonance Comms component is the central place to configure Dissonance. There must be an active one within the scene for Dissonance to work.","title":"Dissonance Comms"},{"location":"Reference/Components/Dissonance-Comms.html#playback-prefab","text":"This is a prefab for the audio playback system. For every remote player who is in the voice session Dissonance will instantiate this prefab, and use it to play the voice from that player. If left blank the default playback prefab included with Dissonance will be used. Read more about the playback prefab and how you can customise it here .","title":"Playback Prefab"},{"location":"Reference/Components/Dissonance-Comms.html#mute","text":"This will prevent the local player from sending any voice.","title":"Mute"},{"location":"Reference/Components/Dissonance-Comms.html#access-tokens","text":"This is the set of access tokens which the local player has.","title":"Access Tokens"},{"location":"Reference/Components/Dissonance-Comms.html#voice-settings","text":"Clicking this button opens an inspector where audio settings relating to voice may be changed.","title":"Voice Settings"},{"location":"Reference/Components/Dissonance-Comms.html#configure-rooms","text":"Clicking this button opens an inspector where rooms can be created or deleted.","title":"Configure Rooms"},{"location":"Reference/Components/Dissonance-Comms.html#diagnostic-settings","text":"Clicking this button opens an inspector where Dissonance diagnostic settings may be changed (e.g. log levels).","title":"Diagnostic Settings"},{"location":"Reference/Components/Dissonance-Comms.html#scripting","text":"Dissonance Comms is also the central place to access Dissonance from scripts.","title":"Scripting"},{"location":"Reference/Components/Dissonance-Comms.html#readonly-properties","text":"","title":"Readonly Properties"},{"location":"Reference/Components/Dissonance-Comms.html#isnetworkinitialised-bool","text":"Indicates if the Dissonance network has been successfully initialised yet.","title":"IsNetworkInitialised : bool"},{"location":"Reference/Components/Dissonance-Comms.html#rooms-rooms","text":"An object which exposes various properties and methods to do with rooms the local player is listening to. See further documentation here .","title":"Rooms : Rooms"},{"location":"Reference/Components/Dissonance-Comms.html#playerchannels-playerchannels","text":"An object which exposes various properties and method to do with players the local player is speaking to. See further documentation here .","title":"PlayerChannels : PlayerChannels"},{"location":"Reference/Components/Dissonance-Comms.html#roomchannels-roomchannels","text":"An object which exposes various properties and methods to do with room the local player is speaking to. See further documentation here .","title":"RoomChannels : RoomChannels"},{"location":"Reference/Components/Dissonance-Comms.html#text-textchat","text":"An object which exposes various properties and methods to do with text chat. See further documentation here .","title":"Text : TextChat"},{"location":"Reference/Components/Dissonance-Comms.html#players-readonlycollectionvoiceplayerstate","text":"A list of VoicePlayerState objects, one for each remote player currently in the session. See further documentation on VoicePlayerState here .","title":"Players : ReadOnlyCollection&lt;VoicePlayerState&gt;"},{"location":"Reference/Components/Dissonance-Comms.html#toppriorityspeaker-channelpriority","text":"The highest priority of all remote players currently speaking in the session.","title":"TopPrioritySpeaker : ChannelPriority"},{"location":"Reference/Components/Dissonance-Comms.html#tokens-ienumerablestring","text":"The set of tokens which the local player possesses.","title":"Tokens : IEnumerable&lt;string&gt;"},{"location":"Reference/Components/Dissonance-Comms.html#microphonecapture-imicrophonecapture","text":"The microphone capture object which Dissonance is currently using. This may be null if Dissonance has not initialised yet or if the local instance is a dedicated server.","title":"MicrophoneCapture : IMicrophoneCapture"},{"location":"Reference/Components/Dissonance-Comms.html#properties","text":"","title":"Properties"},{"location":"Reference/Components/Dissonance-Comms.html#localplayername-string","text":"The name of the local player, this will be initialised to a unique ID per player when Dissonance starts. This may not be changed once Dissonance has started.","title":"LocalPlayerName : String"},{"location":"Reference/Components/Dissonance-Comms.html#playerpriority-channelpriority","text":"The priority of the local player, if a channel is opened with no priority set this priority will be used as a default.","title":"PlayerPriority : ChannelPriority"},{"location":"Reference/Components/Dissonance-Comms.html#microphonename-string","text":"Get or set the name of the microphone to use to capture voice. This may be changed at any time, if the microphone has already begun recording with a different name it will be reset to use the new name.","title":"MicrophoneName : string"},{"location":"Reference/Components/Dissonance-Comms.html#playbackprefab-voiceplayback","text":"Get or set the playback prefab which Dissonance will use to play back remote voices. This may not be changed once Dissonance has started.","title":"PlaybackPrefab : VoicePlayback"},{"location":"Reference/Components/Dissonance-Comms.html#ismuted-bool","text":"Get or set if the local player is muted (i.e. prevented from sending any voice transmissions).","title":"IsMuted : bool"},{"location":"Reference/Components/Dissonance-Comms.html#isdeafened-bool","text":"Get or set if the local player is deafened (i.e. prevented from hearing any remote voice transmissions).","title":"IsDeafened : bool"},{"location":"Reference/Components/Dissonance-Comms.html#events","text":"","title":"Events"},{"location":"Reference/Components/Dissonance-Comms.html#onplayerjoinedsession-event-actionvoiceplayerstate","text":"This event runs whenever a new player joins the Dissonance voice chat session. It is passed the object which represents the new player.","title":"OnPlayerJoinedSession : event Action&lt;VoicePlayerState&gt;"},{"location":"Reference/Components/Dissonance-Comms.html#onplayerleftsession-event-actionvoiceplayerstate","text":"This event runs whenever a player leaves the Dissonance voice chat session. It is passed the object which represents the player. The object will never be touched by Dissonance again - if the player rejoins a new object will be created for them.","title":"OnPlayerLeftSession : event Action&lt;VoicePlayerState&gt;"},{"location":"Reference/Components/Dissonance-Comms.html#onplayerstartedspeaking-event-actionvoiceplayerstate","text":"This event runs whenever a remote player begins speaking in a channel which the local player can hear.","title":"OnPlayerStartedSpeaking : event Action&lt;VoicePlayerState&gt;"},{"location":"Reference/Components/Dissonance-Comms.html#onplayerstoppedspeaking-event-actionvoiceplayerstate","text":"This event runs whenever a remote player stops speaking in all channels which the local player can hear. This may not indicate that the remote player has actually stopped talking completely, it is possible that the local player simply stopped listening. For example if you are listening to Room A and they are talking to Room A and Room B , then when you stop listening to Room A you will receive this event (even though they are still talking to Room B ) because they have stopped speaking from your point of view .","title":"OnPlayerStoppedSpeaking : event Action&lt;VoicePlayerState&gt;"},{"location":"Reference/Components/Dissonance-Comms.html#onplayerenteredroom-event-actionvoiceplayerstate-string","text":"This event runs whenever a remote player begins listening to a new room. It is passed the object which represents the player and the name of the room.","title":"OnPlayerEnteredRoom : event Action&lt;VoicePlayerState, string&gt;"},{"location":"Reference/Components/Dissonance-Comms.html#onplayerexitedroom-event-actionvoiceplayerstate-string","text":"This event runs whenever a remote player stops listening to a room. It is passed the object which represents the player and the name of the room.","title":"OnPlayerExitedRoom : event Action&lt;VoicePlayerState, string&gt;"},{"location":"Reference/Components/Dissonance-Comms.html#localplayernamechanged-event-actionstring","text":"This event runs whenever the local player name is changed. Local player name may only be changed before the DissonanceComms component has been started.","title":"LocalPlayerNameChanged : event Action&lt;string&gt;"},{"location":"Reference/Components/Dissonance-Comms.html#tokenadded-event-actionstring","text":"An event which runs whenever a token is added to the local player.","title":"TokenAdded : event Action&lt;string&gt;"},{"location":"Reference/Components/Dissonance-Comms.html#tokenremoved-event-actionstring","text":"An event which runs whenever a token is removed from the local player.","title":"TokenRemoved : event Action&lt;string&gt;"},{"location":"Reference/Components/Dissonance-Comms.html#methods","text":"","title":"Methods"},{"location":"Reference/Components/Dissonance-Comms.html#findplayerstring-name-voiceplayerstate","text":"Attempt to find the player with the given Dissonance ID. Will return null if no such player can be found.","title":"FindPlayer(string name) : VoicePlayerState"},{"location":"Reference/Components/Dissonance-Comms.html#subcribetovoiceactivationivoiceactivationlistener","text":"Subscribes the given listener object to the voice activation detector (VAD) for the local player. When VAD detects speech the VoiceActivationStart method will be called. When the VAD stops detecting speech the VoiceActivationStop method will be called.","title":"SubcribeToVoiceActivation(IVoiceActivationListener)"},{"location":"Reference/Components/Dissonance-Comms.html#unsubscribefromvoiceactivationivoiceactivationlistener","text":"Unsubscribes a previously subscribed listener object from the VAD.","title":"UnsubscribeFromVoiceActivation(IVoiceActivationListener)"},{"location":"Reference/Components/Dissonance-Comms.html#subcribetorecordedaudioimicrophonesubscriber","text":"Subscribes the given listener object to the microphone recorded audio after it has been preprocessed. This will receive all audio recorded by the mic whether or not it is being sent over the network. Use DissonanceComms.RoomChannels.Count and DissonanceComms.PlayerChannels.Count to determine if the audio is being sent anywhere.","title":"SubcribeToRecordedAudio(IMicrophoneSubscriber)"},{"location":"Reference/Components/Dissonance-Comms.html#unsubscribefromrecordedaudioimicrophonesubscriber","text":"Unsubscribes a previously subscribed listener object from the microphone audio stream.","title":"UnsubscribeFromRecordedAudio(IMicrophoneSubscriber)"},{"location":"Reference/Components/Dissonance-Comms.html#trackplayerpositionidissonanceplayer","text":"Begins position tracking for the player represented by the given object.","title":"TrackPlayerPosition(IDissonancePlayer)"},{"location":"Reference/Components/Dissonance-Comms.html#stoptrackingidissonanceplayer","text":"Stops position tracking for the player represented by the given object.","title":"StopTracking(IDissonancePlayer)"},{"location":"Reference/Components/Dissonance-Comms.html#addtokenstring","text":"Adds a token to the local player.","title":"AddToken(string)"},{"location":"Reference/Components/Dissonance-Comms.html#removetokenstring-bool","text":"Removes a token from the local player and returns a bool indicating if that token was removed. This will return false if the player never had the token in the first place.","title":"RemoveToken(string) : bool"},{"location":"Reference/Components/Dissonance-Comms.html#containstokenstring-bool","text":"Returns a boolean value indicating if the local player has the token with the given name.","title":"ContainsToken(string) : bool"},{"location":"Reference/Components/Dissonance-Comms.html#hasanytokentokenset-bool","text":"Returns a boolean value indicating if the local player has any of the tokens in the given TokenSet.","title":"HasAnyToken(TokenSet) : bool"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html","text":"Voice Broadcast Trigger The Voice Broadcast Trigger controls when and where the local voice data is sent to. Channel Type This section controls which channel voice data will be sent to with this trigger. There are three channel type options, which one you choose will change the rest of the channel type UI to match. Channel type can be set from scripts by modifying the ChannelType property. Channel Type : Room When using the \"Room\" channel type broadcaster sends voice to the specified room (a single room may have multiple speakers and multiple listeners). Available rooms are listed in a dropdown box and new rooms may be added by clicking the \"Config Rooms\" button. The target room name can be set from scripts by modifying the RoomName property. Channel Type : Player When set to \"Player\" the broadcaster sends voice directly to the specified player. The inspector will show a text box to enter the name of the player to send to. The target player name can be configured from a script by modifying the PlayerId field. To get the names of other players inspect the Dissonance Comms component at runtime - when in a session it will show a list of all players in the session. To get the name of players by script enumerate the DissonanceComms:Players property. Channel Type : Self If you have set up Position Tracking then your player object will have an IDissonancePlayer component which identifies it to Dissonance. You can take advantage of this to send directly to players without having to know their name. When set to \"Self\" the broadcast component will look for an IDissonancePlayer component in this gameobject or any ancestor and will send directly to that player. Channel Metadata This section controls which metadata is sent along with the channel. Use Positional Data This determines whether the playback of the data sent through this broadcaster should use 3D audio playback (i.e. voice will sound as if it is coming from a certain position in space). Positional audio requires some additional setup (but does not use any additional CPU or network bandwidth at all when enabled). See the Position Tracking tutorial for information about how to set up your project for position tracking of player objects. This option can be set from a script by modifying the BroadcastPosition field. Priority This determines the priority which this voice has for playback. Everyone who receives audio will compare the priority of all the audio streams they are receiving and will only play out the streams with the highest priority. \"None\" is a special value which indicates that this broadcast trigger is setting no particular priority - the default priority for this player will be used instead. The default priority is set on the DissonanceComms component with the PlayerPriority property (if you do not set it it will have the priority Default ). The priority values have this order: Low Default Medium High IsMuted : bool When set to true this trigger will never activate. This can be used to create a UI push-to-talk activated broadcast trigger - set the Activation Mode to Voice Activation and toggle the IsMuted property with a button. When muted by the UI no voice will be sent, when unmuted the trigger will automatically transmit when speech is detected. Activation Mode This section controls how the broadcast trigger decides when to send voice. There are three activation options, which one you choose will change the rest of the activation mode UI to match. Activation mode can be set from scripts by modifying the Mode property. Activation Mode : None When set to \"None\" the broadcaster will never broadcast any voice. ActivationMode : Voice Activation When set to \"Voice Activation\" the broadcaster will automatically transmit when voice is detected in the microphone signal. ActivationMode : Push To Talk When set to \"Push To Talk\" the broadcaster will transmit when a given input axis is chosen. You must set the name of a Unity input axis and then configure it in the Unity input manager. Collider Volume Activation Using collider volume activation requires Position Tracking to be set up. When active the broadcast trigger will find a sibling physics trigger volume and will only send voice if the local player (as defined by the IDissonancePlayer component) is inside the volume. Access Tokens This section controls which Access Tokens are required to send with this broadcaster. The DissonanceComms component keeps a set of tokens which the local player has. The broadcast trigger will only send voice if the player has one or more of the necessary tokens. Amplitude Faders This section controls the amplitude and soft fading of voice sent with this trigger. \"PushToTalk Fade\" (precise name depends upon which activation mode you have chosen) applies a soft fade in and out every time speech is started or stopped (e.g. every time the push to talk key is pressed or released). This setting should be used with care; applying any fade in is inadvisable as it will cut off the start of what is being said. This fader can be configured from scripts by accessing the ActivationFader property. \"Volume Trigger Fade\" (only available when volume trigger is in use) applies a soft fade every time the player enters or exits the volume. This fader can be configured from scripts by accessing the ColliderTriggerFader property. Since there are two faders this means the trigger will have two different volumes to use, they will be multiplied together and the result is used as the actual volume value. Channel Volume This controls the maximum volume of the fader. This should be used with care; raising the amplification above one will cause clipping, which severely reduces audio quality. Fade In Time This controls how long it takes this fader to increase volume from 0 to the Channel Volume slider level. Fade Out Time This controls how long it takes this fader to decrease volume from Channel Volume slider level to 0. Note that this means voice will continue to be transmitted for this long even after the user has stopped pressing the push to talk key.","title":"Voice Broadcast Trigger"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#voice-broadcast-trigger","text":"The Voice Broadcast Trigger controls when and where the local voice data is sent to.","title":"Voice Broadcast Trigger"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#channel-type","text":"This section controls which channel voice data will be sent to with this trigger. There are three channel type options, which one you choose will change the rest of the channel type UI to match. Channel type can be set from scripts by modifying the ChannelType property.","title":"Channel Type"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#channel-type-room","text":"When using the \"Room\" channel type broadcaster sends voice to the specified room (a single room may have multiple speakers and multiple listeners). Available rooms are listed in a dropdown box and new rooms may be added by clicking the \"Config Rooms\" button. The target room name can be set from scripts by modifying the RoomName property.","title":"Channel Type : Room"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#channel-type-player","text":"When set to \"Player\" the broadcaster sends voice directly to the specified player. The inspector will show a text box to enter the name of the player to send to. The target player name can be configured from a script by modifying the PlayerId field. To get the names of other players inspect the Dissonance Comms component at runtime - when in a session it will show a list of all players in the session. To get the name of players by script enumerate the DissonanceComms:Players property.","title":"Channel Type : Player"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#channel-type-self","text":"If you have set up Position Tracking then your player object will have an IDissonancePlayer component which identifies it to Dissonance. You can take advantage of this to send directly to players without having to know their name. When set to \"Self\" the broadcast component will look for an IDissonancePlayer component in this gameobject or any ancestor and will send directly to that player.","title":"Channel Type : Self"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#channel-metadata","text":"This section controls which metadata is sent along with the channel.","title":"Channel Metadata"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#use-positional-data","text":"This determines whether the playback of the data sent through this broadcaster should use 3D audio playback (i.e. voice will sound as if it is coming from a certain position in space). Positional audio requires some additional setup (but does not use any additional CPU or network bandwidth at all when enabled). See the Position Tracking tutorial for information about how to set up your project for position tracking of player objects. This option can be set from a script by modifying the BroadcastPosition field.","title":"Use Positional Data"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#priority","text":"This determines the priority which this voice has for playback. Everyone who receives audio will compare the priority of all the audio streams they are receiving and will only play out the streams with the highest priority. \"None\" is a special value which indicates that this broadcast trigger is setting no particular priority - the default priority for this player will be used instead. The default priority is set on the DissonanceComms component with the PlayerPriority property (if you do not set it it will have the priority Default ). The priority values have this order: Low Default Medium High","title":"Priority"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#ismuted-bool","text":"When set to true this trigger will never activate. This can be used to create a UI push-to-talk activated broadcast trigger - set the Activation Mode to Voice Activation and toggle the IsMuted property with a button. When muted by the UI no voice will be sent, when unmuted the trigger will automatically transmit when speech is detected.","title":"IsMuted : bool"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#activation-mode","text":"This section controls how the broadcast trigger decides when to send voice. There are three activation options, which one you choose will change the rest of the activation mode UI to match. Activation mode can be set from scripts by modifying the Mode property.","title":"Activation Mode"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#activation-mode-none","text":"When set to \"None\" the broadcaster will never broadcast any voice.","title":"Activation Mode : None"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#activationmode-voice-activation","text":"When set to \"Voice Activation\" the broadcaster will automatically transmit when voice is detected in the microphone signal.","title":"ActivationMode : Voice Activation"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#activationmode-push-to-talk","text":"When set to \"Push To Talk\" the broadcaster will transmit when a given input axis is chosen. You must set the name of a Unity input axis and then configure it in the Unity input manager.","title":"ActivationMode : Push To Talk"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#collider-volume-activation","text":"Using collider volume activation requires Position Tracking to be set up. When active the broadcast trigger will find a sibling physics trigger volume and will only send voice if the local player (as defined by the IDissonancePlayer component) is inside the volume.","title":"Collider Volume Activation"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#access-tokens","text":"This section controls which Access Tokens are required to send with this broadcaster. The DissonanceComms component keeps a set of tokens which the local player has. The broadcast trigger will only send voice if the player has one or more of the necessary tokens.","title":"Access Tokens"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#amplitude-faders","text":"This section controls the amplitude and soft fading of voice sent with this trigger. \"PushToTalk Fade\" (precise name depends upon which activation mode you have chosen) applies a soft fade in and out every time speech is started or stopped (e.g. every time the push to talk key is pressed or released). This setting should be used with care; applying any fade in is inadvisable as it will cut off the start of what is being said. This fader can be configured from scripts by accessing the ActivationFader property. \"Volume Trigger Fade\" (only available when volume trigger is in use) applies a soft fade every time the player enters or exits the volume. This fader can be configured from scripts by accessing the ColliderTriggerFader property. Since there are two faders this means the trigger will have two different volumes to use, they will be multiplied together and the result is used as the actual volume value.","title":"Amplitude Faders"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#channel-volume","text":"This controls the maximum volume of the fader. This should be used with care; raising the amplification above one will cause clipping, which severely reduces audio quality.","title":"Channel Volume"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#fade-in-time","text":"This controls how long it takes this fader to increase volume from 0 to the Channel Volume slider level.","title":"Fade In Time"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#fade-out-time","text":"This controls how long it takes this fader to decrease volume from Channel Volume slider level to 0. Note that this means voice will continue to be transmitted for this long even after the user has stopped pressing the push to talk key.","title":"Fade Out Time"},{"location":"Reference/Components/Voice-Receipt-Trigger.html","text":"Voice Receipt Trigger The Voice Receipt Trigger controls which rooms are being listened to by the local player. Trigger Activation This determines whether the receiver will only receive when the local player is within a trigger zone. See the Unity documentation on Trigger Zones . Using trigger activation requires the same basic setup as using Positional Audio . This setting can be configured from a script by modifying the UseTrigger field. Chat Room Determines which room this receiver is for. Available rooms are listed in a dropdown box and new rooms may be added by clicking the \"Config Rooms\" button. The target room name can be configured from a script by modifying the RoomName field.","title":"Voice Receipt Trigger"},{"location":"Reference/Components/Voice-Receipt-Trigger.html#voice-receipt-trigger","text":"The Voice Receipt Trigger controls which rooms are being listened to by the local player.","title":"Voice Receipt Trigger"},{"location":"Reference/Components/Voice-Receipt-Trigger.html#trigger-activation","text":"This determines whether the receiver will only receive when the local player is within a trigger zone. See the Unity documentation on Trigger Zones . Using trigger activation requires the same basic setup as using Positional Audio . This setting can be configured from a script by modifying the UseTrigger field.","title":"Trigger Activation"},{"location":"Reference/Components/Voice-Receipt-Trigger.html#chat-room","text":"Determines which room this receiver is for. Available rooms are listed in a dropdown box and new rooms may be added by clicking the \"Config Rooms\" button. The target room name can be configured from a script by modifying the RoomName field.","title":"Chat Room"},{"location":"Reference/Networking/Network-Protocol.html","text":"Network Format The Dissonance network system manages three main bits of data: Who is in the session Who is listening to which rooms Voice packets This document will give you an overview of how the Dissonance network system manages this data. To see the exact packet format look at PacketWriter.cs and PacketReader.cs in the Dissonance package, these structs have a method for writing/reading each different packet type. Knowledge of the network format is not necessary to work with Dissonance in most cases . This documentation is only required if you want to interact with Dissonance over the network from your own non-Unity code. For example writing a Dissonance server in another language to host separately from Unity. Terminology Peer Every different machine in the session is a peer. This include both the server and the client. Client A client is a peer which is recording and playing voice. Server The server is peer in the session which manages the organisation of the session, e.g. assigning unique ID numbers to peers when they join. All non-voice packets are sent to the server. The server can be running in 2 modes. A host is a peer which is both a client and a server. A dedicated server is a pure server (i.e. no audio capture or playback). Reliable Some packets are sent reliably . This means that the packets will arrive at their destination in the order they were sent, there are no lost packets. This is used for all non-voice packets. Unreliable Some packets are sent unreliably . This means that the packets may be lost in transport or arrive in a different order. This is always used for voice packets. Frame Audio is recorded, processed and played back in frames , this is a buffer of 10-40ms of audio. Every frame is packed into a single network packet. Room A room is a type of channel which requires the listener to explicitly subscribe to the room to hear any audio sent to that room. Rooms have a name (a string) but on the network rooms are generally referred to by a 16 bit ID which is calculated by the ToRoomId(string name) method. Packet Header All packets contain a header which is used to check that the packet is valid. The first 16 bits of every Dissonance packet are a 16 bit magic number 0x8bc7 . This is read from the start of the packet and if it's incorrect the packet is immediately discarded. If something goes wrong and non-Dissonance packets are sent to Dissonance this prevents them from being decoded. The next 8 bytes are the packet type, this tells Dissonance how the contents of the packet should be decoded. The values used for this are defined in MessageTypes.cs . After that all packets (except HandshakeRequest ) have the 32 bit session number, this is a unique number randomly generated by the server when it starts a new session. If the session number does not match the packet is immediately discarded. If something goes wrong and packets from one Dissonance session are sent to another Dissonance session this prevents them from being decoded. Kicking From A Session If a packet with an incorrect session number is received by the server it will send back an ErrorWrongSession packet to the client which contains the session number being used by the server. If the client is not using this session number it will disconnect and reconnect to the server. Joining A Session A new client sends a HandshakeRequest message to the server. This tells the server the codec settings in use by this client as well as it's name. The server replies with a HandshakeResponse message. This sends the complete state of the server to the client: the session ID. A unique value prepended to all packets. The client ID. A unique 16 bit ID for this client. Client list. A list of all other clients in the session (name, codec setting, unique ID). Room list. A list of the room names which at least one client is currently listening to. Listeners list. A list of clients and the rooms which they are currently listening to. The client replies with a ClientState message. This tells the server the complete state of the client: Name Client ID Codec Settings Rooms list. A list of the rooms this client is currently listening to. Joining Or Leaving A Room The server maintains a list of which rooms every client is currently listening to. Sending a complete ClientState message every time a client join or leaves a room would be wasteful, instead a DeltaClientState message is sent. This contains: Flag indicating joining or leaving Client ID Room name Replicating Data The update messages ClientState and DeltaClientState are sent from clients to the server, which updates it's internal state. The server also broadcasts these messages out to all clients which update their own state. This means that every client has exactly the same list of who is listening to which rooms. Peer To Peer It's possible for peers to communicate directly. When this is setup the metadata messages are still sent to the server but voice packets are sent directly from one client to another. To set this up a client sends a HandshakeP2P message to every peer which it knows how to directly contact. The HandshakeP2P message contains the ID of the sending client. When a client receives a HandshakeP2P message from another client it can take note of the connection which that message came through, send back a HandshakeP2P message in response over that connection, and now the two peers can communicate directly. Voice Packets Each client records audio, preprocesses it to improve audio quality, encodes it (using opus) and then sends the packet. The client decides who to send the packet to based on it's knowledge of who is listening to what. The client sends the voice packet via P2P to as many client as possible. The remaining packets are relayed via the server. The VoiceData packet contains: Sender Client ID 8 bit bitfield of packet flags. Currently 2 bits are used for the \"channel session\" and the other bits are unused. Sequence number. A number which can be used to put packets into the correct order. A list of channels which this voice is addressed to. For each channel: 16 bit channel bitfield 16 Bit channel ID A frame of encoded audio Relayed Packets When packets cannot be sent directly with P2P they can be relayed via the server. The ServerRelayReliable and ServerRelayUnreliable packets are used for this purpose. These packets contain a list of destination client IDs and then an array of bytes. When the server receives one of these packets it sends the array of bytes out to all of the listed clients. The server will discard attempts to relay HandshakeP2P packets. Text Packets Text packets can be sent through the Dissonance session, unlike voice they are always relayed via the server. The TextData packet contains: Recipient type. This indicates if the packet is targeted at a player or a room. Sender ID. Client ID of the sender. Recipient ID. This is either a room ID or a client ID, depending upon the recipient type. A string of UTF8 encoded text. Leaving A Session When a client leaves the session the server sends a RemoveClient message out to all clients. This simply contains the ID of the client which is leaving the session.","title":"Network Protocol"},{"location":"Reference/Networking/Network-Protocol.html#network-format","text":"The Dissonance network system manages three main bits of data: Who is in the session Who is listening to which rooms Voice packets This document will give you an overview of how the Dissonance network system manages this data. To see the exact packet format look at PacketWriter.cs and PacketReader.cs in the Dissonance package, these structs have a method for writing/reading each different packet type. Knowledge of the network format is not necessary to work with Dissonance in most cases . This documentation is only required if you want to interact with Dissonance over the network from your own non-Unity code. For example writing a Dissonance server in another language to host separately from Unity.","title":"Network Format"},{"location":"Reference/Networking/Network-Protocol.html#terminology","text":"","title":"Terminology"},{"location":"Reference/Networking/Network-Protocol.html#peer","text":"Every different machine in the session is a peer. This include both the server and the client.","title":"Peer"},{"location":"Reference/Networking/Network-Protocol.html#client","text":"A client is a peer which is recording and playing voice.","title":"Client"},{"location":"Reference/Networking/Network-Protocol.html#server","text":"The server is peer in the session which manages the organisation of the session, e.g. assigning unique ID numbers to peers when they join. All non-voice packets are sent to the server. The server can be running in 2 modes. A host is a peer which is both a client and a server. A dedicated server is a pure server (i.e. no audio capture or playback).","title":"Server"},{"location":"Reference/Networking/Network-Protocol.html#reliable","text":"Some packets are sent reliably . This means that the packets will arrive at their destination in the order they were sent, there are no lost packets. This is used for all non-voice packets.","title":"Reliable"},{"location":"Reference/Networking/Network-Protocol.html#unreliable","text":"Some packets are sent unreliably . This means that the packets may be lost in transport or arrive in a different order. This is always used for voice packets.","title":"Unreliable"},{"location":"Reference/Networking/Network-Protocol.html#frame","text":"Audio is recorded, processed and played back in frames , this is a buffer of 10-40ms of audio. Every frame is packed into a single network packet.","title":"Frame"},{"location":"Reference/Networking/Network-Protocol.html#room","text":"A room is a type of channel which requires the listener to explicitly subscribe to the room to hear any audio sent to that room. Rooms have a name (a string) but on the network rooms are generally referred to by a 16 bit ID which is calculated by the ToRoomId(string name) method.","title":"Room"},{"location":"Reference/Networking/Network-Protocol.html#packet-header","text":"All packets contain a header which is used to check that the packet is valid. The first 16 bits of every Dissonance packet are a 16 bit magic number 0x8bc7 . This is read from the start of the packet and if it's incorrect the packet is immediately discarded. If something goes wrong and non-Dissonance packets are sent to Dissonance this prevents them from being decoded. The next 8 bytes are the packet type, this tells Dissonance how the contents of the packet should be decoded. The values used for this are defined in MessageTypes.cs . After that all packets (except HandshakeRequest ) have the 32 bit session number, this is a unique number randomly generated by the server when it starts a new session. If the session number does not match the packet is immediately discarded. If something goes wrong and packets from one Dissonance session are sent to another Dissonance session this prevents them from being decoded.","title":"Packet Header"},{"location":"Reference/Networking/Network-Protocol.html#kicking-from-a-session","text":"If a packet with an incorrect session number is received by the server it will send back an ErrorWrongSession packet to the client which contains the session number being used by the server. If the client is not using this session number it will disconnect and reconnect to the server.","title":"Kicking From A Session"},{"location":"Reference/Networking/Network-Protocol.html#joining-a-session","text":"A new client sends a HandshakeRequest message to the server. This tells the server the codec settings in use by this client as well as it's name. The server replies with a HandshakeResponse message. This sends the complete state of the server to the client: the session ID. A unique value prepended to all packets. The client ID. A unique 16 bit ID for this client. Client list. A list of all other clients in the session (name, codec setting, unique ID). Room list. A list of the room names which at least one client is currently listening to. Listeners list. A list of clients and the rooms which they are currently listening to. The client replies with a ClientState message. This tells the server the complete state of the client: Name Client ID Codec Settings Rooms list. A list of the rooms this client is currently listening to.","title":"Joining A Session"},{"location":"Reference/Networking/Network-Protocol.html#joining-or-leaving-a-room","text":"The server maintains a list of which rooms every client is currently listening to. Sending a complete ClientState message every time a client join or leaves a room would be wasteful, instead a DeltaClientState message is sent. This contains: Flag indicating joining or leaving Client ID Room name","title":"Joining Or Leaving A Room"},{"location":"Reference/Networking/Network-Protocol.html#replicating-data","text":"The update messages ClientState and DeltaClientState are sent from clients to the server, which updates it's internal state. The server also broadcasts these messages out to all clients which update their own state. This means that every client has exactly the same list of who is listening to which rooms.","title":"Replicating Data"},{"location":"Reference/Networking/Network-Protocol.html#peer-to-peer","text":"It's possible for peers to communicate directly. When this is setup the metadata messages are still sent to the server but voice packets are sent directly from one client to another. To set this up a client sends a HandshakeP2P message to every peer which it knows how to directly contact. The HandshakeP2P message contains the ID of the sending client. When a client receives a HandshakeP2P message from another client it can take note of the connection which that message came through, send back a HandshakeP2P message in response over that connection, and now the two peers can communicate directly.","title":"Peer To Peer"},{"location":"Reference/Networking/Network-Protocol.html#voice-packets","text":"Each client records audio, preprocesses it to improve audio quality, encodes it (using opus) and then sends the packet. The client decides who to send the packet to based on it's knowledge of who is listening to what. The client sends the voice packet via P2P to as many client as possible. The remaining packets are relayed via the server. The VoiceData packet contains: Sender Client ID 8 bit bitfield of packet flags. Currently 2 bits are used for the \"channel session\" and the other bits are unused. Sequence number. A number which can be used to put packets into the correct order. A list of channels which this voice is addressed to. For each channel: 16 bit channel bitfield 16 Bit channel ID A frame of encoded audio","title":"Voice Packets"},{"location":"Reference/Networking/Network-Protocol.html#relayed-packets","text":"When packets cannot be sent directly with P2P they can be relayed via the server. The ServerRelayReliable and ServerRelayUnreliable packets are used for this purpose. These packets contain a list of destination client IDs and then an array of bytes. When the server receives one of these packets it sends the array of bytes out to all of the listed clients. The server will discard attempts to relay HandshakeP2P packets.","title":"Relayed Packets"},{"location":"Reference/Networking/Network-Protocol.html#text-packets","text":"Text packets can be sent through the Dissonance session, unlike voice they are always relayed via the server. The TextData packet contains: Recipient type. This indicates if the packet is targeted at a player or a room. Sender ID. Client ID of the sender. Recipient ID. This is either a room ID or a client ID, depending upon the recipient type. A string of UTF8 encoded text.","title":"Text Packets"},{"location":"Reference/Networking/Network-Protocol.html#leaving-a-session","text":"When a client leaves the session the server sends a RemoveClient message out to all clients. This simply contains the ID of the client which is leaving the session.","title":"Leaving A Session"},{"location":"Reference/Other/PlayerChannel.html","text":"PlayerChannel This object represents a single speech channel directly to another player opened with the PlayerChannels API. The other player will receive the local voice without having to take any action. Dispose() Closes this channel. SubscriptionId : ushort Get the unique ID of this channel. This is only unique among the set of open channels - once this channel is closed the ID may be re-used by another channel. TargetId : string Get the name of the player this channel is sending voice to. IsOpen : bool Get a value indicating if this channel is currently open. Once a channel is closed you should release the channel struct - it is useless (re-opening the channel will create a new PlayerChannel struct). Once IsOpen becomes false then accessing most other properties will immediately throw an exception. Positional : bool Get or set whether audio sent through this channel should use positional playback. If there are multiple channels open sending the same voice then playback will only be positional if all channels are set to use positional playback. Priority : ChannelPriority Get or set the priority of voice sent with this channel. If priority is set to None then it will fall back to using the priority set on the local DissonanceComms component in the PlayerPriority property. If there are multiple channels open sending the same voice data then playback will use the highest priority. Volume : float Get or set the volume to play back the voice sent through this channel. Volume is a direct multiplier on the audio data and should be between 0 and 1. If there are multiple channels open sending the same voice then playback will use the loudest volume.","title":"PlayerChannel"},{"location":"Reference/Other/PlayerChannel.html#playerchannel","text":"This object represents a single speech channel directly to another player opened with the PlayerChannels API. The other player will receive the local voice without having to take any action.","title":"PlayerChannel"},{"location":"Reference/Other/PlayerChannel.html#dispose","text":"Closes this channel.","title":"Dispose()"},{"location":"Reference/Other/PlayerChannel.html#subscriptionid-ushort","text":"Get the unique ID of this channel. This is only unique among the set of open channels - once this channel is closed the ID may be re-used by another channel.","title":"SubscriptionId : ushort"},{"location":"Reference/Other/PlayerChannel.html#targetid-string","text":"Get the name of the player this channel is sending voice to.","title":"TargetId : string"},{"location":"Reference/Other/PlayerChannel.html#isopen-bool","text":"Get a value indicating if this channel is currently open. Once a channel is closed you should release the channel struct - it is useless (re-opening the channel will create a new PlayerChannel struct). Once IsOpen becomes false then accessing most other properties will immediately throw an exception.","title":"IsOpen : bool"},{"location":"Reference/Other/PlayerChannel.html#positional-bool","text":"Get or set whether audio sent through this channel should use positional playback. If there are multiple channels open sending the same voice then playback will only be positional if all channels are set to use positional playback.","title":"Positional : bool"},{"location":"Reference/Other/PlayerChannel.html#priority-channelpriority","text":"Get or set the priority of voice sent with this channel. If priority is set to None then it will fall back to using the priority set on the local DissonanceComms component in the PlayerPriority property. If there are multiple channels open sending the same voice data then playback will use the highest priority.","title":"Priority : ChannelPriority"},{"location":"Reference/Other/PlayerChannel.html#volume-float","text":"Get or set the volume to play back the voice sent through this channel. Volume is a direct multiplier on the audio data and should be between 0 and 1. If there are multiple channels open sending the same voice then playback will use the loudest volume.","title":"Volume : float"},{"location":"Reference/Other/PlayerChannels.html","text":"PlayerChannels This object exposes properties and methods to do with players that the local player is speaking to. Count : int The number of players which the local player is a speaking to. Contains(PlayerChannel) : bool Returns a boolean value indicating if the local player is speaking to the given channel. Open(string, [bool], [ChannelPriority], [float]) : PlayerChannel Opens a channel to begin speaking to the given player and returns a PlayerChannel object which represents this open channel (and can be used to close it). Takes three optional parameters. 1. A boolean value indicating if this channel should use positional playback 2. A ChannelPriority which indicates the priority of this channel 3. A float which indicates the volume to play back this channel with Close(PlayerChannel) : bool Closes the given channel and returns a boolean indicating if the channel was open in the first place.","title":"PlayerChannels"},{"location":"Reference/Other/PlayerChannels.html#playerchannels","text":"This object exposes properties and methods to do with players that the local player is speaking to.","title":"PlayerChannels"},{"location":"Reference/Other/PlayerChannels.html#count-int","text":"The number of players which the local player is a speaking to.","title":"Count : int"},{"location":"Reference/Other/PlayerChannels.html#containsplayerchannel-bool","text":"Returns a boolean value indicating if the local player is speaking to the given channel.","title":"Contains(PlayerChannel) : bool"},{"location":"Reference/Other/PlayerChannels.html#openstring-bool-channelpriority-float-playerchannel","text":"Opens a channel to begin speaking to the given player and returns a PlayerChannel object which represents this open channel (and can be used to close it). Takes three optional parameters. 1. A boolean value indicating if this channel should use positional playback 2. A ChannelPriority which indicates the priority of this channel 3. A float which indicates the volume to play back this channel with","title":"Open(string, [bool], [ChannelPriority], [float]) : PlayerChannel"},{"location":"Reference/Other/PlayerChannels.html#closeplayerchannel-bool","text":"Closes the given channel and returns a boolean indicating if the channel was open in the first place.","title":"Close(PlayerChannel) : bool"},{"location":"Reference/Other/RemoteChannel.html","text":"RemoteChannel A RemoteChannel struct represents a snapshot of information about a channel which a player is speaking through. Read Only Properties Type : ChannelType Get the type of this channel. A channel is either to a Room (in which case the local player will only hear voices if they are subscribed to the Room) or to a player (in which case the appropriate player will hear the voice without needing to subscribe to it). Options : PlaybackOptions Get the PlaybackOptions which have been set for this channel. The actual playback options used are an aggregation of the options set on all the channels the local player is receiving voice from the given player through. Options.IsPositional : bool Get whether this channel should be played with positional audio. Actual audio playback will be positional only if all channels from the given player are set to positional playback. Options.AmplitudeMultiplier : float Get the amplitude multiplier to apply to audio through this channel. The maximum multiplier from all channels from the given player will be used. Options.Priority : ChannelPriority Get the priority of audio through this channel. The maximum priority from all channels from the given player will be used. TargetName : string Get the name of the target of this channel. This is either a room name or a player name, depending upon the Type property.","title":"RemoteChannel"},{"location":"Reference/Other/RemoteChannel.html#remotechannel","text":"A RemoteChannel struct represents a snapshot of information about a channel which a player is speaking through.","title":"RemoteChannel"},{"location":"Reference/Other/RemoteChannel.html#read-only-properties","text":"","title":"Read Only Properties"},{"location":"Reference/Other/RemoteChannel.html#type-channeltype","text":"Get the type of this channel. A channel is either to a Room (in which case the local player will only hear voices if they are subscribed to the Room) or to a player (in which case the appropriate player will hear the voice without needing to subscribe to it).","title":"Type : ChannelType"},{"location":"Reference/Other/RemoteChannel.html#options-playbackoptions","text":"Get the PlaybackOptions which have been set for this channel. The actual playback options used are an aggregation of the options set on all the channels the local player is receiving voice from the given player through.","title":"Options : PlaybackOptions"},{"location":"Reference/Other/RemoteChannel.html#optionsispositional-bool","text":"Get whether this channel should be played with positional audio. Actual audio playback will be positional only if all channels from the given player are set to positional playback.","title":"Options.IsPositional : bool"},{"location":"Reference/Other/RemoteChannel.html#optionsamplitudemultiplier-float","text":"Get the amplitude multiplier to apply to audio through this channel. The maximum multiplier from all channels from the given player will be used.","title":"Options.AmplitudeMultiplier : float"},{"location":"Reference/Other/RemoteChannel.html#optionspriority-channelpriority","text":"Get the priority of audio through this channel. The maximum priority from all channels from the given player will be used.","title":"Options.Priority : ChannelPriority"},{"location":"Reference/Other/RemoteChannel.html#targetname-string","text":"Get the name of the target of this channel. This is either a room name or a player name, depending upon the Type property.","title":"TargetName : string"},{"location":"Reference/Other/RoomChannel.html","text":"RoomChannel This object represents a single speech channel to a room opened with the PlayerChannels API. Other players will only receive the voice if they have joined the room. Dispose() Closes this channel. SubscriptionId : ushort Get the unique ID of this channel. This is only unique among the set of open channels - once this channel is closed the ID may be re-used by another channel. TargetId : string Get the name of the room this channel is sending voice to. IsOpen : bool Get a value indicating if this channel is currently open. Once a channel is closed you should release the channel struct - it is useless (re-opening the channel will create a new PlayerChannel struct). Once IsOpen becomes false then accessing most other properties will immediately throw an exception. Positional : bool Get or set whether audio sent through this channel should use positional playback. If there are multiple channels open sending the same voice then playback will only be positional if all channels are set to use positional playback. Priority : ChannelPriority Get or set the priority of voice sent with this channel. If priority is set to None then it will fall back to using the priority set on the local DissonanceComms component in the PlayerPriority property. If there are multiple channels open sending the same voice data then playback will use the highest priority. Volume : float Get or set the volume to play back the voice sent through this channel. Volume is a direct multiplier on the audio data and should be between 0 and 1. If there are multiple channels open sending the same voice then playback will use the loudest volume.","title":"RoomChannel"},{"location":"Reference/Other/RoomChannel.html#roomchannel","text":"This object represents a single speech channel to a room opened with the PlayerChannels API. Other players will only receive the voice if they have joined the room.","title":"RoomChannel"},{"location":"Reference/Other/RoomChannel.html#dispose","text":"Closes this channel.","title":"Dispose()"},{"location":"Reference/Other/RoomChannel.html#subscriptionid-ushort","text":"Get the unique ID of this channel. This is only unique among the set of open channels - once this channel is closed the ID may be re-used by another channel.","title":"SubscriptionId : ushort"},{"location":"Reference/Other/RoomChannel.html#targetid-string","text":"Get the name of the room this channel is sending voice to.","title":"TargetId : string"},{"location":"Reference/Other/RoomChannel.html#isopen-bool","text":"Get a value indicating if this channel is currently open. Once a channel is closed you should release the channel struct - it is useless (re-opening the channel will create a new PlayerChannel struct). Once IsOpen becomes false then accessing most other properties will immediately throw an exception.","title":"IsOpen : bool"},{"location":"Reference/Other/RoomChannel.html#positional-bool","text":"Get or set whether audio sent through this channel should use positional playback. If there are multiple channels open sending the same voice then playback will only be positional if all channels are set to use positional playback.","title":"Positional : bool"},{"location":"Reference/Other/RoomChannel.html#priority-channelpriority","text":"Get or set the priority of voice sent with this channel. If priority is set to None then it will fall back to using the priority set on the local DissonanceComms component in the PlayerPriority property. If there are multiple channels open sending the same voice data then playback will use the highest priority.","title":"Priority : ChannelPriority"},{"location":"Reference/Other/RoomChannel.html#volume-float","text":"Get or set the volume to play back the voice sent through this channel. Volume is a direct multiplier on the audio data and should be between 0 and 1. If there are multiple channels open sending the same voice then playback will use the loudest volume.","title":"Volume : float"},{"location":"Reference/Other/RoomChannels.html","text":"RoomChannels This object exposes properties and method to do with rooms that the local player is speaking to. For rooms the player is listening to see this documentation intead. Count : int The number of rooms which the local player is a speaking to. Contains(RoomChannel) : bool Returns a boolean value indicating if the local player is speaking to the given channel. Open(string, [bool], [ChannelPriority], [float]) : RoomChannel Opens a channel to begin speaking to the given room and returns a RoomChannel which represents this open channel (and can be used to close it). Takes three optional parameters. 1. A boolean value indicating if this channel should use positional playback 2. A ChannelPriority which indicates the priority of this channel 3. A float which indicates the volume to play back this channel with Close(RoomChannel) : bool Closes the given channel and returns a boolean indicating if the channel was open in the first place.","title":"RoomChannels"},{"location":"Reference/Other/RoomChannels.html#roomchannels","text":"This object exposes properties and method to do with rooms that the local player is speaking to. For rooms the player is listening to see this documentation intead.","title":"RoomChannels"},{"location":"Reference/Other/RoomChannels.html#count-int","text":"The number of rooms which the local player is a speaking to.","title":"Count : int"},{"location":"Reference/Other/RoomChannels.html#containsroomchannel-bool","text":"Returns a boolean value indicating if the local player is speaking to the given channel.","title":"Contains(RoomChannel) : bool"},{"location":"Reference/Other/RoomChannels.html#openstring-bool-channelpriority-float-roomchannel","text":"Opens a channel to begin speaking to the given room and returns a RoomChannel which represents this open channel (and can be used to close it). Takes three optional parameters. 1. A boolean value indicating if this channel should use positional playback 2. A ChannelPriority which indicates the priority of this channel 3. A float which indicates the volume to play back this channel with","title":"Open(string, [bool], [ChannelPriority], [float]) : RoomChannel"},{"location":"Reference/Other/RoomChannels.html#closeroomchannel-bool","text":"Closes the given channel and returns a boolean indicating if the channel was open in the first place.","title":"Close(RoomChannel) : bool"},{"location":"Reference/Other/Rooms.html","text":"Rooms This object exposes properties and method to do with rooms that the local player is listening to. For rooms the player is speaking to see this documentation intead. Count : int The number of rooms which the local player is a listening to. Contains(string) : bool Returns a boolean value indicating if the local player is listening to a room with the given name. Join(string) : RoomMembership Begin listening to the room with the given name. Returns a \"RoomMembership\" object which can be used to stop listening to the room. Leave(RoomMembership) : bool Stop listening to the room represented by the given RoomMembership.","title":"Rooms"},{"location":"Reference/Other/Rooms.html#rooms","text":"This object exposes properties and method to do with rooms that the local player is listening to. For rooms the player is speaking to see this documentation intead.","title":"Rooms"},{"location":"Reference/Other/Rooms.html#count-int","text":"The number of rooms which the local player is a listening to.","title":"Count : int"},{"location":"Reference/Other/Rooms.html#containsstring-bool","text":"Returns a boolean value indicating if the local player is listening to a room with the given name.","title":"Contains(string) : bool"},{"location":"Reference/Other/Rooms.html#joinstring-roommembership","text":"Begin listening to the room with the given name. Returns a \"RoomMembership\" object which can be used to stop listening to the room.","title":"Join(string) : RoomMembership"},{"location":"Reference/Other/Rooms.html#leaveroommembership-bool","text":"Stop listening to the room represented by the given RoomMembership.","title":"Leave(RoomMembership) : bool"},{"location":"Reference/Other/TextChat.html","text":"TextChat This object exposes properties and method to do with text chat within a Dissonance session. Send(string, string) Send a message to the given room. Whisper(string, string) Send a message to the given player. MessageReceived : event Action An event which indicates a text message was received from another player. The TextMessage object contains information about who send the message, how they sent it and what the message is.","title":"TextChat"},{"location":"Reference/Other/TextChat.html#textchat","text":"This object exposes properties and method to do with text chat within a Dissonance session.","title":"TextChat"},{"location":"Reference/Other/TextChat.html#sendstring-string","text":"Send a message to the given room.","title":"Send(string, string)"},{"location":"Reference/Other/TextChat.html#whisperstring-string","text":"Send a message to the given player.","title":"Whisper(string, string)"},{"location":"Reference/Other/TextChat.html#messagereceived-event-action","text":"An event which indicates a text message was received from another player. The TextMessage object contains information about who send the message, how they sent it and what the message is.","title":"MessageReceived : event Action"},{"location":"Reference/Other/VoicePlayerState.html","text":"VoicePlayerState This object exposes properties to do with other players in a Dissonance session. There is one of these objects per player (including the local player) in the Players property on the DissonanceComms component. You can also get one of these objects for a specific player with the FindPlayer method on the DissonanceComms component. //Get your comms component DissonanceComms comms ; //Get a specific player VoicePlayerState player = comms . FindPlayer ( \"Player ID\" ); //Enumerate all players in the session for ( var i = 0 ; i < comms . Players . Count ; i ++) { VoicePlayerState player = comms . Players [ i ]; } Events OnStartedSpeaking : Action<VoicePlayerState> This event is raised every time this player starts speaking. It is passed the state object for this player. VoicePlayerState.OnStartedSpeaking += player =&gt; { Debug.Log(\"Player \" + player.Name + \" Started Speaking\"); } OnStoppedSpeaking : Action<VoicePlayerState> This event is raised every time this player stops speaking. It is passed the state object for this player. VoicePlayerState.OnStoppedSpeaking += player =&gt; { Debug.Log(\"Player \" + player.Name + \" Stopped Speaking\"); } OnEnteredRoom : Action<VoicePlayerState, string> This event is raised every time this player begins listening to a new room. It is passed the state object for this player and the name of the room. VoicePlayerState.OnEnteredRoom += (player, room) =&gt; { Debug.Log(\"Player \" + player.Name + \" began listening to room \" + room); } OnExitedRoom : Action<VoicePlayerState, string> This event is raised every time this player stops listening to a room. It is passed the state object for this player and the name of the room. VoicePlayerState.OnExitedRoom += (player, room) =&gt; { Debug.Log(\"Player \" + player.Name + \" stopped listening to room \" + room); } OnLeftSession : Action<VoicePlayerState> This event is raised when the player leaves the session. After this the session object will never be used again. Even if the same player rejoins with the same name, they will be assigned a new state object. VoicePlayerState.OnLeftSession += player =&gt; { Debug.Log(\"Player \" + player.Name + \" Left Session\"); } Read Only Properties Name : String The name of this player. This is the value in the DissonanceComms:LocalPlayerName property for that player. DissonanceComms comms; VoicePlayerState aPlayer; if (aPlayer.Name == comms.LocalPlayerName) { Debug.Log(aPlayer.Name + \" is the local player\"); } IsConnected : bool Get a value indicating if this player is currently in the session. IsSpeaking : bool Get a value indicating if this player is currently speaking Amplitude : float Get the current amplitude of the speech from this player. Value is in the range of 0 to 1. When using this value remember that 1 is the loudest value that can possibly be produced by the audio system - in most circumstances a speech signal will be very quiet (0 to 0.05 or less). SpeakerPriority : ChannelPriority? Get the current priority of speech from this speaker. Null if the player is not speaking. Rooms : ReadOnlyCollection<string> Get the list of rooms this player is currently listening to. PacketLoss : float? Get the estimated packet loss (0 to 1) to/from this player. May be null if the player has disconnected or packet loss has not yet been measured. Playback : VoicePlayback Get the VoicePlayback component associated with this player. May be null if Dissonance is still setting up playback for this player, or the player has left the session. Tracker : IDissonancePlayer Get the IDissonancePlayer component associated with this player. May be null if Dissonance is still setting up tracking for this player, this player does not have a IDissonancePlayer component, or the player has left the session. Properties Volume : float Get or set the Volume which speech from the player should be played at. The value is a direct multiplier applied to the audio and should be in the range 0 to 1. IsLocallyMuted : bool Get or set if this player is locally muted and will not produce any audio on the local machine. Methods GetSpeakingChannels(channels: List ) Get a snapshot of the channels you are hearing this speaker through. If they are not speaking to you then this will return no results. The channels parameter passed in must not be null, the list will be cleared and then filled with the current snapshot.","title":"VoicePlayerState"},{"location":"Reference/Other/VoicePlayerState.html#voiceplayerstate","text":"This object exposes properties to do with other players in a Dissonance session. There is one of these objects per player (including the local player) in the Players property on the DissonanceComms component. You can also get one of these objects for a specific player with the FindPlayer method on the DissonanceComms component. //Get your comms component DissonanceComms comms ; //Get a specific player VoicePlayerState player = comms . FindPlayer ( \"Player ID\" ); //Enumerate all players in the session for ( var i = 0 ; i < comms . Players . Count ; i ++) { VoicePlayerState player = comms . Players [ i ]; }","title":"VoicePlayerState"},{"location":"Reference/Other/VoicePlayerState.html#events","text":"","title":"Events"},{"location":"Reference/Other/VoicePlayerState.html#onstartedspeaking-actionvoiceplayerstate","text":"This event is raised every time this player starts speaking. It is passed the state object for this player. VoicePlayerState.OnStartedSpeaking += player =&gt; { Debug.Log(\"Player \" + player.Name + \" Started Speaking\"); }","title":"OnStartedSpeaking : Action&lt;VoicePlayerState&gt;"},{"location":"Reference/Other/VoicePlayerState.html#onstoppedspeaking-actionvoiceplayerstate","text":"This event is raised every time this player stops speaking. It is passed the state object for this player. VoicePlayerState.OnStoppedSpeaking += player =&gt; { Debug.Log(\"Player \" + player.Name + \" Stopped Speaking\"); }","title":"OnStoppedSpeaking : Action&lt;VoicePlayerState&gt;"},{"location":"Reference/Other/VoicePlayerState.html#onenteredroom-actionvoiceplayerstate-string","text":"This event is raised every time this player begins listening to a new room. It is passed the state object for this player and the name of the room. VoicePlayerState.OnEnteredRoom += (player, room) =&gt; { Debug.Log(\"Player \" + player.Name + \" began listening to room \" + room); }","title":"OnEnteredRoom : Action&lt;VoicePlayerState, string&gt;"},{"location":"Reference/Other/VoicePlayerState.html#onexitedroom-actionvoiceplayerstate-string","text":"This event is raised every time this player stops listening to a room. It is passed the state object for this player and the name of the room. VoicePlayerState.OnExitedRoom += (player, room) =&gt; { Debug.Log(\"Player \" + player.Name + \" stopped listening to room \" + room); }","title":"OnExitedRoom : Action&lt;VoicePlayerState, string&gt;"},{"location":"Reference/Other/VoicePlayerState.html#onleftsession-actionvoiceplayerstate","text":"This event is raised when the player leaves the session. After this the session object will never be used again. Even if the same player rejoins with the same name, they will be assigned a new state object. VoicePlayerState.OnLeftSession += player =&gt; { Debug.Log(\"Player \" + player.Name + \" Left Session\"); }","title":"OnLeftSession : Action&lt;VoicePlayerState&gt;"},{"location":"Reference/Other/VoicePlayerState.html#read-only-properties","text":"","title":"Read Only Properties"},{"location":"Reference/Other/VoicePlayerState.html#name-string","text":"The name of this player. This is the value in the DissonanceComms:LocalPlayerName property for that player. DissonanceComms comms; VoicePlayerState aPlayer; if (aPlayer.Name == comms.LocalPlayerName) { Debug.Log(aPlayer.Name + \" is the local player\"); }","title":"Name : String"},{"location":"Reference/Other/VoicePlayerState.html#isconnected-bool","text":"Get a value indicating if this player is currently in the session.","title":"IsConnected : bool"},{"location":"Reference/Other/VoicePlayerState.html#isspeaking-bool","text":"Get a value indicating if this player is currently speaking","title":"IsSpeaking : bool"},{"location":"Reference/Other/VoicePlayerState.html#amplitude-float","text":"Get the current amplitude of the speech from this player. Value is in the range of 0 to 1. When using this value remember that 1 is the loudest value that can possibly be produced by the audio system - in most circumstances a speech signal will be very quiet (0 to 0.05 or less).","title":"Amplitude : float"},{"location":"Reference/Other/VoicePlayerState.html#speakerpriority-channelpriority","text":"Get the current priority of speech from this speaker. Null if the player is not speaking.","title":"SpeakerPriority : ChannelPriority?"},{"location":"Reference/Other/VoicePlayerState.html#rooms-readonlycollectionstring","text":"Get the list of rooms this player is currently listening to.","title":"Rooms : ReadOnlyCollection&lt;string&gt;"},{"location":"Reference/Other/VoicePlayerState.html#packetloss-float","text":"Get the estimated packet loss (0 to 1) to/from this player. May be null if the player has disconnected or packet loss has not yet been measured.","title":"PacketLoss : float?"},{"location":"Reference/Other/VoicePlayerState.html#playback-voiceplayback","text":"Get the VoicePlayback component associated with this player. May be null if Dissonance is still setting up playback for this player, or the player has left the session.","title":"Playback : VoicePlayback"},{"location":"Reference/Other/VoicePlayerState.html#tracker-idissonanceplayer","text":"Get the IDissonancePlayer component associated with this player. May be null if Dissonance is still setting up tracking for this player, this player does not have a IDissonancePlayer component, or the player has left the session.","title":"Tracker : IDissonancePlayer"},{"location":"Reference/Other/VoicePlayerState.html#properties","text":"","title":"Properties"},{"location":"Reference/Other/VoicePlayerState.html#volume-float","text":"Get or set the Volume which speech from the player should be played at. The value is a direct multiplier applied to the audio and should be in the range 0 to 1.","title":"Volume : float"},{"location":"Reference/Other/VoicePlayerState.html#islocallymuted-bool","text":"Get or set if this player is locally muted and will not produce any audio on the local machine.","title":"IsLocallyMuted : bool"},{"location":"Reference/Other/VoicePlayerState.html#methods","text":"","title":"Methods"},{"location":"Reference/Other/VoicePlayerState.html#getspeakingchannelschannels-list","text":"Get a snapshot of the channels you are hearing this speaker through. If they are not speaking to you then this will return no results. The channels parameter passed in must not be null, the list will be cleared and then filled with the current snapshot.","title":"GetSpeakingChannels(channels: List)"},{"location":"Tutorials/Access-Control-Tokens.html","text":"Access Control Tokens Also see this video about access tokens. Access control tokens can be added to both Broadcast Triggers and Receipt Triggers . The trigger will not function unless the local player has one of the required tokens. Defining Required Tokens Tokens can be added and removed through the inspector: This receipt trigger will not function unless the local player has one of the two access tokens - 'TopSecretPassword' or 'mysocratesnote'. Tokens can also be managed with scripts: var receiver = FindObjectOfType < VoiceReceiptTrigger >(); receiver . AddToken ( \"correcthorsebatterystaple\" ); // Add if ( receiver . ContainsToken ( \"correcthorsebatterystaple\" )) // Query receiver . RemoveToken ( \"correcthorsebatterystaple\" ); // Remove Defining Available Tokens Once triggers have been configured to require tokens you will need to add some tokens to the local player. This can be done in the inspector in the same way as for triggers. Tokens added in the inspector will apply to all players so they can only be used as the default tokens everyone starts with. You are more likely to want to manage tokens through scripts. When you create a player and do something which requires restricting their access to channels (e.g. joining a team) you should add the appropriate tokens to the local player: var local = FindObjectOfType < DissonanceComms >(); local . AddToken ( \"Green Team\" ); Assuming you have transmitters and receivers set up for every team, each one with a different token, this gives you a simple way to ensure that the player is speaking and listening to the right team channels.","title":"Access Tokens"},{"location":"Tutorials/Access-Control-Tokens.html#access-control-tokens","text":"Also see this video about access tokens. Access control tokens can be added to both Broadcast Triggers and Receipt Triggers . The trigger will not function unless the local player has one of the required tokens.","title":"Access Control Tokens"},{"location":"Tutorials/Access-Control-Tokens.html#defining-required-tokens","text":"Tokens can be added and removed through the inspector: This receipt trigger will not function unless the local player has one of the two access tokens - 'TopSecretPassword' or 'mysocratesnote'. Tokens can also be managed with scripts: var receiver = FindObjectOfType < VoiceReceiptTrigger >(); receiver . AddToken ( \"correcthorsebatterystaple\" ); // Add if ( receiver . ContainsToken ( \"correcthorsebatterystaple\" )) // Query receiver . RemoveToken ( \"correcthorsebatterystaple\" ); // Remove","title":"Defining Required Tokens"},{"location":"Tutorials/Access-Control-Tokens.html#defining-available-tokens","text":"Once triggers have been configured to require tokens you will need to add some tokens to the local player. This can be done in the inspector in the same way as for triggers. Tokens added in the inspector will apply to all players so they can only be used as the default tokens everyone starts with. You are more likely to want to manage tokens through scripts. When you create a player and do something which requires restricting their access to channels (e.g. joining a team) you should add the appropriate tokens to the local player: var local = FindObjectOfType < DissonanceComms >(); local . AddToken ( \"Green Team\" ); Assuming you have transmitters and receivers set up for every team, each one with a different token, this gives you a simple way to ensure that the player is speaking and listening to the right team channels.","title":"Defining Available Tokens"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html","text":"Acoustic Echo Cancellation Requires Dissonance v6.2.0 or greater! When playing audio from speakers and recording audio from a nearby microphone you will often encounter problems when the microphone picks up the audio from the speakers. In a voice session a single person doing this can cause annoying echoes to be transmitted and multiple people doing this simultaneously can cause painful feedback which persists until everyone stops transmitting. This can be particularly problematic when using Voice Activation Detection (VAD) because the VAD automatically transmits back all speech it detects, causing constant echoes of everything other people say. It can also be very bad on platforms where the mic and the speaker are very close together such as VR headsets and mobile phones. Acoustic Echo Cancellation (AEC) is a system to automatically remove these echoes from the transmitted voice signal. How Does AEC Work? Dissonance already runs an audio preprocessor on the microphone signal before it is transmitted, by default this is running Noise Suppression (NS) and Voice Detection (VAD). To enable AEC we introduce a postprocessor which has all game audio passed through it - this postprocessor informs the microphone preprocessor what audio is about to be played through the speakers. With this knowledge the preprocessor can remove the echo signal from the microphone signal when it appears a short time later. Audio Output -&gt; Audio Postprocessor -&gt; Speakers -&gt; Echo -&gt; Microphone -&gt; Audio Preprocessor The most complex part of this system is working out what the delay is between the Audio Postprocessor and the Audio Preprocessor . This is achieved automatically but it is umportant to understand that the AEC system can take several seconds to work out the correct delay value - until it has done this no echo will be cancelled. The AEC cannot be calculating the delay value while there is no sound being played and it will slowly \"forget\" the delay value during periods of silence. In most scenarios this is not a problem - game sound effects and background music will be enough to keep the AEC synchronised with a suitable delay value. However if you are encountering problems with the AEC not working you should consider adding some sound effects for the AEC to process - e.g. a short jingle when a user joins a session, or ringing sound when joining a session. AEC Setup Before starting ensure you are using Dissonance 6.2.0 or greater! 1. Audio Postprocessor The first thing required for the AEC to function is to attach the postprocessor mentioned above to an audio mixer . Attach the Dissonance Echo Cancellation audio filter to the very last audio mixer in the mixing system and disable the Auto Mixer Suspend option for this mixer. If you were not already using audio mixers simply create a new mixer in Window > Audio Mixer and attach the filter to that. 2. Route Non-Voice Audio The filter will only process audio which passes through the mixer it is attached to - how to achieve this depends on what kind of audio mixing system you already had setup before using AEC. If you were already using audio mixers then ensure that all the mixers eventually pass through the filter with the Dissonance Echo Cancellation filter attached. If you were not already using mixers then simply all the AudioSource components you use to output to the new mixer you created in the previous step. You can check that you have done this correctly by running the game and watching the audio mixer window. The dB meter on the mixer should move when non-voice audio is playing. 3. Route Voice Audio Voice audio also needs to be re-routed to pass through the mixer with the filter through the filter. To change where voice audio is sent you need to create a custom playback prefab . Create a prefab with a VoicePlayback component and an AudioSource component. Set the output of the AudioSource to the correct mixer. Finally drop the prefab into the Playback Prefab field of the Dissonance Comms component. If you were already using audio mixers then you may want to consider creating a mixer specifically for voice and outputting this mixer to the root mixer. This will allow you to attach sound effects specifically to voices. If you were not using audio mixers then you should just send the voice data to the mixer you created in step 1. 4. AEC Configuration Now that all the audio is routed to pass through the AEC filter AEC can run. Open the Dissonance quality settings menu Window > Dissonance > Quality Settings to set the amount of echo suppression applied. Desktop platforms and mobile platforms use completely different AEC systems internally and are configured separately. Dissonance will automatically switch to using the mobile AEC (AECM) when a mobile platform is detected. These settings can be set in the editor - they will be saved into an asset and used as the default values at runtime. They can be changed at runtime by accessing the VoiceSettings class: //Change amount of AEC applied on Desktop VoiceSettings . Instance . AecSuppressionAmount = AecSuppressionLevels . Moderate ; //Change amount of AEC applied on Mobile VoiceSettings . Instance . AecmRoutingMode = AecmRoutingMode . Speakerphone ; Only the two settings shown above can be changed while Dissonance is running, doing so will trigger a reset of the audio input system (causing a small hitch in transmitted audio). Changes to any other AEC related settings will be ignored until the next time the audio input system is reset (e.g. by changing the settings above). It is advisable to start with very low AEC settings and ask the user to increase them if echo becomes a problem - excessive levels of AEC can very badly distort voices. 5. Testing AEC Once you have set all of this up you may want to test that AEC is working as intended. To do so simply add an AudioSource component to your scene playing some loud music - make sure it's routed through the correct mixer! Now run the scene in the editor and select the filter attached to the audio mixer, this will show a status screen for the AEC: The second box shows the AEC status. In this image it is showing a warning - if everything is setup correctly it should show AEC filter is running . When the filter first starts all of the numbers shown here will be zero or even negative. This indicates that the filter has not yet converged and will not yet be removing any echo. After a short period of time (5-10 seconds) it should converge and begin removing echoes, if Fraction Poor Delays is more than 0% then the AEC will likely perform very badly. Once the AEC is running and has converged remote speakers in the session should not be able to hear the music you are playing. In our own tests we have had music playing loudly enough to drown out voices but even that was still cancelled! Fixing Audio effect Dissonance Echo Cancellation could not be found. Error iOS To fix this problem on iOS you must manually register the audio effect with the Unity audio pipeline. Download AudioPluginInterface.h from the Unity native audio plugin SDK and add it to your XCode project. add #import \"AudioPluginInterface.h\"; to UnityAppController.mm in XCode. Find the preStartUnity method and add the line UnityRegisterAudioPlugin(&UnityGetAudioEffectDefinitions); If this does not fix the issue, please add a comment to this issue . Android To fix this issue on Android you must re-import the plugin with the correct settings. Remove Assets/Plugins/Dissonance/Plugins/Android/libs/armeabi-v7a/libAudioPluginDissonance.so from the project (ensure that the libAudioPluginDissonance.so.meta is gone). Restart the Unity editor Put libAudioPluginDissonance.so back into the Assets/Plugins/Dissonance/Plugins/Android/libs/armeabi-v7a Configure the import settings: Check that libAudioPluginDissonance.so.meta contains isPreloaded: 1 If this does not fix the problem, please add a comment to this issue .","title":"Acoustic Echo Cancellation"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#acoustic-echo-cancellation","text":"Requires Dissonance v6.2.0 or greater! When playing audio from speakers and recording audio from a nearby microphone you will often encounter problems when the microphone picks up the audio from the speakers. In a voice session a single person doing this can cause annoying echoes to be transmitted and multiple people doing this simultaneously can cause painful feedback which persists until everyone stops transmitting. This can be particularly problematic when using Voice Activation Detection (VAD) because the VAD automatically transmits back all speech it detects, causing constant echoes of everything other people say. It can also be very bad on platforms where the mic and the speaker are very close together such as VR headsets and mobile phones. Acoustic Echo Cancellation (AEC) is a system to automatically remove these echoes from the transmitted voice signal.","title":"Acoustic Echo Cancellation"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#how-does-aec-work","text":"Dissonance already runs an audio preprocessor on the microphone signal before it is transmitted, by default this is running Noise Suppression (NS) and Voice Detection (VAD). To enable AEC we introduce a postprocessor which has all game audio passed through it - this postprocessor informs the microphone preprocessor what audio is about to be played through the speakers. With this knowledge the preprocessor can remove the echo signal from the microphone signal when it appears a short time later. Audio Output -&gt; Audio Postprocessor -&gt; Speakers -&gt; Echo -&gt; Microphone -&gt; Audio Preprocessor The most complex part of this system is working out what the delay is between the Audio Postprocessor and the Audio Preprocessor . This is achieved automatically but it is umportant to understand that the AEC system can take several seconds to work out the correct delay value - until it has done this no echo will be cancelled. The AEC cannot be calculating the delay value while there is no sound being played and it will slowly \"forget\" the delay value during periods of silence. In most scenarios this is not a problem - game sound effects and background music will be enough to keep the AEC synchronised with a suitable delay value. However if you are encountering problems with the AEC not working you should consider adding some sound effects for the AEC to process - e.g. a short jingle when a user joins a session, or ringing sound when joining a session.","title":"How Does AEC Work?"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#aec-setup","text":"Before starting ensure you are using Dissonance 6.2.0 or greater!","title":"AEC Setup"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#1-audio-postprocessor","text":"The first thing required for the AEC to function is to attach the postprocessor mentioned above to an audio mixer . Attach the Dissonance Echo Cancellation audio filter to the very last audio mixer in the mixing system and disable the Auto Mixer Suspend option for this mixer. If you were not already using audio mixers simply create a new mixer in Window > Audio Mixer and attach the filter to that.","title":"1. Audio Postprocessor"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#2-route-non-voice-audio","text":"The filter will only process audio which passes through the mixer it is attached to - how to achieve this depends on what kind of audio mixing system you already had setup before using AEC. If you were already using audio mixers then ensure that all the mixers eventually pass through the filter with the Dissonance Echo Cancellation filter attached. If you were not already using mixers then simply all the AudioSource components you use to output to the new mixer you created in the previous step. You can check that you have done this correctly by running the game and watching the audio mixer window. The dB meter on the mixer should move when non-voice audio is playing.","title":"2. Route Non-Voice Audio"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#3-route-voice-audio","text":"Voice audio also needs to be re-routed to pass through the mixer with the filter through the filter. To change where voice audio is sent you need to create a custom playback prefab . Create a prefab with a VoicePlayback component and an AudioSource component. Set the output of the AudioSource to the correct mixer. Finally drop the prefab into the Playback Prefab field of the Dissonance Comms component. If you were already using audio mixers then you may want to consider creating a mixer specifically for voice and outputting this mixer to the root mixer. This will allow you to attach sound effects specifically to voices. If you were not using audio mixers then you should just send the voice data to the mixer you created in step 1.","title":"3. Route Voice Audio"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#4-aec-configuration","text":"Now that all the audio is routed to pass through the AEC filter AEC can run. Open the Dissonance quality settings menu Window > Dissonance > Quality Settings to set the amount of echo suppression applied. Desktop platforms and mobile platforms use completely different AEC systems internally and are configured separately. Dissonance will automatically switch to using the mobile AEC (AECM) when a mobile platform is detected. These settings can be set in the editor - they will be saved into an asset and used as the default values at runtime. They can be changed at runtime by accessing the VoiceSettings class: //Change amount of AEC applied on Desktop VoiceSettings . Instance . AecSuppressionAmount = AecSuppressionLevels . Moderate ; //Change amount of AEC applied on Mobile VoiceSettings . Instance . AecmRoutingMode = AecmRoutingMode . Speakerphone ; Only the two settings shown above can be changed while Dissonance is running, doing so will trigger a reset of the audio input system (causing a small hitch in transmitted audio). Changes to any other AEC related settings will be ignored until the next time the audio input system is reset (e.g. by changing the settings above). It is advisable to start with very low AEC settings and ask the user to increase them if echo becomes a problem - excessive levels of AEC can very badly distort voices.","title":"4. AEC Configuration"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#5-testing-aec","text":"Once you have set all of this up you may want to test that AEC is working as intended. To do so simply add an AudioSource component to your scene playing some loud music - make sure it's routed through the correct mixer! Now run the scene in the editor and select the filter attached to the audio mixer, this will show a status screen for the AEC: The second box shows the AEC status. In this image it is showing a warning - if everything is setup correctly it should show AEC filter is running . When the filter first starts all of the numbers shown here will be zero or even negative. This indicates that the filter has not yet converged and will not yet be removing any echo. After a short period of time (5-10 seconds) it should converge and begin removing echoes, if Fraction Poor Delays is more than 0% then the AEC will likely perform very badly. Once the AEC is running and has converged remote speakers in the session should not be able to hear the music you are playing. In our own tests we have had music playing loudly enough to drown out voices but even that was still cancelled!","title":"5. Testing AEC"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#fixing-audio-effect-dissonance-echo-cancellation-could-not-be-found-error","text":"","title":"Fixing Audio effect Dissonance Echo Cancellation could not be found. Error"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#ios","text":"To fix this problem on iOS you must manually register the audio effect with the Unity audio pipeline. Download AudioPluginInterface.h from the Unity native audio plugin SDK and add it to your XCode project. add #import \"AudioPluginInterface.h\"; to UnityAppController.mm in XCode. Find the preStartUnity method and add the line UnityRegisterAudioPlugin(&UnityGetAudioEffectDefinitions); If this does not fix the issue, please add a comment to this issue .","title":"iOS"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#android","text":"To fix this issue on Android you must re-import the plugin with the correct settings. Remove Assets/Plugins/Dissonance/Plugins/Android/libs/armeabi-v7a/libAudioPluginDissonance.so from the project (ensure that the libAudioPluginDissonance.so.meta is gone). Restart the Unity editor Put libAudioPluginDissonance.so back into the Assets/Plugins/Dissonance/Plugins/Android/libs/armeabi-v7a Configure the import settings: Check that libAudioPluginDissonance.so.meta contains isPreloaded: 1 If this does not fix the problem, please add a comment to this issue .","title":"Android"},{"location":"Tutorials/Assembly-Definitions.html","text":"Assembly Definitions Using Assembly Definition Files Requires Dissonance 6.2.5 ! The compilation order of scripts in Unity can be controlled by using Assembly Definitions , these files allow you to explicitly split code up into smaller parts and specify the dependencies between those parts. Dissonance does not ship with assembly definitions by default, but it is setup so that assembly definitions can be added if required. After installing Dissonance you need to create 4 assembly definitions. They must have the exact names as shown here: Assets/Plugins/Dissonance/Dissonance.asmdef Assets/Plugins/Dissonance/Editor/DissonanceEditor.asmdef - References: - Dissonance.asmdef Assets/Dissonance/DissonanceIntegrations.asmdef - References: - Dissonance.asmdef In each network integration that you install you must create the final asmdef: Assets/Dissonance/Integrations/{Integration_Name}/Editor/Dissonance{Integration_Name}Editor - References: - Assets/Plugins/Dissonance/Dissonance.asmdef - Assets/Plugins/Dissonance/Editor/DissonanceEditor.asmdef - Assets/Dissonance/DissonanceIntegrations.asmdef","title":"Assembly Definitions"},{"location":"Tutorials/Assembly-Definitions.html#assembly-definitions","text":"Using Assembly Definition Files Requires Dissonance 6.2.5 ! The compilation order of scripts in Unity can be controlled by using Assembly Definitions , these files allow you to explicitly split code up into smaller parts and specify the dependencies between those parts. Dissonance does not ship with assembly definitions by default, but it is setup so that assembly definitions can be added if required. After installing Dissonance you need to create 4 assembly definitions. They must have the exact names as shown here: Assets/Plugins/Dissonance/Dissonance.asmdef Assets/Plugins/Dissonance/Editor/DissonanceEditor.asmdef - References: - Dissonance.asmdef Assets/Dissonance/DissonanceIntegrations.asmdef - References: - Dissonance.asmdef In each network integration that you install you must create the final asmdef: Assets/Dissonance/Integrations/{Integration_Name}/Editor/Dissonance{Integration_Name}Editor - References: - Assets/Plugins/Dissonance/Dissonance.asmdef - Assets/Plugins/Dissonance/Editor/DissonanceEditor.asmdef - Assets/Dissonance/DissonanceIntegrations.asmdef","title":"Assembly Definitions"},{"location":"Tutorials/Audio-Mixing.html","text":"Tutorial: Audio Mixing Also see this video about audio mixing. Dissonance does not have any special support built in for audio mixing, because unity already has a powerful mixing system built in which dissonance audio is routed through. You can find out more about the unity audio mixing system here . This tutorial offers advice about the best way to use the unity audio pipeline for VoIP. General Principles It can be tempting to mix voice signals in the same way as any other audio signal in your game and to add various sound effects to the voice for realism/immersion. Things such as drowning out teammates with loud gunfire, deafening players when they're hit by a flashbang or adding extreme radio fuzz when the enemy team use jammers might all sound immersive but in reality will just force people not to use the in game VoIP. Any audio mixing done to the voice signal should be done to improve the voice the voice quality. Volume Ducking Games frequently have very loud sound effects such as explosions and gunfire which can drown out other sounds in the game. However, it would interrupt conversations if these noises also drowned out the voice signal. A naive solution would be to increase the volume of the voice signal far above the game sounds but doing this would cause clipping and sound terrible. An alternative solution would be to reduce the volume of the game audio far below the voice signal, but doing this would cause the game sounds to lack impact even when no one is talking. The best solution is to play game sounds at full volume when no one is talking but then when someone starts talking simply \"duck\" the volume so the voice can be clearly heard over the game sounds. Above is an example audio mixer for a game. Highlighted in red are all the groups of non voice data, highlighted in blue is a groups of NPC voice audio and highlighted in green is a groups of human voice data. If you do not have any groups like this then all you need to add is a single groups of \"non-voice\" and make sure all the game sounds play to this group. To make dissonance play to the \"Human Voice\" group you need to modify your playback prefab, simply drag the \"Human Voice\" group into the AudioSource of the prefab and all voice will play to that group. The yellow arrows indicate \"sends\", a send sends audio from one signal processor to another. At the receiving end of the sends is a \"Duck Volume\" effect, this reduces the volume of the group relative to the volume of the signal it receives via a send. The setup shown above has two volume ducks and three sends. The human voice sends to \"Non-Voice\" and \"NPC Voice\", this means than when a human speaks both NPC voices and other sounds get quieter. The \"NPC Voice\" has a single send to the \"Non-Voice\" group, this means that when an NPC speaks other sounds get quieter. Sound Effects As mentioned above you should be very cautious about applying any sound effects to the voice signal which are not for the purpose of enhancing the voice quality. However there are some situations where applying sound effects to voices could sound good, for example keeping allied communications clean, but adding a subtle radio distortion effect to enemy communications. Applying an effect is very simple, simply click add on the audio group and select the effect you want. Above is an example of an audio group with a distortion effect applied.","title":"Audio Mixing For Voice"},{"location":"Tutorials/Audio-Mixing.html#tutorial-audio-mixing","text":"Also see this video about audio mixing. Dissonance does not have any special support built in for audio mixing, because unity already has a powerful mixing system built in which dissonance audio is routed through. You can find out more about the unity audio mixing system here . This tutorial offers advice about the best way to use the unity audio pipeline for VoIP.","title":"Tutorial: Audio Mixing"},{"location":"Tutorials/Audio-Mixing.html#general-principles","text":"It can be tempting to mix voice signals in the same way as any other audio signal in your game and to add various sound effects to the voice for realism/immersion. Things such as drowning out teammates with loud gunfire, deafening players when they're hit by a flashbang or adding extreme radio fuzz when the enemy team use jammers might all sound immersive but in reality will just force people not to use the in game VoIP. Any audio mixing done to the voice signal should be done to improve the voice the voice quality.","title":"General Principles"},{"location":"Tutorials/Audio-Mixing.html#volume-ducking","text":"Games frequently have very loud sound effects such as explosions and gunfire which can drown out other sounds in the game. However, it would interrupt conversations if these noises also drowned out the voice signal. A naive solution would be to increase the volume of the voice signal far above the game sounds but doing this would cause clipping and sound terrible. An alternative solution would be to reduce the volume of the game audio far below the voice signal, but doing this would cause the game sounds to lack impact even when no one is talking. The best solution is to play game sounds at full volume when no one is talking but then when someone starts talking simply \"duck\" the volume so the voice can be clearly heard over the game sounds. Above is an example audio mixer for a game. Highlighted in red are all the groups of non voice data, highlighted in blue is a groups of NPC voice audio and highlighted in green is a groups of human voice data. If you do not have any groups like this then all you need to add is a single groups of \"non-voice\" and make sure all the game sounds play to this group. To make dissonance play to the \"Human Voice\" group you need to modify your playback prefab, simply drag the \"Human Voice\" group into the AudioSource of the prefab and all voice will play to that group. The yellow arrows indicate \"sends\", a send sends audio from one signal processor to another. At the receiving end of the sends is a \"Duck Volume\" effect, this reduces the volume of the group relative to the volume of the signal it receives via a send. The setup shown above has two volume ducks and three sends. The human voice sends to \"Non-Voice\" and \"NPC Voice\", this means than when a human speaks both NPC voices and other sounds get quieter. The \"NPC Voice\" has a single send to the \"Non-Voice\" group, this means that when an NPC speaks other sounds get quieter.","title":"Volume Ducking"},{"location":"Tutorials/Audio-Mixing.html#sound-effects","text":"As mentioned above you should be very cautious about applying any sound effects to the voice signal which are not for the purpose of enhancing the voice quality. However there are some situations where applying sound effects to voices could sound good, for example keeping allied communications clean, but adding a subtle radio distortion effect to enemy communications. Applying an effect is very simple, simply click add on the audio group and select the effect you want. Above is an example of an audio group with a distortion effect applied.","title":"Sound Effects"},{"location":"Tutorials/Channel-Priority.html","text":"Channel Priority Channel priority can be used to automatically mute low priority channels while high priority channels are speaking. For example muting the global voice chat room whilst someone in the team chat room is talking. Priority Levels There are 4 priority levels which can be set on a channel: 1. Low 2. Default 3. Medium 4. High If a player is receiving voice from multiple sources then the sources with the highest priority will play and all others will be muted. There is another priority option: None . If this used then the priority falls back to the default value for this player, which is set in DissonanceComms.PlayerPriority . If None is specified as the default player priority then Default is used instead. Defining Priority The priority of a channel can be defined in a number of ways. The inspector for the Voice Broadcast Trigger allows you to set the priority for voice sent with this trigger: In scripts you can change the priority for a VoiceBroadcastTrigger with the Priority property: var trigger = GetComponent < VoiceBroadcastTrigger >(); trigger . Priority = ChannelPriority . High ; Alternatively if you are directly using channels from scripts instead of using the trigger components you can set the priority when the channel is created, and then modify it from the channel object at any time: var comms = GetComponent < DissonanceComms >(); //Create the channel with an explicit priority var channel = comms . RoomChannels . Open ( \"Room Name\" , priority : ChannelPriority . High ); //Change the priority channel . Priority = ChannelPriority . Medium ; //Close the channel channel . Dispose ();","title":"Channel Priority"},{"location":"Tutorials/Channel-Priority.html#channel-priority","text":"Channel priority can be used to automatically mute low priority channels while high priority channels are speaking. For example muting the global voice chat room whilst someone in the team chat room is talking.","title":"Channel Priority"},{"location":"Tutorials/Channel-Priority.html#priority-levels","text":"There are 4 priority levels which can be set on a channel: 1. Low 2. Default 3. Medium 4. High If a player is receiving voice from multiple sources then the sources with the highest priority will play and all others will be muted. There is another priority option: None . If this used then the priority falls back to the default value for this player, which is set in DissonanceComms.PlayerPriority . If None is specified as the default player priority then Default is used instead.","title":"Priority Levels"},{"location":"Tutorials/Channel-Priority.html#defining-priority","text":"The priority of a channel can be defined in a number of ways. The inspector for the Voice Broadcast Trigger allows you to set the priority for voice sent with this trigger: In scripts you can change the priority for a VoiceBroadcastTrigger with the Priority property: var trigger = GetComponent < VoiceBroadcastTrigger >(); trigger . Priority = ChannelPriority . High ; Alternatively if you are directly using channels from scripts instead of using the trigger components you can set the priority when the channel is created, and then modify it from the channel object at any time: var comms = GetComponent < DissonanceComms >(); //Create the channel with an explicit priority var channel = comms . RoomChannels . Open ( \"Room Name\" , priority : ChannelPriority . High ); //Change the priority channel . Priority = ChannelPriority . Medium ; //Close the channel channel . Dispose ();","title":"Defining Priority"},{"location":"Tutorials/Channel-Volume.html","text":"Channel Volume The playback volume can be set by the speaker per broadcast channel. This can be used to individually reduce the volume of a speaker. For example fading off voice over a small period of time when someone stops speaking. Broadcast Trigger Component The broadcaster trigger component exposes 2 amplitude settings in the inspector; activation fade and trigger fade. Activation Fade applies a fade in/out every time speech is started or stopped. For example every time push-to-talk is pressed/released. This setting should be used with care; applying any fade-in is inadvisable as it will almost certainly cause the start of what is being said to be cut off. Volume Trigger Fade applies only to broadcast triggers which are using physics based volume triggers. This fade will be applied every time the player enters or exits the trigger area. Both faders have the same three controls: The Channel Volume slider controls the amplitude which will be reached after the fade in time has passed. This is a direct multiplier applied to the audio, values between 0 to 1 will reduce playback amplitude, values between 1 to 2 will increase playback amplitude. If both faders are in use the values will be multiplied together. The Fade In Time slider controls how long it takes the playback amplitude to increase from zero (silent) to the Channel Volume slider value. The Fade Out Time slider controls how long it takes the playback amplitude to decrease from the Channel Volume slider value to zero (silent). Script Controlled Volume If you are controlling channels directly from your own scripts you can control volume on the channel object. var comms = GetComponent < DissonanceComms >(); //Create a channel with explicit amplitude var channel = comms . RoomsChannels . Open ( \"Room Name\" , amplitudeMultiplier : 0.5f ); //At any time while the channel is open change the amplitude channel . AmplitudeMultiplier = 1.0f ; //Close the channel channel . Dispose ();","title":"Channel Volume"},{"location":"Tutorials/Channel-Volume.html#channel-volume","text":"The playback volume can be set by the speaker per broadcast channel. This can be used to individually reduce the volume of a speaker. For example fading off voice over a small period of time when someone stops speaking.","title":"Channel Volume"},{"location":"Tutorials/Channel-Volume.html#broadcast-trigger-component","text":"The broadcaster trigger component exposes 2 amplitude settings in the inspector; activation fade and trigger fade. Activation Fade applies a fade in/out every time speech is started or stopped. For example every time push-to-talk is pressed/released. This setting should be used with care; applying any fade-in is inadvisable as it will almost certainly cause the start of what is being said to be cut off. Volume Trigger Fade applies only to broadcast triggers which are using physics based volume triggers. This fade will be applied every time the player enters or exits the trigger area. Both faders have the same three controls: The Channel Volume slider controls the amplitude which will be reached after the fade in time has passed. This is a direct multiplier applied to the audio, values between 0 to 1 will reduce playback amplitude, values between 1 to 2 will increase playback amplitude. If both faders are in use the values will be multiplied together. The Fade In Time slider controls how long it takes the playback amplitude to increase from zero (silent) to the Channel Volume slider value. The Fade Out Time slider controls how long it takes the playback amplitude to decrease from the Channel Volume slider value to zero (silent).","title":"Broadcast Trigger Component"},{"location":"Tutorials/Channel-Volume.html#script-controlled-volume","text":"If you are controlling channels directly from your own scripts you can control volume on the channel object. var comms = GetComponent < DissonanceComms >(); //Create a channel with explicit amplitude var channel = comms . RoomsChannels . Open ( \"Room Name\" , amplitudeMultiplier : 0.5f ); //At any time while the channel is open change the amplitude channel . AmplitudeMultiplier = 1.0f ; //Close the channel channel . Dispose ();","title":"Script Controlled Volume"},{"location":"Tutorials/Collider-Chat-Room.html","text":"Collider Chat Rooms Also see this video about collider chat rooms. This tutorial will introduce volume triggers for transmission and receipt triggers, and how they can be used to implement localised chat rooms which allow users standing within the same area in your game world to chat with each other. This tutorial builds upon the setup in the Position tracking guide. Position Tracking must be set up to allow Dissonance to track player positions for collider chat rooms to function. A demo scene for this tutorial can be found in Dissonance/Demos . Step 1: Define our room volume Imagine your game has multiple physical lobby rooms all connected to a central corridor. You decide that we want players to be able to speak to and hear the other players in whatever room they are in, and for this to dynamically update as they move from room to room. The first thing you will need to do is define the volume which represents your lobby room using a Unity trigger volume . Create a new game object called \"LobbyChatRoom\". Add a \"Box Collider\" to the game object, set it's size to the size of your lobby room and check \"Is Trigger\". Step 2: Add a Receipt Trigger To allow you to hear the users talking in the lobby chat room you will need to add a \"Voice Receipt Trigger\" to the game object. Unlike the \"Global\" chat channel in the quick start guide, here you will add this to the same game object as the \"Box Collider\". Enable \"Trigger Activation\" on the \"Voice Receipt Trigger\" to tell the script to only listen to the room when the player is within the collider attached to the game object. Step 3: Define a new Chat Rooms Right now, the receipt trigger is listening to the \"Global\" chat room, not the chat room for the lobby. On the inspector for the \"Voice Receipt Trigger\" click \"Config Rooms\" to go to Dissonance's room configuration. By default, Dissonance creates three chat rooms; \"Global\", \"Red Team\" and \"Blue Team\". Click \"Add Room\", and rename the new room to \"Lobby\". Now, go back to the receipt trigger, and change the selection in the \"Chat Room\" drop down to the new \"Lobby\" room. Chat rooms can be named dynamically when configuring the triggers programatically. Step 4: Add a Broadcast Trigger You now have a receiver configured to hear other people alking in the lobby room, but no one is saying anything! You need to add a broadcast trigger to the room. Add a \"Voice Broadcast Trigger\" script to the game object. Use a Channel Type of \"Room\", and choose the \"Lobby\" room. Finished You now have a trigger box set up as a chat room. Players standing within the collider can talk to each other in the \"Lobby\" chat room, players who walk out of the volume will not be able to speak to or hear from the lobby room.","title":"Collider Chat Rooms"},{"location":"Tutorials/Collider-Chat-Room.html#collider-chat-rooms","text":"Also see this video about collider chat rooms. This tutorial will introduce volume triggers for transmission and receipt triggers, and how they can be used to implement localised chat rooms which allow users standing within the same area in your game world to chat with each other. This tutorial builds upon the setup in the Position tracking guide. Position Tracking must be set up to allow Dissonance to track player positions for collider chat rooms to function. A demo scene for this tutorial can be found in Dissonance/Demos .","title":"Collider Chat Rooms"},{"location":"Tutorials/Collider-Chat-Room.html#step-1-define-our-room-volume","text":"Imagine your game has multiple physical lobby rooms all connected to a central corridor. You decide that we want players to be able to speak to and hear the other players in whatever room they are in, and for this to dynamically update as they move from room to room. The first thing you will need to do is define the volume which represents your lobby room using a Unity trigger volume . Create a new game object called \"LobbyChatRoom\". Add a \"Box Collider\" to the game object, set it's size to the size of your lobby room and check \"Is Trigger\".","title":"Step 1: Define our room volume"},{"location":"Tutorials/Collider-Chat-Room.html#step-2-add-a-receipt-trigger","text":"To allow you to hear the users talking in the lobby chat room you will need to add a \"Voice Receipt Trigger\" to the game object. Unlike the \"Global\" chat channel in the quick start guide, here you will add this to the same game object as the \"Box Collider\". Enable \"Trigger Activation\" on the \"Voice Receipt Trigger\" to tell the script to only listen to the room when the player is within the collider attached to the game object.","title":"Step 2: Add a Receipt Trigger"},{"location":"Tutorials/Collider-Chat-Room.html#step-3-define-a-new-chat-rooms","text":"Right now, the receipt trigger is listening to the \"Global\" chat room, not the chat room for the lobby. On the inspector for the \"Voice Receipt Trigger\" click \"Config Rooms\" to go to Dissonance's room configuration. By default, Dissonance creates three chat rooms; \"Global\", \"Red Team\" and \"Blue Team\". Click \"Add Room\", and rename the new room to \"Lobby\". Now, go back to the receipt trigger, and change the selection in the \"Chat Room\" drop down to the new \"Lobby\" room. Chat rooms can be named dynamically when configuring the triggers programatically.","title":"Step 3: Define a new Chat Rooms"},{"location":"Tutorials/Collider-Chat-Room.html#step-4-add-a-broadcast-trigger","text":"You now have a receiver configured to hear other people alking in the lobby room, but no one is saying anything! You need to add a broadcast trigger to the room. Add a \"Voice Broadcast Trigger\" script to the game object. Use a Channel Type of \"Room\", and choose the \"Lobby\" room.","title":"Step 4: Add a Broadcast Trigger"},{"location":"Tutorials/Collider-Chat-Room.html#finished","text":"You now have a trigger box set up as a chat room. Players standing within the collider can talk to each other in the \"Lobby\" chat room, players who walk out of the volume will not be able to speak to or hear from the lobby room.","title":"Finished"},{"location":"Tutorials/Custom-Microphone-Capture.html","text":"Tutorial: Custom Microphone Capture This tutorial will explain how to replace the microphone capture system in Dissonance with your own script. By doing this you will gain complete control over what audio is input to Dissonance. Default Microphone Capture When the DissonanceComms component Start method is called (just once when the component is first enabled) Dissonance will look for a sibling component which implements the IMicrophoneCapture interface. If it does not find a suitable component it will create a BasicMicrophoneCapture component which internally uses the Unity microphone API . To use your custom microphone script simply drop it onto the same gameObject as DissonanceComms. IMicrophoneCapture bool IsRecording { get; } This property indicates if the microphone component is currently recording. TimeSpan Latency { get; } This property should give the estimated latency of the microphone capture system. This is the total time from audio physically hitting the microphone hardware to the data being passed on to subscribers. WaveFormat StartCapture(string mic_name) Attempt to begin recording. The return value indicates what format the captured data will be. If microphone capture cannot be started for any reason this method should return null. The microphone name is passed through from the UI, how it is interpreted depends upon what kind of audio capture system you are using. StopCapture() Immediately stops microphone capture, discarding any data remaining in internal buffers. Subscribe(IMicrophoneSubscriber subscriber) Subscribes a new object to receive raw microphone data. bool Unsubscribe(IMicrophoneSubscriber subscriber) Attempts to remove a previously subscribed object. Returns whether the object was found (if it was found it is assumed it was successfully removed). bool Update() Pass buffered data on to the subscribers. Returns true if the microphone needs to be reset. In this case Stop will immediately be called (and start may be called afterwards).","title":"Writing A Custom Microphone Capture System"},{"location":"Tutorials/Custom-Microphone-Capture.html#tutorial-custom-microphone-capture","text":"This tutorial will explain how to replace the microphone capture system in Dissonance with your own script. By doing this you will gain complete control over what audio is input to Dissonance.","title":"Tutorial: Custom Microphone Capture"},{"location":"Tutorials/Custom-Microphone-Capture.html#default-microphone-capture","text":"When the DissonanceComms component Start method is called (just once when the component is first enabled) Dissonance will look for a sibling component which implements the IMicrophoneCapture interface. If it does not find a suitable component it will create a BasicMicrophoneCapture component which internally uses the Unity microphone API . To use your custom microphone script simply drop it onto the same gameObject as DissonanceComms.","title":"Default Microphone Capture"},{"location":"Tutorials/Custom-Microphone-Capture.html#imicrophonecapture","text":"","title":"IMicrophoneCapture"},{"location":"Tutorials/Custom-Microphone-Capture.html#bool-isrecording-get","text":"This property indicates if the microphone component is currently recording.","title":"bool IsRecording { get; }"},{"location":"Tutorials/Custom-Microphone-Capture.html#timespan-latency-get","text":"This property should give the estimated latency of the microphone capture system. This is the total time from audio physically hitting the microphone hardware to the data being passed on to subscribers.","title":"TimeSpan Latency { get; }"},{"location":"Tutorials/Custom-Microphone-Capture.html#waveformat-startcapturestring-mic_name","text":"Attempt to begin recording. The return value indicates what format the captured data will be. If microphone capture cannot be started for any reason this method should return null. The microphone name is passed through from the UI, how it is interpreted depends upon what kind of audio capture system you are using.","title":"WaveFormat StartCapture(string mic_name)"},{"location":"Tutorials/Custom-Microphone-Capture.html#stopcapture","text":"Immediately stops microphone capture, discarding any data remaining in internal buffers.","title":"StopCapture()"},{"location":"Tutorials/Custom-Microphone-Capture.html#subscribeimicrophonesubscriber-subscriber","text":"Subscribes a new object to receive raw microphone data.","title":"Subscribe(IMicrophoneSubscriber subscriber)"},{"location":"Tutorials/Custom-Microphone-Capture.html#bool-unsubscribeimicrophonesubscriber-subscriber","text":"Attempts to remove a previously subscribed object. Returns whether the object was found (if it was found it is assumed it was successfully removed).","title":"bool Unsubscribe(IMicrophoneSubscriber subscriber)"},{"location":"Tutorials/Custom-Microphone-Capture.html#bool-update","text":"Pass buffered data on to the subscribers. Returns true if the microphone needs to be reset. In this case Stop will immediately be called (and start may be called afterwards).","title":"bool Update()"},{"location":"Tutorials/Custom-Networking.html","text":"Tutorial: Custom Network Integration Dissonance is built to be completely decoupled from the underlying networking system, this allows Dissonance to run on top of various different Unity networking assets (e.g. UNet, Forge, Photon etc) just by swapping which Dissonance network component is used. If none of the existing integrations work for your application then you may need to build a custom network integration. Getting Started Dissonance includes a set of base classes which implement most of the networking logic for you: BaseCommsNetwork - This is the main comms network component which you place into your scene. It manages the networking, starting and stopping Dissonance networking in response to network events. BaseServer - This is a class created by the comms network component on one of the peers in the session. It manages the session as other peers join and leave. You will extend this class to implement your server logic. BaseClient - This is a class created by the comms network component on all the peers in the session. It manages sending and receiving voice. You will extend this class to implement your client logic. These classes all take 5 type parameters, which specify some extra details about your network system: TServer - This is the type of the class you have extended from BaseServer TClient - This is the type of the class you have extended from BaseClient TPeer - This is a type of your choice which represents other peers in the network. For now just create a new empty struct type and fill in the details later. TClientParam - This is the type of data needed for a client to join the session (e.g. an IP address). If your network does not need this (e.g. it is already running before Dissonance is started) then just pass Unit . TServerParam - This is the type of data needed for a server to host a session (e.g. a port number). If your network does not need this (e.g. it is already running before Dissonance is started) then just pass Unit . Here is an example from the HLAPI integration of these types in use: public class HlapiCommsNetwork : BaseCommsNetwork < HlapiServer , // A class which implements BaseServer HlapiClient , // A class which implements BaseClient HlapiConn , // A struct which contains a HLAPI NetworkConnection Unit , // Nothing Unit // Nothing > You should now have several new classes and structs: CustomCommsNetwork : BaseCommsNetwork CustomClient : BaseClient CustomServer : BaseServer CustomPeer struct ServerParam (maybe) ClientParam (maybe) You will have a number of build errors like \"abstract member [...] not implemented\" - these are the things you must implement before the network integration can work. CustomCommsNetwork : BaseCommsNetwork In your custom comms network class you will need to create your custom client and custom server objects. Dissonance will call these methods when a server or client needs to be created. You shouldn't connect to the network in this method, simply create the objects. Here are examples from the HLAPI integration: // We specified `Unit` as `TServerParam`, so we get given a `Unit` protected override HlapiServer CreateServer ( Unit details ) { return new HlapiServer ( this ); } // We specified `Unit` as `TClientParam`, so we get given a `Unit` protected override HlapiClient CreateClient ( Unit details ) { return new HlapiClient ( this ); } You may also need to override the Initialize method. This allows you to setup your network system before any networking is done. The HLAPI integration look like this: protected override void Initialize () { //Sanity check the channel configuration set in the inspector //... << Removed code for simplicity of example >> // HLAPI requires a message handler for every type code. // Register one which just discards packets while Dissonance // is _not_ running. NetworkServer . RegisterHandler ( TypeCode , NullMessageReceivedHandler ); // Don't forget to call base.Initialize! base . Initialize (); } Finally you need to decide how your network integration will be started, there are two techniques for this. Some integrations (e.g. HLAPI/Photon) have a network system which is already running and Dissonance simply uses that, in this case the CustomCommsNetwork should watch the status of the external network system and make sure that the Dissonance network is synchronized with it (e.g. when the external network stops Dissonance should stop and when it starts Dissonance should start). Some other integrations (e.g. WebRTC/LLAPI) host a separate network session entirely within the custom network components, in this case you may want to add StartNetwork/StopNetwork methods to your component which you can use to control the networking. If you are using the first technique then you need to monitor the external network system and make sure that Dissonance is running in the same way as the network system. Here is how this is implemented in the HLAPI network integration: // Check every frame protected override void Update () { // Check if Dissonance is ready if ( IsInitialized ) { // Check if the HLAPI is ready var networkActive = NetworkManager . singleton . isNetworkActive && ( NetworkServer . active || NetworkClient . active ); if ( networkActive ) { // Check what mode the HLAPI is in var server = NetworkServer . active ; var client = NetworkClient . active ; // Check what mode Dissonance is in and if // they're different then call the correct method if ( Mode . IsServerEnabled () != server || Mode . IsClientEnabled () != client ) { // HLAPI is server and client, so run as a non-dedicated // host (passing in the correct parameters) if ( server && client ) RunAsHost ( Unit . None , Unit . None ); // HLAPI is just a server, so run as a dedicated host else if ( server ) RunAsDedicatedServer ( Unit . None ); // HLAPI is just a client, so run as a client else if ( client ) RunAsClient ( Unit . None ); } } else if ( Mode != NetworkMode . None ) { //Network is not active, make sure Dissonance is not active Stop (); } } base . Update (); } As you can see this is ultimately calling the methods RunAsHost (if HLAPI is a client and a server), RunAsDedicatedServer (if HLAPI is just a server), RunAsClient (if HLAPI is just a client) or Stop if HLAPI is not running. If you are using the self hosted technique you should expose public methods which call these 4 methods when you want to start/stop networking. CustomClient : BaseClient This class handles all of the client side logic of Dissonance, one of these will be created on every single peer in the session (including the host). There will be two build errors to fix in this class. Base class [...] doesn't contain a parameterless constructor . To fix this simply add a constructor which passes a CustomCommsNetwork to the base class: public CustomClient ( CustomCommsNetwork network ) : base ( network ) { } You already implemented the CreateClient method in your CustomCommsNetwork which uses this constructor. Make sure to pass in other parameters here (e.g. connection parameters) as necessary. abstract member [...] not implemented . There will be four of these errors to fix: public override void Connect() This will be called when you need to connect to the session. Once you have finished connecting (which may take a long time) you should call base.Connected() . For example in the HLAPI integration this simply binds a message handler and immediately calls Connected , wheras in the LLAPI integration it starts connecting the network socket and does not call Connected until that succeeds. protected override void ReadMessages() This will be called periodically to poll messages from the network system. Any packets you receive should be to base.NetworkPacketReceived . protected override void SendReliable(ArraySegment packet) This method sends a packet to the server using a reliable and in order channel (e.g. TCP). Packets sent with this method are not latency sensitive but MUST arrive in order. If you detect that a reliable packet has been lost you should immediately stop the Dissonance network session. protected override void SendUnreliable(ArraySegment packet) This methods sends a packet to the server using an unreliable and unordered channel (e.g. UDP). Packets sent with this method are extremely latency sensitive and must arrive as soon as possible or not at all. It is expected that some packets sent using this method may be lost or arrive out of order. CustomServer : BaseServer This class handles all the server side logic of Dissonance, one of these will be created on a single peer in the session and handles managing the session. In the basic configuration all voice data is relayed via this peer (see P2P section for details on how to avoid this). There will be five \"abstract member [...] not implemented\" errors to fix: public override void Connect() This will be called when you need to host a session, you should do any setup required here. For example in the HLAPI integration this binds message handlers, in the LLAPI integration it creates and opens a listen socket. public override void Disconnect() This will be called when you need to stop hosting a session, you should do any required teardown here. protected override void ReadMessages() This will be called periodically to poll messages from the network system. Any packets you receive should be to base.NetworkPacketReceived . The base.NetworkPacketReceived method on the server requires an instance of your TPeer type (e.g. CustomPeer ). protected override void SendReliable(TPeer destination, ArraySegment<byte> packet) This method sends a reliable packet to another peer using a reliable and in order channel (e.g. TCP). Packets sent with this method are not latency sensitive but MUST arrive in order. If you detect that a reliable packet has been lost you should immediately stop the Dissonance network session. This is where you should decide what your CustomPeer struct needs to contain. Whatever information you require to specify which peer to send to should be added into your struct. For example in the HLAPI integration sending requires a NetworkConnection object, so the CustomPeer struct contains a single NetworkConnection field. protected override void SendUnreliable(TPeer destination, ArraySegment<byte> packet) This methods sends a packet to the server using an unreliable and unordered channel (e.g. UDP). Packets sent with this method are extremely latency sensitive and must arrive as soon as possible or not at all. It is expected that some packets sent using this method may be lost or arrive out of order. ClientDisconnected Finally there is one more method that you must call when appropriate: ClientDisconnected indicates that a client has left the session. You should call this as soon as you know a client has left. Editor Inspector Finally you should create an inspector for your CustomCommsNetwork. Doing this is very simple, extend the BaseDissonanceCommsNetworkEditor class and pass the same 5 generic types you defined above. Attach the CustomEditor attribute to the class. For example in the HLAPI integration the inspector looks like this: [CustomEditor(typeof(HlapiCommsNetwork))] public class UNetCommsNetworkEditor : BaseDissonnanceCommsNetworkEditor < HlapiCommsNetwork , HlapiServer , HlapiClient , HlapiConn , Unit , Unit > { } This will set up a basic inspector for you. Testing At this point you should have a basic voice chat system functioning with your custom network. You should set up a test scene to test it. While the test scene is running check these things: - Look at the inspector for your CustomCommsNetwork component. - Once the network session is started the Mode should shows \"Server & Client\", \"Client\" or \"Server\" depending on the mode this peer is running in. - Once the network session has connected the Connection Status should show \"Connected\" - Try sending a text chat message. - Create a broadcast and receipt trigger and speak. - Look at the inspector for the DissonanceComms component. It shows a list of client in the session, disconnect a client and make sure they disappear. Extensions: Loopback The Dissonance networking system create a CustomClient and a CustomServer on the host machine (unless running a dedicated server). The server must be able to send and receive message to this local peer the same as any other peer. This can cause complications with some network systems which do not handle this kind of \"loopback\" correctly. You must also be careful to make sure you can distinguish messages from other peers to the host - make sure that they don't get processed by the host client object. To handle this many of the Dissonance integrations have a special check for loopback. For example in the HLAPI integration there is a HlapiCommsNetwork:PreprocessPacketToClient method which is given all packets sent from the server to the client, it checks if the packet is a loopback packet and if so it passes it directly to the client and HLAPI itself never has to deal with this packet. internal bool PreprocessPacketToClient ( ArraySegment < byte > packet , HlapiConn destination ) { // No client means this can't be loopback if ( Client == null ) return false ; // HLAPI way to check if this is loopback. if ( NetworkManager . singleton . client . connection != destination . Connection ) return false ; // This is loopback! // check that we have a valid local client, // in cases of startup or in-progress shutdowns if ( Client != null ) { // Don't immediately deliver the packet, add it to a queue and // deliver it next frame. This prevents the local client from // executing \"within\" the local server which can cause // confusing stack traces. _loopbackQueue . Add ( packet . CopyTo ( _loopbackBuffers . Get ())); } return true ; } Extensions: Peer To Peer Currently the network integration you have built sends all packets to the server, which then relays them to other clients. If possible you may want to implement peer to peer voice communications. However, you should consider the bandwidth of your game before implementing peer to peer as it is not always beneficial to use it. In a non P2P setup voice follows a path like: Speaker -> Server -> Listener # 1 -> Listener # 2 -> Listener # 3 In this case the bandwidth used by the speaker is 1 voice stream ~20 kilobits/second . The bandwidth used by each listener is 1 voice stream ~20 kilobits/second . The bandwidth used by the server is (Speakers + Listeners) * Bandwidth = (1 + 3) * ~20 = ~80 kilobits/second . In this setup the bandwidth of each client (speaker or listener) is the minimum possible. If your game uses client devices with tight bandwidth limits this may be the best setup. In a P2P setup the voice follows a different path: Speaker -> Listener # 1 -> Listener # 2 -> Listener # 3 The bandwidth on the server has been reduced (to zero). However, the total bandwidth for the speaker client is now Listeners * Bandwidth = 3 * ~20 = ~60 kilobits/second . Implementing P2P If you have decided to use peer to peer you need to modify your CustomClient class. Wherever you call NetworkReceivePacket you should modify it to capture the return value of the method call, if the value is not call ReceiveHandshakeP2P with it and a CustomPeer object for the sender of the message. For example in the Photon Unity Networking (PUN) integration the receiving code is implemented like this: // This event is called by PUN when a packet arrives public void PacketDelivered ( byte eventcode , ArraySegment < byte > data , int senderid ) { // Skip events we don't care about if ( eventcode != _network . EventCodeToClient ) return ; // Receive the packet, capture return value var id = NetworkReceivedPacket ( data ); // If the value is not null // pass to handshake method with the `senderid` of this packet if ( id . HasValue ) ReceiveHandshakeP2P ( id . Value , senderid ); } You now need to implement two more methods for sending packets: SendReliableP2P(List<ClientInfo<TPeer?>> destinations, ArraySegment<byte> packet) SendUnreliableP2P(List<ClientInfo<TPeer?>> destinations, ArraySegment<byte> packet) These methods send a packet to a list of destinations. You should send the packet to as many of these destinations as possible and remove them from the list. Once you are done call the base method with the remaining items in the list, they will be sent via the server as usual. For example the PUN implementation of this is: private void SendUnreliableP2P ( IList < ClientInfo < int? >> destinations , ArraySegment < byte > packet ) { // Build a list of destinations we know how to send to // i.e. have a non-null Connection object var dests = new List < int >(); foreach ( var item in destinations ) if ( item . Connection . HasValue ) dests . Add ( item . Connection ); // Remove all the ones we can send to from the input list destinations . RemoveAll ( dests ); // Send the packets to the list of destinations through PUN _network . Send ( packet , dests , reliable : false ); // Call base to do server relay for all the peers we don't // know how to contact base . SendUnreliableP2P ( destinations , packet ); } Because there is a fallback mechanism you can mix P2P and non-P2P packets as necessary. For example you start by sending everything via the server, establish a p2p connection between clients and if it fails (e.g. due to firewall or NAT settings) you can simply keep on sending via relay for that specific pair of clients. Alternatively you could monitor client bandwidth and send via P2P if there is spare bandwidth - falling back to server relay if the client is close to reaching it's bandwidth limit. Finally you need to start establishing p2p connections. Override the OnServerAssignedSessionId method, when this is called you should send a \"handshake\" packet to every peer you know how to contact directly. This will tell those peers that you are available for p2p communication. For example in the PUN integration this is implemented as: protected override void OnServerAssignedSessionId ( uint session , ushort id ) { base . OnServerAssignedSessionId ( session , id ); // Create the handshake packet to send var packet = new ArraySegment < byte >( WriteHandshakeP2P ( session , id )); // Send this to everyone else in the session through PUN _network . Send ( packet , _network . EventCodeToClient , new RaiseEventOptions { Receivers = ReceiverGroup . Others , }, true ); }","title":"Writing A Custom Network Integration"},{"location":"Tutorials/Custom-Networking.html#tutorial-custom-network-integration","text":"Dissonance is built to be completely decoupled from the underlying networking system, this allows Dissonance to run on top of various different Unity networking assets (e.g. UNet, Forge, Photon etc) just by swapping which Dissonance network component is used. If none of the existing integrations work for your application then you may need to build a custom network integration.","title":"Tutorial: Custom Network Integration"},{"location":"Tutorials/Custom-Networking.html#getting-started","text":"Dissonance includes a set of base classes which implement most of the networking logic for you: BaseCommsNetwork - This is the main comms network component which you place into your scene. It manages the networking, starting and stopping Dissonance networking in response to network events. BaseServer - This is a class created by the comms network component on one of the peers in the session. It manages the session as other peers join and leave. You will extend this class to implement your server logic. BaseClient - This is a class created by the comms network component on all the peers in the session. It manages sending and receiving voice. You will extend this class to implement your client logic. These classes all take 5 type parameters, which specify some extra details about your network system: TServer - This is the type of the class you have extended from BaseServer TClient - This is the type of the class you have extended from BaseClient TPeer - This is a type of your choice which represents other peers in the network. For now just create a new empty struct type and fill in the details later. TClientParam - This is the type of data needed for a client to join the session (e.g. an IP address). If your network does not need this (e.g. it is already running before Dissonance is started) then just pass Unit . TServerParam - This is the type of data needed for a server to host a session (e.g. a port number). If your network does not need this (e.g. it is already running before Dissonance is started) then just pass Unit . Here is an example from the HLAPI integration of these types in use: public class HlapiCommsNetwork : BaseCommsNetwork < HlapiServer , // A class which implements BaseServer HlapiClient , // A class which implements BaseClient HlapiConn , // A struct which contains a HLAPI NetworkConnection Unit , // Nothing Unit // Nothing > You should now have several new classes and structs: CustomCommsNetwork : BaseCommsNetwork CustomClient : BaseClient CustomServer : BaseServer CustomPeer struct ServerParam (maybe) ClientParam (maybe) You will have a number of build errors like \"abstract member [...] not implemented\" - these are the things you must implement before the network integration can work.","title":"Getting Started"},{"location":"Tutorials/Custom-Networking.html#customcommsnetwork-basecommsnetwork","text":"In your custom comms network class you will need to create your custom client and custom server objects. Dissonance will call these methods when a server or client needs to be created. You shouldn't connect to the network in this method, simply create the objects. Here are examples from the HLAPI integration: // We specified `Unit` as `TServerParam`, so we get given a `Unit` protected override HlapiServer CreateServer ( Unit details ) { return new HlapiServer ( this ); } // We specified `Unit` as `TClientParam`, so we get given a `Unit` protected override HlapiClient CreateClient ( Unit details ) { return new HlapiClient ( this ); } You may also need to override the Initialize method. This allows you to setup your network system before any networking is done. The HLAPI integration look like this: protected override void Initialize () { //Sanity check the channel configuration set in the inspector //... << Removed code for simplicity of example >> // HLAPI requires a message handler for every type code. // Register one which just discards packets while Dissonance // is _not_ running. NetworkServer . RegisterHandler ( TypeCode , NullMessageReceivedHandler ); // Don't forget to call base.Initialize! base . Initialize (); } Finally you need to decide how your network integration will be started, there are two techniques for this. Some integrations (e.g. HLAPI/Photon) have a network system which is already running and Dissonance simply uses that, in this case the CustomCommsNetwork should watch the status of the external network system and make sure that the Dissonance network is synchronized with it (e.g. when the external network stops Dissonance should stop and when it starts Dissonance should start). Some other integrations (e.g. WebRTC/LLAPI) host a separate network session entirely within the custom network components, in this case you may want to add StartNetwork/StopNetwork methods to your component which you can use to control the networking. If you are using the first technique then you need to monitor the external network system and make sure that Dissonance is running in the same way as the network system. Here is how this is implemented in the HLAPI network integration: // Check every frame protected override void Update () { // Check if Dissonance is ready if ( IsInitialized ) { // Check if the HLAPI is ready var networkActive = NetworkManager . singleton . isNetworkActive && ( NetworkServer . active || NetworkClient . active ); if ( networkActive ) { // Check what mode the HLAPI is in var server = NetworkServer . active ; var client = NetworkClient . active ; // Check what mode Dissonance is in and if // they're different then call the correct method if ( Mode . IsServerEnabled () != server || Mode . IsClientEnabled () != client ) { // HLAPI is server and client, so run as a non-dedicated // host (passing in the correct parameters) if ( server && client ) RunAsHost ( Unit . None , Unit . None ); // HLAPI is just a server, so run as a dedicated host else if ( server ) RunAsDedicatedServer ( Unit . None ); // HLAPI is just a client, so run as a client else if ( client ) RunAsClient ( Unit . None ); } } else if ( Mode != NetworkMode . None ) { //Network is not active, make sure Dissonance is not active Stop (); } } base . Update (); } As you can see this is ultimately calling the methods RunAsHost (if HLAPI is a client and a server), RunAsDedicatedServer (if HLAPI is just a server), RunAsClient (if HLAPI is just a client) or Stop if HLAPI is not running. If you are using the self hosted technique you should expose public methods which call these 4 methods when you want to start/stop networking.","title":"CustomCommsNetwork : BaseCommsNetwork"},{"location":"Tutorials/Custom-Networking.html#customclient-baseclient","text":"This class handles all of the client side logic of Dissonance, one of these will be created on every single peer in the session (including the host). There will be two build errors to fix in this class. Base class [...] doesn't contain a parameterless constructor . To fix this simply add a constructor which passes a CustomCommsNetwork to the base class: public CustomClient ( CustomCommsNetwork network ) : base ( network ) { } You already implemented the CreateClient method in your CustomCommsNetwork which uses this constructor. Make sure to pass in other parameters here (e.g. connection parameters) as necessary. abstract member [...] not implemented . There will be four of these errors to fix:","title":"CustomClient : BaseClient"},{"location":"Tutorials/Custom-Networking.html#public-override-void-connect","text":"This will be called when you need to connect to the session. Once you have finished connecting (which may take a long time) you should call base.Connected() . For example in the HLAPI integration this simply binds a message handler and immediately calls Connected , wheras in the LLAPI integration it starts connecting the network socket and does not call Connected until that succeeds.","title":"public override void Connect()"},{"location":"Tutorials/Custom-Networking.html#protected-override-void-readmessages","text":"This will be called periodically to poll messages from the network system. Any packets you receive should be to base.NetworkPacketReceived .","title":"protected override void ReadMessages()"},{"location":"Tutorials/Custom-Networking.html#protected-override-void-sendreliablearraysegment-packet","text":"This method sends a packet to the server using a reliable and in order channel (e.g. TCP). Packets sent with this method are not latency sensitive but MUST arrive in order. If you detect that a reliable packet has been lost you should immediately stop the Dissonance network session.","title":"protected override void SendReliable(ArraySegment packet)"},{"location":"Tutorials/Custom-Networking.html#protected-override-void-sendunreliablearraysegment-packet","text":"This methods sends a packet to the server using an unreliable and unordered channel (e.g. UDP). Packets sent with this method are extremely latency sensitive and must arrive as soon as possible or not at all. It is expected that some packets sent using this method may be lost or arrive out of order.","title":"protected override void SendUnreliable(ArraySegment packet)"},{"location":"Tutorials/Custom-Networking.html#customserver-baseserver","text":"This class handles all the server side logic of Dissonance, one of these will be created on a single peer in the session and handles managing the session. In the basic configuration all voice data is relayed via this peer (see P2P section for details on how to avoid this). There will be five \"abstract member [...] not implemented\" errors to fix:","title":"CustomServer : BaseServer"},{"location":"Tutorials/Custom-Networking.html#public-override-void-connect_1","text":"This will be called when you need to host a session, you should do any setup required here. For example in the HLAPI integration this binds message handlers, in the LLAPI integration it creates and opens a listen socket.","title":"public override void Connect()"},{"location":"Tutorials/Custom-Networking.html#public-override-void-disconnect","text":"This will be called when you need to stop hosting a session, you should do any required teardown here.","title":"public override void Disconnect()"},{"location":"Tutorials/Custom-Networking.html#protected-override-void-readmessages_1","text":"This will be called periodically to poll messages from the network system. Any packets you receive should be to base.NetworkPacketReceived . The base.NetworkPacketReceived method on the server requires an instance of your TPeer type (e.g. CustomPeer ).","title":"protected override void ReadMessages()"},{"location":"Tutorials/Custom-Networking.html#protected-override-void-sendreliabletpeer-destination-arraysegmentltbytegt-packet","text":"This method sends a reliable packet to another peer using a reliable and in order channel (e.g. TCP). Packets sent with this method are not latency sensitive but MUST arrive in order. If you detect that a reliable packet has been lost you should immediately stop the Dissonance network session. This is where you should decide what your CustomPeer struct needs to contain. Whatever information you require to specify which peer to send to should be added into your struct. For example in the HLAPI integration sending requires a NetworkConnection object, so the CustomPeer struct contains a single NetworkConnection field.","title":"protected override void SendReliable(TPeer destination, ArraySegment&lt;byte&gt; packet)"},{"location":"Tutorials/Custom-Networking.html#protected-override-void-sendunreliabletpeer-destination-arraysegmentltbytegt-packet","text":"This methods sends a packet to the server using an unreliable and unordered channel (e.g. UDP). Packets sent with this method are extremely latency sensitive and must arrive as soon as possible or not at all. It is expected that some packets sent using this method may be lost or arrive out of order.","title":"protected override void SendUnreliable(TPeer destination, ArraySegment&lt;byte&gt; packet)"},{"location":"Tutorials/Custom-Networking.html#clientdisconnected","text":"Finally there is one more method that you must call when appropriate: ClientDisconnected indicates that a client has left the session. You should call this as soon as you know a client has left.","title":"ClientDisconnected"},{"location":"Tutorials/Custom-Networking.html#editor-inspector","text":"Finally you should create an inspector for your CustomCommsNetwork. Doing this is very simple, extend the BaseDissonanceCommsNetworkEditor class and pass the same 5 generic types you defined above. Attach the CustomEditor attribute to the class. For example in the HLAPI integration the inspector looks like this: [CustomEditor(typeof(HlapiCommsNetwork))] public class UNetCommsNetworkEditor : BaseDissonnanceCommsNetworkEditor < HlapiCommsNetwork , HlapiServer , HlapiClient , HlapiConn , Unit , Unit > { } This will set up a basic inspector for you.","title":"Editor Inspector"},{"location":"Tutorials/Custom-Networking.html#testing","text":"At this point you should have a basic voice chat system functioning with your custom network. You should set up a test scene to test it. While the test scene is running check these things: - Look at the inspector for your CustomCommsNetwork component. - Once the network session is started the Mode should shows \"Server & Client\", \"Client\" or \"Server\" depending on the mode this peer is running in. - Once the network session has connected the Connection Status should show \"Connected\" - Try sending a text chat message. - Create a broadcast and receipt trigger and speak. - Look at the inspector for the DissonanceComms component. It shows a list of client in the session, disconnect a client and make sure they disappear.","title":"Testing"},{"location":"Tutorials/Custom-Networking.html#extensions-loopback","text":"The Dissonance networking system create a CustomClient and a CustomServer on the host machine (unless running a dedicated server). The server must be able to send and receive message to this local peer the same as any other peer. This can cause complications with some network systems which do not handle this kind of \"loopback\" correctly. You must also be careful to make sure you can distinguish messages from other peers to the host - make sure that they don't get processed by the host client object. To handle this many of the Dissonance integrations have a special check for loopback. For example in the HLAPI integration there is a HlapiCommsNetwork:PreprocessPacketToClient method which is given all packets sent from the server to the client, it checks if the packet is a loopback packet and if so it passes it directly to the client and HLAPI itself never has to deal with this packet. internal bool PreprocessPacketToClient ( ArraySegment < byte > packet , HlapiConn destination ) { // No client means this can't be loopback if ( Client == null ) return false ; // HLAPI way to check if this is loopback. if ( NetworkManager . singleton . client . connection != destination . Connection ) return false ; // This is loopback! // check that we have a valid local client, // in cases of startup or in-progress shutdowns if ( Client != null ) { // Don't immediately deliver the packet, add it to a queue and // deliver it next frame. This prevents the local client from // executing \"within\" the local server which can cause // confusing stack traces. _loopbackQueue . Add ( packet . CopyTo ( _loopbackBuffers . Get ())); } return true ; }","title":"Extensions: Loopback"},{"location":"Tutorials/Custom-Networking.html#extensions-peer-to-peer","text":"Currently the network integration you have built sends all packets to the server, which then relays them to other clients. If possible you may want to implement peer to peer voice communications. However, you should consider the bandwidth of your game before implementing peer to peer as it is not always beneficial to use it. In a non P2P setup voice follows a path like: Speaker -> Server -> Listener # 1 -> Listener # 2 -> Listener # 3 In this case the bandwidth used by the speaker is 1 voice stream ~20 kilobits/second . The bandwidth used by each listener is 1 voice stream ~20 kilobits/second . The bandwidth used by the server is (Speakers + Listeners) * Bandwidth = (1 + 3) * ~20 = ~80 kilobits/second . In this setup the bandwidth of each client (speaker or listener) is the minimum possible. If your game uses client devices with tight bandwidth limits this may be the best setup. In a P2P setup the voice follows a different path: Speaker -> Listener # 1 -> Listener # 2 -> Listener # 3 The bandwidth on the server has been reduced (to zero). However, the total bandwidth for the speaker client is now Listeners * Bandwidth = 3 * ~20 = ~60 kilobits/second .","title":"Extensions: Peer To Peer"},{"location":"Tutorials/Custom-Networking.html#implementing-p2p","text":"If you have decided to use peer to peer you need to modify your CustomClient class. Wherever you call NetworkReceivePacket you should modify it to capture the return value of the method call, if the value is not call ReceiveHandshakeP2P with it and a CustomPeer object for the sender of the message. For example in the Photon Unity Networking (PUN) integration the receiving code is implemented like this: // This event is called by PUN when a packet arrives public void PacketDelivered ( byte eventcode , ArraySegment < byte > data , int senderid ) { // Skip events we don't care about if ( eventcode != _network . EventCodeToClient ) return ; // Receive the packet, capture return value var id = NetworkReceivedPacket ( data ); // If the value is not null // pass to handshake method with the `senderid` of this packet if ( id . HasValue ) ReceiveHandshakeP2P ( id . Value , senderid ); } You now need to implement two more methods for sending packets:","title":"Implementing P2P"},{"location":"Tutorials/Custom-Networking.html#sendreliablep2plistltclientinfolttpeergtgt-destinations-arraysegmentltbytegt-packet","text":"","title":"SendReliableP2P(List&lt;ClientInfo&lt;TPeer?&gt;&gt; destinations, ArraySegment&lt;byte&gt; packet)"},{"location":"Tutorials/Custom-Networking.html#sendunreliablep2plistltclientinfolttpeergtgt-destinations-arraysegmentltbytegt-packet","text":"These methods send a packet to a list of destinations. You should send the packet to as many of these destinations as possible and remove them from the list. Once you are done call the base method with the remaining items in the list, they will be sent via the server as usual. For example the PUN implementation of this is: private void SendUnreliableP2P ( IList < ClientInfo < int? >> destinations , ArraySegment < byte > packet ) { // Build a list of destinations we know how to send to // i.e. have a non-null Connection object var dests = new List < int >(); foreach ( var item in destinations ) if ( item . Connection . HasValue ) dests . Add ( item . Connection ); // Remove all the ones we can send to from the input list destinations . RemoveAll ( dests ); // Send the packets to the list of destinations through PUN _network . Send ( packet , dests , reliable : false ); // Call base to do server relay for all the peers we don't // know how to contact base . SendUnreliableP2P ( destinations , packet ); } Because there is a fallback mechanism you can mix P2P and non-P2P packets as necessary. For example you start by sending everything via the server, establish a p2p connection between clients and if it fails (e.g. due to firewall or NAT settings) you can simply keep on sending via relay for that specific pair of clients. Alternatively you could monitor client bandwidth and send via P2P if there is spare bandwidth - falling back to server relay if the client is close to reaching it's bandwidth limit. Finally you need to start establishing p2p connections. Override the OnServerAssignedSessionId method, when this is called you should send a \"handshake\" packet to every peer you know how to contact directly. This will tell those peers that you are available for p2p communication. For example in the PUN integration this is implemented as: protected override void OnServerAssignedSessionId ( uint session , ushort id ) { base . OnServerAssignedSessionId ( session , id ); // Create the handshake packet to send var packet = new ArraySegment < byte >( WriteHandshakeP2P ( session , id )); // Send this to everyone else in the session through PUN _network . Send ( packet , _network . EventCodeToClient , new RaiseEventOptions { Receivers = ReceiverGroup . Others , }, true ); }","title":"SendUnreliableP2P(List&lt;ClientInfo&lt;TPeer?&gt;&gt; destinations, ArraySegment&lt;byte&gt; packet)"},{"location":"Tutorials/Custom-Position-Tracking.html","text":"Tutorial: Custom Position Tracking This tutorial will explain how to write a scripts necessary to extend the Dissonance position tracking system to more advanced scenarios. The basics of position tracking are explained in this tutorial . How Dissonance Tracks Players Dissonance tracks the position of players through a behaviour which implements the IDissonancePlayer interface. This interface exposes the necessary information for Dissonance to play back voices in the correct locations. public interface IDissonancePlayer { string PlayerId { get ; } Vector3 Position { get ; } Quaternion Rotation { get ; } NetworkPlayerType Type { get ; } } PlayerId This is the ID of the player which this object represents. For the local player this is the value in the LocalPlayerName property on your DissonanceComms object. This value should be synchronised across the network. How this works will depend upon your networking system. For example here is how the HLAPI integration does it: private string _playerId ; // This property implements the PlayerId part of the interface public string PlayerId { get { return _playerId ; } } // When the network system starts this behaviour, this method runs public override void OnStartAuthority () { base . OnStartAuthority (); // Get the local DissonanceComms object var comms = FindObjectOfType < DissonanceComms >(); // Call set player name, to sync the name across all peers SetPlayerName ( FindObjectOfType < DissonanceComms >(). LocalPlayerName ); // Make sure that if the local name is changed, we sync the change across the network comms . LocalPlayerNameChanged += SetPlayerName ; } private void SetPlayerName ( string playerName ) { CmdSetPlayerName ( playerName ); } // This is a \"Command\" which means that it is run on *all* peers when invoked. // This is what does the actual synchronisation of the name across the network [Command] private void CmdSetPlayerName ( string playerName ) { _playerId = playerName ; } Position And Rotation These properties supply the location information which is used by Dissonance to properly play positional audio. If the behaviour is attached to the object which represents the player position then implementing this is trivial: public Vector3 Position { get { return transform . position ; } } public Quaternion Rotation { get { return transform . rotation ; } } If you wanted to represent a slightly different location (e.g. your player is made of multiple object, one of which represents the head) then you would need to change the implementation of the properties slightly: private MonoBehaviour _head ; public Vector3 Position { get { return _head . transform . position ; } } public Quaternion Rotation { get { return _head . transform . rotation ; } } // When this behaviour is enabled, find the other object we want to get the position from public void OnEnable () { _head = GetEntityWhichRepresentsTheHead (); } Type This indicates to Dissonance if this object represents the (singular) local player or one of the (multiple) remote players. How you implement this property depends upon your network system. Using the HLAPI integration as an example again: public NetworkPlayerType Type { get { return isLocalPlayer ? NetworkPlayerType . Local : NetworkPlayerType . Remote ; } } This assumes that the component is attached to a player object. Therefore is it is not the local player then it must be a remote player.","title":"Writing A Custom IDissonancePlayer"},{"location":"Tutorials/Custom-Position-Tracking.html#tutorial-custom-position-tracking","text":"This tutorial will explain how to write a scripts necessary to extend the Dissonance position tracking system to more advanced scenarios. The basics of position tracking are explained in this tutorial .","title":"Tutorial: Custom Position Tracking"},{"location":"Tutorials/Custom-Position-Tracking.html#how-dissonance-tracks-players","text":"Dissonance tracks the position of players through a behaviour which implements the IDissonancePlayer interface. This interface exposes the necessary information for Dissonance to play back voices in the correct locations. public interface IDissonancePlayer { string PlayerId { get ; } Vector3 Position { get ; } Quaternion Rotation { get ; } NetworkPlayerType Type { get ; } }","title":"How Dissonance Tracks Players"},{"location":"Tutorials/Custom-Position-Tracking.html#playerid","text":"This is the ID of the player which this object represents. For the local player this is the value in the LocalPlayerName property on your DissonanceComms object. This value should be synchronised across the network. How this works will depend upon your networking system. For example here is how the HLAPI integration does it: private string _playerId ; // This property implements the PlayerId part of the interface public string PlayerId { get { return _playerId ; } } // When the network system starts this behaviour, this method runs public override void OnStartAuthority () { base . OnStartAuthority (); // Get the local DissonanceComms object var comms = FindObjectOfType < DissonanceComms >(); // Call set player name, to sync the name across all peers SetPlayerName ( FindObjectOfType < DissonanceComms >(). LocalPlayerName ); // Make sure that if the local name is changed, we sync the change across the network comms . LocalPlayerNameChanged += SetPlayerName ; } private void SetPlayerName ( string playerName ) { CmdSetPlayerName ( playerName ); } // This is a \"Command\" which means that it is run on *all* peers when invoked. // This is what does the actual synchronisation of the name across the network [Command] private void CmdSetPlayerName ( string playerName ) { _playerId = playerName ; }","title":"PlayerId"},{"location":"Tutorials/Custom-Position-Tracking.html#position-and-rotation","text":"These properties supply the location information which is used by Dissonance to properly play positional audio. If the behaviour is attached to the object which represents the player position then implementing this is trivial: public Vector3 Position { get { return transform . position ; } } public Quaternion Rotation { get { return transform . rotation ; } } If you wanted to represent a slightly different location (e.g. your player is made of multiple object, one of which represents the head) then you would need to change the implementation of the properties slightly: private MonoBehaviour _head ; public Vector3 Position { get { return _head . transform . position ; } } public Quaternion Rotation { get { return _head . transform . rotation ; } } // When this behaviour is enabled, find the other object we want to get the position from public void OnEnable () { _head = GetEntityWhichRepresentsTheHead (); }","title":"Position And Rotation"},{"location":"Tutorials/Custom-Position-Tracking.html#type","text":"This indicates to Dissonance if this object represents the (singular) local player or one of the (multiple) remote players. How you implement this property depends upon your network system. Using the HLAPI integration as an example again: public NetworkPlayerType Type { get { return isLocalPlayer ? NetworkPlayerType . Local : NetworkPlayerType . Remote ; } } This assumes that the component is attached to a player object. Therefore is it is not the local player then it must be a remote player.","title":"Type"},{"location":"Tutorials/Direct-Player-Transmit.html","text":"Direct Player Messaging Also see this video about direct player messaging. This tutorial will explain how to broadcast a voice message directly to a specific player, rather than to all players in a room. There are two ways to achieve this. Set The Player Name To transmit to a specific player, change the Channel Type option on the VoiceBroadcastTrigger to \"Player\", then give the player name for Recipient Player Name. To change the targetted player at run time modify the PlayerId field of the VoiceBroadcastTrigger behaviour. GetComponent < VoiceBroadcastTrigger >(). PlayerId = \"TheNewRemotePlayerName\" ; Target A Player Behaviour If you have set up Dissonance position tracking in your game then the game objects which represent your players will all have a behaviour on them which implements the IDissonancePlayer interface. For example if you are using the Forge Networking integration this is the ForgePlayer component. To transmit to this player change the Channel Type option on a VoiceBroadcastTrigger attached to the same game object to \"Self\".","title":"Transmit to Player"},{"location":"Tutorials/Direct-Player-Transmit.html#direct-player-messaging","text":"Also see this video about direct player messaging. This tutorial will explain how to broadcast a voice message directly to a specific player, rather than to all players in a room. There are two ways to achieve this.","title":"Direct Player Messaging"},{"location":"Tutorials/Direct-Player-Transmit.html#set-the-player-name","text":"To transmit to a specific player, change the Channel Type option on the VoiceBroadcastTrigger to \"Player\", then give the player name for Recipient Player Name. To change the targetted player at run time modify the PlayerId field of the VoiceBroadcastTrigger behaviour. GetComponent < VoiceBroadcastTrigger >(). PlayerId = \"TheNewRemotePlayerName\" ;","title":"Set The Player Name"},{"location":"Tutorials/Direct-Player-Transmit.html#target-a-player-behaviour","text":"If you have set up Dissonance position tracking in your game then the game objects which represent your players will all have a behaviour on them which implements the IDissonancePlayer interface. For example if you are using the Forge Networking integration this is the ForgePlayer component. To transmit to this player change the Channel Type option on a VoiceBroadcastTrigger attached to the same game object to \"Self\".","title":"Target A Player Behaviour"},{"location":"Tutorials/Directly-Using-Channels.html","text":"Directly Using Channels This tutorial will explain how to use the channel API for fine grained control over when and where voice is sent. Channels are the system which are used internally by the transmit triggers which come with Dissonance. Direct use of channels requires writing scripts. Using a channel is quite simple - when a channel is open voice will be sent to whoever is appropriate. A single client may have multiple channels open at once, potentially all sending to the same remote player. The remote playback system will correctly handle this situation and will only play the voice back once. There are two kinds of channels, which correspond to two different types of receivers. Player Channels When a player channel is opened the local voice is sent to the player associated with that channel. The receiving player does not need to take any action to receive the voice. This is accessed through the PlayerChannels property on the DissonanceComms object. DissonanceComms comms ; PlayerChannel channel = comms . PlayerChannels . Open ( string playerId , bool positional , ChannelPriority priority ); Room Channels When a room channel is opened no voice is sent anywhere by default. Receiving players must take an action to indicate that they wish to receive the voice (i.e. join the room). This is accessed through the RoomChannels property on the DissonanceComms object (to open a sending channel) and the Rooms property (to control receipt). DissonanceComms comms ; RoomChannel channel = comms . RoomChannels . Open ( string roomId , bool positional , ChannelPriority priority ); DissonanceComms comms ; comms . Rooms . Join ( string roomId ); Managing An Open Channel When you open a channel you receive back an object which represents that channel. This object allows you to control the channel while it is still open. bool IsOpen { get; } This property indicates if the channel is open. A channel will remain open until you explicitly close it. bool Positional { get; set; } This property indicates if this channel should be played back with positional data. You may change this value at any time. When a channel is using positional audio the remote playeback system will position the playback in space so that it sounds like the player voice is coming from the correct direction. If a channel is not using positional audio the voice will be non-directional. ChannelPriority Priority { get; set; } This property indicates the priority associated with data sent over this channel. You may change this value at any time. When a receiver is receiving multiple channels simultaneously it will only play the highest priority channel(s) it is currently receiving. Dispose() Close the channel.","title":"Using Channels"},{"location":"Tutorials/Directly-Using-Channels.html#directly-using-channels","text":"This tutorial will explain how to use the channel API for fine grained control over when and where voice is sent. Channels are the system which are used internally by the transmit triggers which come with Dissonance. Direct use of channels requires writing scripts. Using a channel is quite simple - when a channel is open voice will be sent to whoever is appropriate. A single client may have multiple channels open at once, potentially all sending to the same remote player. The remote playback system will correctly handle this situation and will only play the voice back once. There are two kinds of channels, which correspond to two different types of receivers.","title":"Directly Using Channels"},{"location":"Tutorials/Directly-Using-Channels.html#player-channels","text":"When a player channel is opened the local voice is sent to the player associated with that channel. The receiving player does not need to take any action to receive the voice. This is accessed through the PlayerChannels property on the DissonanceComms object. DissonanceComms comms ; PlayerChannel channel = comms . PlayerChannels . Open ( string playerId , bool positional , ChannelPriority priority );","title":"Player Channels"},{"location":"Tutorials/Directly-Using-Channels.html#room-channels","text":"When a room channel is opened no voice is sent anywhere by default. Receiving players must take an action to indicate that they wish to receive the voice (i.e. join the room). This is accessed through the RoomChannels property on the DissonanceComms object (to open a sending channel) and the Rooms property (to control receipt). DissonanceComms comms ; RoomChannel channel = comms . RoomChannels . Open ( string roomId , bool positional , ChannelPriority priority ); DissonanceComms comms ; comms . Rooms . Join ( string roomId );","title":"Room Channels"},{"location":"Tutorials/Directly-Using-Channels.html#managing-an-open-channel","text":"When you open a channel you receive back an object which represents that channel. This object allows you to control the channel while it is still open. bool IsOpen { get; } This property indicates if the channel is open. A channel will remain open until you explicitly close it. bool Positional { get; set; } This property indicates if this channel should be played back with positional data. You may change this value at any time. When a channel is using positional audio the remote playeback system will position the playback in space so that it sounds like the player voice is coming from the correct direction. If a channel is not using positional audio the voice will be non-directional. ChannelPriority Priority { get; set; } This property indicates the priority associated with data sent over this channel. You may change this value at any time. When a receiver is receiving multiple channels simultaneously it will only play the highest priority channel(s) it is currently receiving. Dispose() Close the channel.","title":"Managing An Open Channel"},{"location":"Tutorials/Global-Chat-Room.html","text":"Global Chat Room A global chat room is just a single room which all users talk to and listen to. This is a very simple system to create using Dissonance. Create a Voice Broadcast Trigger and a Voice Receipt Trigger on the root Dissonance game object Set the room for both of them to \"Global\". Both components will activate when the scene loads (on each different computer in the network session) and all players will be in the room. Find out more about the broadcast trigger and the receipt trigger .","title":"Global Chat Room"},{"location":"Tutorials/Global-Chat-Room.html#global-chat-room","text":"A global chat room is just a single room which all users talk to and listen to. This is a very simple system to create using Dissonance. Create a Voice Broadcast Trigger and a Voice Receipt Trigger on the root Dissonance game object Set the room for both of them to \"Global\". Both components will activate when the scene loads (on each different computer in the network session) and all players will be in the room. Find out more about the broadcast trigger and the receipt trigger .","title":"Global Chat Room"},{"location":"Tutorials/Playback-Prefab.html","text":"Playback Prefab The playback prefab is how Dissonance plays the audio signal from each player. A copy of the prefab is instantiated for each player and then moved into the correct position for positional audio to work. Creating your own playback prefab allows you to customise the AudioSource settings used for voice or attach your own script to the prefab. To use a custom prefab drag the prefab into the Playback Prefab field on the Dissonance Comms component inspector. If no prefab is set Dissonance will automatically use a default prefab. Prefab Components The playback prefab must include a VoicePlayback component (part of Dissonance). You may also attach a Unity AudioSource component, in which case you can adjust some of the settings to change how voice will be played back. However, the following settings will be overwritten by Dissonance: Loop Pitch Clip Play On Awake Mute Lifetime When writing your own scripts to attach to the playback prefab it is important to remember that the lifetime is managed entirely by Dissonance. Prefab instances are recycled to reduce the amount of garbage created. This means that your custom script attached to the prefab must be able to handle being re-assigned from one player to another. When there are no instances available to use, a new one is created: Prefab instantiated Default components added Activated When the player for an instance leaves the prefab is recycled: Deactivated Stored in a pool of inactive instances When another player joins an instance is retrieved and re-used: Retrieved from pool Activated To handle this in your script simply use the normal Unity lifecycle events : void Awake () { // This only runs once. Use this to perform one-time setup. // e.g. Find some Dissonance components _playbackComponent = GetComponent < VoicePlayback >(); _dissonanceComms = FindObjectOfType < DissonanceComms >(); } void OnEnable () { // This runs every time the script is activated. Use this to perform per-player setup // e.g. find information about this player _playerState = _dissonanceComms . FindPlayer ( _playbackComponent . PlayerName ); } void Update () { // This will run every frame while the script is active } void OnDisable () { // This runs every time the script is deactivated. Use this to perform per-player cleanup // e.g. Remove the things which were initialised in OnEnable _playerState = null ; }","title":"Custom Playback Prefab"},{"location":"Tutorials/Playback-Prefab.html#playback-prefab","text":"The playback prefab is how Dissonance plays the audio signal from each player. A copy of the prefab is instantiated for each player and then moved into the correct position for positional audio to work. Creating your own playback prefab allows you to customise the AudioSource settings used for voice or attach your own script to the prefab. To use a custom prefab drag the prefab into the Playback Prefab field on the Dissonance Comms component inspector. If no prefab is set Dissonance will automatically use a default prefab.","title":"Playback Prefab"},{"location":"Tutorials/Playback-Prefab.html#prefab-components","text":"The playback prefab must include a VoicePlayback component (part of Dissonance). You may also attach a Unity AudioSource component, in which case you can adjust some of the settings to change how voice will be played back. However, the following settings will be overwritten by Dissonance: Loop Pitch Clip Play On Awake Mute","title":"Prefab Components"},{"location":"Tutorials/Playback-Prefab.html#lifetime","text":"When writing your own scripts to attach to the playback prefab it is important to remember that the lifetime is managed entirely by Dissonance. Prefab instances are recycled to reduce the amount of garbage created. This means that your custom script attached to the prefab must be able to handle being re-assigned from one player to another. When there are no instances available to use, a new one is created: Prefab instantiated Default components added Activated When the player for an instance leaves the prefab is recycled: Deactivated Stored in a pool of inactive instances When another player joins an instance is retrieved and re-used: Retrieved from pool Activated To handle this in your script simply use the normal Unity lifecycle events : void Awake () { // This only runs once. Use this to perform one-time setup. // e.g. Find some Dissonance components _playbackComponent = GetComponent < VoicePlayback >(); _dissonanceComms = FindObjectOfType < DissonanceComms >(); } void OnEnable () { // This runs every time the script is activated. Use this to perform per-player setup // e.g. find information about this player _playerState = _dissonanceComms . FindPlayer ( _playbackComponent . PlayerName ); } void Update () { // This will run every frame while the script is active } void OnDisable () { // This runs every time the script is deactivated. Use this to perform per-player cleanup // e.g. Remove the things which were initialised in OnEnable _playerState = null ; }","title":"Lifetime"},{"location":"Tutorials/Player-State.html","text":"Player State Dissonance offers an easy to use API for finding out information about other players in the session. Discovering Players There are two ways to discover who is in the Dissonance session - events and polling. To get a list of players currently in the session, you can access the Players property on the DissonanceComms object: var comms = FindObjectOfType < DissonanceComms >(); foreach ( var player in comms . Players ) { Debug . Log ( \"Player \" + player . Name + \" is in the game\" ); } This will give you a set of VoicePlayerState objects (including one for the local player). These objects will stay valid forever and will be updated with new information as necessary. Dissonance also exposes some events which will get invoked when certain things happen, for example a new player joining the session. var comms = FindObjectOfType < DissonanceComms >(); comms . OnPlayerJoinedSession += player => { Debug . Log ( \"Player \" + player . Name + \" Joined session\" ); } comms . OnPlayerLeftSession += player => { Debug . Log ( \"Player \" + player . Name + \" Left session\" ); } The player objects passed to the event handlers here are VoicePlayerState objects which expose a lot of useful data about the players such as if they are currently talking and a live readout of the amplitue.","title":"Finding Players"},{"location":"Tutorials/Player-State.html#player-state","text":"Dissonance offers an easy to use API for finding out information about other players in the session.","title":"Player State"},{"location":"Tutorials/Player-State.html#discovering-players","text":"There are two ways to discover who is in the Dissonance session - events and polling. To get a list of players currently in the session, you can access the Players property on the DissonanceComms object: var comms = FindObjectOfType < DissonanceComms >(); foreach ( var player in comms . Players ) { Debug . Log ( \"Player \" + player . Name + \" is in the game\" ); } This will give you a set of VoicePlayerState objects (including one for the local player). These objects will stay valid forever and will be updated with new information as necessary. Dissonance also exposes some events which will get invoked when certain things happen, for example a new player joining the session. var comms = FindObjectOfType < DissonanceComms >(); comms . OnPlayerJoinedSession += player => { Debug . Log ( \"Player \" + player . Name + \" Joined session\" ); } comms . OnPlayerLeftSession += player => { Debug . Log ( \"Player \" + player . Name + \" Left session\" ); } The player objects passed to the event handlers here are VoicePlayerState objects which expose a lot of useful data about the players such as if they are currently talking and a live readout of the amplitue.","title":"Discovering Players"},{"location":"Tutorials/Position-Tracking-For-Bolt.html","text":"Tutorial: Position Tracking Also see this video about position tracking. This tutorial will explain how to configure your project to track the position of players. This is required for 3D positional audio playback of remote player voice chat and collider trigger support for VoiceBroadcastTrigger and VoiceReceiptTrigger . There are some additional steps required for this to work with Photon BOLT, if you are not using that network integration instead see the more general position tracking tutorial . BOLT State Synchronisation First you need to modify the bolt state which you use for your player; add a new string property called DissonancePlayerId . Now you need to create a new script which will use this state. Dissonance includes a base class which does most of the work for you. using Dissonance.Integrations.PhotonBolt ; public class DissonancePlayerTracking : BoltPlayer < ??? > // <-- See below { public DissonancePlayerTracking () : base ( \"DissonancePlayerId\" , state => state . DissonancePlayerId , ( state , id ) => state . DissonancePlayerId = id ) { } } The ??? in the example needs to be replaced with the state which bolt has generated for your player. Setup Tracking To setup position tracking you simply need to attach the DissonancePlayerTracking component to the game object which represents each player. Ensure that this component is attached to all entities in the scene which represent a player (both the local player and all remote players). If you have a prefab which is used to construct your players you can simply attach the behaviour to this prefab. Using Position Tracking Positional Audio When positional audio is enabled the voice from remote players will sound like it is coming from the correct position. To enable this simply tick the \"use positional data\" checkbox on the voice broadcast trigger. Collider Chat Room Voice broadcaster triggers and voice receipt triggers can be configured to only send/receive audio when the local player is inside a certain volume. See this tutorial for how to achieve this. Direct Transmit To Player When position tracking is enable transmitting to a specific player is simplified. If a Voice Broadcast Trigger is attached to a player entity it can be configured to transmit to the player represented by the game object. See this tutorial for details.","title":"Position Tracking For BOLT"},{"location":"Tutorials/Position-Tracking-For-Bolt.html#tutorial-position-tracking","text":"Also see this video about position tracking. This tutorial will explain how to configure your project to track the position of players. This is required for 3D positional audio playback of remote player voice chat and collider trigger support for VoiceBroadcastTrigger and VoiceReceiptTrigger . There are some additional steps required for this to work with Photon BOLT, if you are not using that network integration instead see the more general position tracking tutorial .","title":"Tutorial: Position Tracking"},{"location":"Tutorials/Position-Tracking-For-Bolt.html#bolt-state-synchronisation","text":"First you need to modify the bolt state which you use for your player; add a new string property called DissonancePlayerId . Now you need to create a new script which will use this state. Dissonance includes a base class which does most of the work for you. using Dissonance.Integrations.PhotonBolt ; public class DissonancePlayerTracking : BoltPlayer < ??? > // <-- See below { public DissonancePlayerTracking () : base ( \"DissonancePlayerId\" , state => state . DissonancePlayerId , ( state , id ) => state . DissonancePlayerId = id ) { } } The ??? in the example needs to be replaced with the state which bolt has generated for your player.","title":"BOLT State Synchronisation"},{"location":"Tutorials/Position-Tracking-For-Bolt.html#setup-tracking","text":"To setup position tracking you simply need to attach the DissonancePlayerTracking component to the game object which represents each player. Ensure that this component is attached to all entities in the scene which represent a player (both the local player and all remote players). If you have a prefab which is used to construct your players you can simply attach the behaviour to this prefab.","title":"Setup Tracking"},{"location":"Tutorials/Position-Tracking-For-Bolt.html#using-position-tracking","text":"","title":"Using Position Tracking"},{"location":"Tutorials/Position-Tracking-For-Bolt.html#positional-audio","text":"When positional audio is enabled the voice from remote players will sound like it is coming from the correct position. To enable this simply tick the \"use positional data\" checkbox on the voice broadcast trigger.","title":"Positional Audio"},{"location":"Tutorials/Position-Tracking-For-Bolt.html#collider-chat-room","text":"Voice broadcaster triggers and voice receipt triggers can be configured to only send/receive audio when the local player is inside a certain volume. See this tutorial for how to achieve this.","title":"Collider Chat Room"},{"location":"Tutorials/Position-Tracking-For-Bolt.html#direct-transmit-to-player","text":"When position tracking is enable transmitting to a specific player is simplified. If a Voice Broadcast Trigger is attached to a player entity it can be configured to transmit to the player represented by the game object. See this tutorial for details.","title":"Direct Transmit To Player"},{"location":"Tutorials/Position-Tracking.html","text":"Tutorial: Position Tracking Also see this video about position tracking. This tutorial will explain how to configure your project to track the position of players. This is required for 3D positional audio playback of remote player voice chat and collider trigger support for VoiceBroadcastTrigger and VoiceReceiptTrigger . Setup Tracking To setup position tracking you simply need to attach a single behaviour to all your player entities. This behaviour depends upon which network integration you are using, it will be located in the folder for your integration: Integrations/UNet_HLAPI/HlapiPlayer Integrations/ForgeNetworking/ForgePlayer Integrations/PhotonUnityNetworking/PhotonPlayer Ensure that this component is attached to all entities in the scene which represent a player (both the local player and all remote players). If you have a prefab which is used to construct your players you can simply attach the behaviour to this prefab. For slightly more advanced setups you may need to write your own player script for position tracking, you can find documentation for this here . What Does Position Tracking Cost? Some people have avoided using the position tracking because they're worried that it's wasting network bandwidth - after all your player positions are already synchronised across the network so it would be a waste for Dissonance to send the positions to. However Dissonance does not send any extra data across the network when position tracking is enabled - instead it relies on your game objects already being in the right place on every client and simply plays the audio from wherever they are in space. Using Position Tracking Positional Audio When positional audio is enabled the voice from remote players will sound like it is coming from the correct position. To enable this simply tick the \"use positional data\" checkbox on the voice broadcast trigger. Collider Chat Room Voice broadcaster triggers and voice receipt triggers can be configured to only send/receive audio when the local player is inside a certain volume. See this tutorial for how to achieve this. Direct Transmit To Player When position tracking is enable transmitting to a specific player is simplified. If a Voice Broadcast Trigger is attached to a player entity it can be configured to transmit to the player represented by the game object. See this tutorial for details.","title":"Position Tracking"},{"location":"Tutorials/Position-Tracking.html#tutorial-position-tracking","text":"Also see this video about position tracking. This tutorial will explain how to configure your project to track the position of players. This is required for 3D positional audio playback of remote player voice chat and collider trigger support for VoiceBroadcastTrigger and VoiceReceiptTrigger .","title":"Tutorial: Position Tracking"},{"location":"Tutorials/Position-Tracking.html#setup-tracking","text":"To setup position tracking you simply need to attach a single behaviour to all your player entities. This behaviour depends upon which network integration you are using, it will be located in the folder for your integration: Integrations/UNet_HLAPI/HlapiPlayer Integrations/ForgeNetworking/ForgePlayer Integrations/PhotonUnityNetworking/PhotonPlayer Ensure that this component is attached to all entities in the scene which represent a player (both the local player and all remote players). If you have a prefab which is used to construct your players you can simply attach the behaviour to this prefab. For slightly more advanced setups you may need to write your own player script for position tracking, you can find documentation for this here .","title":"Setup Tracking"},{"location":"Tutorials/Position-Tracking.html#what-does-position-tracking-cost","text":"Some people have avoided using the position tracking because they're worried that it's wasting network bandwidth - after all your player positions are already synchronised across the network so it would be a waste for Dissonance to send the positions to. However Dissonance does not send any extra data across the network when position tracking is enabled - instead it relies on your game objects already being in the right place on every client and simply plays the audio from wherever they are in space.","title":"What Does Position Tracking Cost?"},{"location":"Tutorials/Position-Tracking.html#using-position-tracking","text":"","title":"Using Position Tracking"},{"location":"Tutorials/Position-Tracking.html#positional-audio","text":"When positional audio is enabled the voice from remote players will sound like it is coming from the correct position. To enable this simply tick the \"use positional data\" checkbox on the voice broadcast trigger.","title":"Positional Audio"},{"location":"Tutorials/Position-Tracking.html#collider-chat-room","text":"Voice broadcaster triggers and voice receipt triggers can be configured to only send/receive audio when the local player is inside a certain volume. See this tutorial for how to achieve this.","title":"Collider Chat Room"},{"location":"Tutorials/Position-Tracking.html#direct-transmit-to-player","text":"When position tracking is enable transmitting to a specific player is simplified. If a Voice Broadcast Trigger is attached to a player entity it can be configured to transmit to the player represented by the game object. See this tutorial for details.","title":"Direct Transmit To Player"},{"location":"Tutorials/Proximity-Chat.html","text":"Proximity Chat Also see this video about proximity chat rooms. This tutorial will explain how to build a proximity chat system where players can only talk to other players who are standing close to them. How this will work in your game depends upon exactly how you create player objects - feel free to ask for help . Proximity chat rooms work by combining direct player transmission and collider chat rooms . Each player in your game should have a voice broadcast trigger attached to it (set to broadcast directly to that player) and configured as a collider chat room with a suitable collision volume (e.g. a large sphere). When two players stand close to one another they will enter each others transmission trigger volumes and begin talking to one another. In this example channel type is set to \"Self\", this means the broadcast trigger searches for one of the Dissonance position tracking behaviours and transmits directly to the player which that represents.","title":"Proximity Chat"},{"location":"Tutorials/Proximity-Chat.html#proximity-chat","text":"Also see this video about proximity chat rooms. This tutorial will explain how to build a proximity chat system where players can only talk to other players who are standing close to them. How this will work in your game depends upon exactly how you create player objects - feel free to ask for help . Proximity chat rooms work by combining direct player transmission and collider chat rooms . Each player in your game should have a voice broadcast trigger attached to it (set to broadcast directly to that player) and configured as a collider chat room with a suitable collision volume (e.g. a large sphere). When two players stand close to one another they will enter each others transmission trigger volumes and begin talking to one another. In this example channel type is set to \"Self\", this means the broadcast trigger searches for one of the Dissonance position tracking behaviours and transmits directly to the player which that represents.","title":"Proximity Chat"},{"location":"Tutorials/Push-to-Talk.html","text":"Tutorial: Push-to-Talk There is a video version of this tutorial here . When a broadcast trigger is in Push-To-Talk (PTT) mode voice will only be transmitted while the \"talk\" button is pressed. To set a broadcast trigger to use PTT simply change the \"Activation Mode\" to \"Push To Talk\" and choose which input axis must be pressed for voice to be transmitted. See the Unity documentation for how to define a new input axis.","title":"Push-To-Talk"},{"location":"Tutorials/Push-to-Talk.html#tutorial-push-to-talk","text":"There is a video version of this tutorial here . When a broadcast trigger is in Push-To-Talk (PTT) mode voice will only be transmitted while the \"talk\" button is pressed. To set a broadcast trigger to use PTT simply change the \"Activation Mode\" to \"Push To Talk\" and choose which input axis must be pressed for voice to be transmitted. See the Unity documentation for how to define a new input axis.","title":"Tutorial: Push-to-Talk"},{"location":"Tutorials/Script-Controlled-Speech.html","text":"Script Controlled Speech There are several options for controlling speech from scripts, depending on what you want to achieve. Muting The Local Player If you want to completely prevent a player from speaking you can set the IsMuted property on the DissonanceComms component to true. DissonanceComms comms ; comms . IsMuted = true ; // User cannot speak comms . IsMuted = false ; // User can speak Deafening The Local Player If you want to completely prevent the local player from hearing any speech you can set the IsDeafened property on the DissonanceComms component to true. DissonanceComms comms ; comms . IsDeafened = true ; // User cannot hear comms . IsDeafened = false ; //User can hear Muting Remote Players If you want to locally mute a remote player (prevent yourself from hearing them talk) you can set the IsLocallyMuted property on their player object. DissonanceComms comms ; var player = comms . FindPlayer ( player_id ); player . IsLocallyMuted = true ; // You will not hear user when they speak player . IsLocallyMuted = false ; // You will hear user when they speak Disabling Triggers The VoiceBroadcastTrigger is the normal way to trigger voice transmission. Simply disabling this component will prevent it from triggering any voice transmissions until it is enabled again. VoiceBroadcastTrigger trigger ; trigger . enabled = false ; // This trigger cannot send voice trigger . enabled = true ; // This trigger can send voice Opening Channels The most general way to control player voice transmission from scripts is to open and close channels, for more information about channels see this tutorial . To start talking open a channel, to stop talking dispose the channel: DissonanceComms comms ; var channel = comms . RoomChannels . Open ( \"Room ID\" , true , ChannelPriority . Default ); //Player speech will be transmitted to the room named \"Room ID\" channel . Dispose (); //Player speech will no longer be transmitted by this channel","title":"Script Controlled Speech"},{"location":"Tutorials/Script-Controlled-Speech.html#script-controlled-speech","text":"There are several options for controlling speech from scripts, depending on what you want to achieve.","title":"Script Controlled Speech"},{"location":"Tutorials/Script-Controlled-Speech.html#muting-the-local-player","text":"If you want to completely prevent a player from speaking you can set the IsMuted property on the DissonanceComms component to true. DissonanceComms comms ; comms . IsMuted = true ; // User cannot speak comms . IsMuted = false ; // User can speak","title":"Muting The Local Player"},{"location":"Tutorials/Script-Controlled-Speech.html#deafening-the-local-player","text":"If you want to completely prevent the local player from hearing any speech you can set the IsDeafened property on the DissonanceComms component to true. DissonanceComms comms ; comms . IsDeafened = true ; // User cannot hear comms . IsDeafened = false ; //User can hear","title":"Deafening The Local Player"},{"location":"Tutorials/Script-Controlled-Speech.html#muting-remote-players","text":"If you want to locally mute a remote player (prevent yourself from hearing them talk) you can set the IsLocallyMuted property on their player object. DissonanceComms comms ; var player = comms . FindPlayer ( player_id ); player . IsLocallyMuted = true ; // You will not hear user when they speak player . IsLocallyMuted = false ; // You will hear user when they speak","title":"Muting Remote Players"},{"location":"Tutorials/Script-Controlled-Speech.html#disabling-triggers","text":"The VoiceBroadcastTrigger is the normal way to trigger voice transmission. Simply disabling this component will prevent it from triggering any voice transmissions until it is enabled again. VoiceBroadcastTrigger trigger ; trigger . enabled = false ; // This trigger cannot send voice trigger . enabled = true ; // This trigger can send voice","title":"Disabling Triggers"},{"location":"Tutorials/Script-Controlled-Speech.html#opening-channels","text":"The most general way to control player voice transmission from scripts is to open and close channels, for more information about channels see this tutorial . To start talking open a channel, to stop talking dispose the channel: DissonanceComms comms ; var channel = comms . RoomChannels . Open ( \"Room ID\" , true , ChannelPriority . Default ); //Player speech will be transmitted to the room named \"Room ID\" channel . Dispose (); //Player speech will no longer be transmitted by this channel","title":"Opening Channels"},{"location":"Tutorials/Spatializer-Plugin.html","text":"Spatializer Plugins Unity natively supports Audio Spatializers for virtual reality (VR) projects. To find out more about how to use an Audio Spatializer in your project refer to the Unity documentation . When not using a spatializer plugin Dissonance will automatically apply basic spatialization itself, this interferes with native spatialization plugins and must be disabled when using one. Dissonance includes two default playback prefabs in the Assets/Plugins/Dissonance/Resources directory. To begin using a spatialization plugin simply use the SpatializedPlaybackPrefab - all voices will now be spatialized using the spatializer plugin you have selected. Spatialization And Custom Playback Prefabs If you are creating a custom playback prefab enaling spatialization is very simple - just tick the Spatialize checkbox on the AudioSource in the prefab.","title":"Spatialization Plugins"},{"location":"Tutorials/Spatializer-Plugin.html#spatializer-plugins","text":"Unity natively supports Audio Spatializers for virtual reality (VR) projects. To find out more about how to use an Audio Spatializer in your project refer to the Unity documentation . When not using a spatializer plugin Dissonance will automatically apply basic spatialization itself, this interferes with native spatialization plugins and must be disabled when using one. Dissonance includes two default playback prefabs in the Assets/Plugins/Dissonance/Resources directory. To begin using a spatialization plugin simply use the SpatializedPlaybackPrefab - all voices will now be spatialized using the spatializer plugin you have selected.","title":"Spatializer Plugins"},{"location":"Tutorials/Spatializer-Plugin.html#spatialization-and-custom-playback-prefabs","text":"If you are creating a custom playback prefab enaling spatialization is very simple - just tick the Spatialize checkbox on the AudioSource in the prefab.","title":"Spatialization And Custom Playback Prefabs"},{"location":"Tutorials/Team-Chat-Rooms.html","text":"Team Chat Rooms A team chat room is a set of rooms where all users on the same team talk to and listen to the same room. To create a setup like this requires a small amount of scripting as it depends on how your game defines what a \"team\" actually is! To create a team chat setup first create multiple pairs of broadcasters and receivers, one for each team. With the setup as shown here every player will speak and and listen to every team channel. To fix this add a unique token to each pair of triggers (e.g. the team name), once you have done this none of the triggers will activate and no one will speak or listen to any of the team rooms. Finally, when you create a player and assign them to a team run a script which adds the appropriate token to the local player. Exactly how this code works depends a lot on exactly how your game defines what a team is, feel free to ask for help . Here is some example code: void OnAssignPlayerToTeam ( string teamName ) { //Find local comms object var comms = FindObjectOfType < DissonanceComms >(); //Sanity check that we found what we're looking for if ( comms == null ) { Debug . Log ( \"Cannot find voice components for team '{0}'\" , teamName ); return ; } //Add the token for the team comms . AddToken ( teamName ); } Additional Global Chat Room If you want to still have a global voice chat room and have per team chat rooms this can be achieved by simply having the normal global chat room configuration with a different activation mode (e.g. a different push-to-talk input axis, such as 'v' to team chat and 'b' to global chat).","title":"Team Chat Rooms"},{"location":"Tutorials/Team-Chat-Rooms.html#team-chat-rooms","text":"A team chat room is a set of rooms where all users on the same team talk to and listen to the same room. To create a setup like this requires a small amount of scripting as it depends on how your game defines what a \"team\" actually is! To create a team chat setup first create multiple pairs of broadcasters and receivers, one for each team. With the setup as shown here every player will speak and and listen to every team channel. To fix this add a unique token to each pair of triggers (e.g. the team name), once you have done this none of the triggers will activate and no one will speak or listen to any of the team rooms. Finally, when you create a player and assign them to a team run a script which adds the appropriate token to the local player. Exactly how this code works depends a lot on exactly how your game defines what a team is, feel free to ask for help . Here is some example code: void OnAssignPlayerToTeam ( string teamName ) { //Find local comms object var comms = FindObjectOfType < DissonanceComms >(); //Sanity check that we found what we're looking for if ( comms == null ) { Debug . Log ( \"Cannot find voice components for team '{0}'\" , teamName ); return ; } //Add the token for the team comms . AddToken ( teamName ); }","title":"Team Chat Rooms"},{"location":"Tutorials/Team-Chat-Rooms.html#additional-global-chat-room","text":"If you want to still have a global voice chat room and have per team chat rooms this can be achieved by simply having the normal global chat room configuration with a different activation mode (e.g. a different push-to-talk input axis, such as 'v' to team chat and 'b' to global chat).","title":"Additional Global Chat Room"},{"location":"Tutorials/Text-Chat.html","text":"Text Chat Dissonance allows text chat messages to be routed through the comms network to the same players and chat rooms used by the voice comms network. This tutorial will demonstrate the APIs provided to send and receive text chat messages with Dissonance. Send a text message to a Chat Room // get the DissonanceComms script from the Dissonance game object var dissonance = GetComponent < DissonanceComms >(); // send a text message to the Party chat channel dissonance . Text . Send ( \"Party\" , \"Who just pulled the boss?\" ) Send a text message to a player // get the DissonanceComms script from the Dissonance game object var dissonance = GetComponent < DissonanceComms >(); // send a text message to a specific player dissonance . Text . Whisper ( \"hunter\" , \"Did you just pull the boss?\" ) Receive a text message Dissonance will only send you text messages if they are directly addressed to you or to a room which you are listening to. To listen to a room you can use a voice receipt trigger voice receipt trigger , or directly use the Dissonance API from scripts to enter the room. // get the DissonanceComms script from the Dissonance game object var dissonance = GetComponent < DissonanceComms >(); //If necessary, enter a room using the scripting API dissonance . Rooms . Join ( \"Room Name\" ); dissonance . Text . MessageRecieved += message => { //This code will run every time you receive a text message var format = \"[{0}] {1}: {2}\" ; if ( message . RecipientType == ChannelType . Player ) format = \"{1} whispers: {2}\" ; chatLog . Write ( string . Format ( format , message . Recipient , message . Sender , message . Message )); };","title":"Text Chat"},{"location":"Tutorials/Text-Chat.html#text-chat","text":"Dissonance allows text chat messages to be routed through the comms network to the same players and chat rooms used by the voice comms network. This tutorial will demonstrate the APIs provided to send and receive text chat messages with Dissonance.","title":"Text Chat"},{"location":"Tutorials/Text-Chat.html#send-a-text-message-to-a-chat-room","text":"// get the DissonanceComms script from the Dissonance game object var dissonance = GetComponent < DissonanceComms >(); // send a text message to the Party chat channel dissonance . Text . Send ( \"Party\" , \"Who just pulled the boss?\" )","title":"Send a text message to a Chat Room"},{"location":"Tutorials/Text-Chat.html#send-a-text-message-to-a-player","text":"// get the DissonanceComms script from the Dissonance game object var dissonance = GetComponent < DissonanceComms >(); // send a text message to a specific player dissonance . Text . Whisper ( \"hunter\" , \"Did you just pull the boss?\" )","title":"Send a text message to a player"},{"location":"Tutorials/Text-Chat.html#receive-a-text-message","text":"Dissonance will only send you text messages if they are directly addressed to you or to a room which you are listening to. To listen to a room you can use a voice receipt trigger voice receipt trigger , or directly use the Dissonance API from scripts to enter the room. // get the DissonanceComms script from the Dissonance game object var dissonance = GetComponent < DissonanceComms >(); //If necessary, enter a room using the scripting API dissonance . Rooms . Join ( \"Room Name\" ); dissonance . Text . MessageRecieved += message => { //This code will run every time you receive a text message var format = \"[{0}] {1}: {2}\" ; if ( message . RecipientType == ChannelType . Player ) format = \"{1} whispers: {2}\" ; chatLog . Write ( string . Format ( format , message . Recipient , message . Sender , message . Message )); };","title":"Receive a text message"}]}